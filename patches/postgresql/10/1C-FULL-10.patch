diff -ruN a/configure b/configure
--- a/configure	2017-12-28 14:57:41.931568037 +0300
+++ b/configure	2017-12-28 14:58:03.463305255 +0300
@@ -5644,7 +5644,79 @@
 	# Put the nasty error message in config.log where it belongs
 	echo "$ICU_PKG_ERRORS" >&5
 
-	as_fn_error $? "Package requirements (icu-uc icu-i18n) were not met:
+	icu_not_found=1
+elif test $pkg_failed = untried; then
+        { $as_echo "$as_me:${as_lineno-$LINENO}: result: no" >&5
+$as_echo "no" >&6; }
+	icu_not_found=1
+else
+	ICU_CFLAGS=$pkg_cv_ICU_CFLAGS
+	ICU_LIBS=$pkg_cv_ICU_LIBS
+        { $as_echo "$as_me:${as_lineno-$LINENO}: result: yes" >&5
+$as_echo "yes" >&6; }
+	icu_not_found=0
+fi
+  if test "$icu_not_found" -eq 1; then
+
+pkg_failed=no
+{ $as_echo "$as_me:${as_lineno-$LINENO}: checking for icu" >&5
+$as_echo_n "checking for icu... " >&6; }
+
+if test -n "$ICU_CFLAGS"; then
+    pkg_cv_ICU_CFLAGS="$ICU_CFLAGS"
+ elif test -n "$PKG_CONFIG"; then
+    if test -n "$PKG_CONFIG" && \
+    { { $as_echo "$as_me:${as_lineno-$LINENO}: \$PKG_CONFIG --exists --print-errors \"icu\""; } >&5
+  ($PKG_CONFIG --exists --print-errors "icu") 2>&5
+  ac_status=$?
+  $as_echo "$as_me:${as_lineno-$LINENO}: \$? = $ac_status" >&5
+  test $ac_status = 0; }; then
+  pkg_cv_ICU_CFLAGS=`$PKG_CONFIG --cflags "icu" 2>/dev/null`
+		      test "x$?" != "x0" && pkg_failed=yes
+else
+  pkg_failed=yes
+fi
+ else
+    pkg_failed=untried
+fi
+if test -n "$ICU_LIBS"; then
+    pkg_cv_ICU_LIBS="$ICU_LIBS"
+ elif test -n "$PKG_CONFIG"; then
+    if test -n "$PKG_CONFIG" && \
+    { { $as_echo "$as_me:${as_lineno-$LINENO}: \$PKG_CONFIG --exists --print-errors \"icu\""; } >&5
+  ($PKG_CONFIG --exists --print-errors "icu") 2>&5
+  ac_status=$?
+  $as_echo "$as_me:${as_lineno-$LINENO}: \$? = $ac_status" >&5
+  test $ac_status = 0; }; then
+  pkg_cv_ICU_LIBS=`$PKG_CONFIG --libs "icu" 2>/dev/null`
+		      test "x$?" != "x0" && pkg_failed=yes
+else
+  pkg_failed=yes
+fi
+ else
+    pkg_failed=untried
+fi
+
+
+
+if test $pkg_failed = yes; then
+        { $as_echo "$as_me:${as_lineno-$LINENO}: result: no" >&5
+$as_echo "no" >&6; }
+
+if $PKG_CONFIG --atleast-pkgconfig-version 0.20; then
+        _pkg_short_errors_supported=yes
+else
+        _pkg_short_errors_supported=no
+fi
+        if test $_pkg_short_errors_supported = yes; then
+	        ICU_PKG_ERRORS=`$PKG_CONFIG --short-errors --print-errors --cflags --libs "icu" 2>&1`
+        else
+	        ICU_PKG_ERRORS=`$PKG_CONFIG --print-errors --cflags --libs "icu" 2>&1`
+        fi
+	# Put the nasty error message in config.log where it belongs
+	echo "$ICU_PKG_ERRORS" >&5
+
+	as_fn_error $? "Package requirements (icu) were not met:
 
 $ICU_PKG_ERRORS
 
@@ -5676,6 +5748,7 @@
 $as_echo "yes" >&6; }
 
 fi
+  fi
 fi
 
 #
diff -ruN a/configure.in b/configure.in
--- a/configure.in	2017-12-28 14:57:41.975567500 +0300
+++ b/configure.in	2017-12-28 14:58:03.463305255 +0300
@@ -627,7 +627,10 @@
 AC_SUBST(with_icu)
 
 if test "$with_icu" = yes; then
-  PKG_CHECK_MODULES(ICU, icu-uc icu-i18n)
+  PKG_CHECK_MODULES(ICU, icu-uc icu-i18n,icu_not_found=0,icu_not_found=1)
+  if test "$icu_not_found" -eq 1; then
+  	PKG_CHECK_MODULES(ICU, icu)
+  fi
 fi
 
 #
diff -ruN a/contrib/fasttrun/expected/fasttrun.out b/contrib/fasttrun/expected/fasttrun.out
--- a/contrib/fasttrun/expected/fasttrun.out	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fasttrun/expected/fasttrun.out	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,115 @@
+CREATE EXTENSION fasttrun;
+create table persist ( a int );
+insert into persist values (1);
+select fasttruncate('persist');
+ERROR:  Relation isn't a temporary table
+insert into persist values (2);
+select * from persist order by a;
+ a 
+---
+ 1
+ 2
+(2 rows)
+
+create temp table temp1 (a int);
+insert into temp1 values (1);
+BEGIN;
+create temp table temp2 (a int);
+insert into temp2 values (1);
+select * from temp1 order by a;
+ a 
+---
+ 1
+(1 row)
+
+select * from temp2 order by a;
+ a 
+---
+ 1
+(1 row)
+
+insert into temp1 (select * from generate_series(1,10000));
+insert into temp2 (select * from generate_series(1,11000));
+analyze temp2;
+select relname,  relpages>0, reltuples>0 from pg_class where relname in ('temp1', 'temp2') order by relname;
+ relname | ?column? | ?column? 
+---------+----------+----------
+ temp1   | f        | f
+ temp2   | t        | t
+(2 rows)
+
+select fasttruncate('temp1');
+ fasttruncate 
+--------------
+ 
+(1 row)
+
+select fasttruncate('temp2');
+ fasttruncate 
+--------------
+ 
+(1 row)
+
+insert into temp1 values (-2);
+insert into temp2 values (-2);
+select * from temp1 order by a;
+ a  
+----
+ -2
+(1 row)
+
+select * from temp2 order by a;
+ a  
+----
+ -2
+(1 row)
+
+COMMIT;
+select * from temp1 order by a;
+ a  
+----
+ -2
+(1 row)
+
+select * from temp2 order by a;
+ a  
+----
+ -2
+(1 row)
+
+select relname,  relpages>0, reltuples>0 from pg_class where relname in ('temp1', 'temp2') order by relname;
+ relname | ?column? | ?column? 
+---------+----------+----------
+ temp1   | f        | f
+ temp2   | f        | f
+(2 rows)
+
+select fasttruncate('temp1');
+ fasttruncate 
+--------------
+ 
+(1 row)
+
+select fasttruncate('temp2');
+ fasttruncate 
+--------------
+ 
+(1 row)
+
+select * from temp1 order by a;
+ a 
+---
+(0 rows)
+
+select * from temp2 order by a;
+ a 
+---
+(0 rows)
+
+select relname,  relpages>0, reltuples>0 from pg_class where relname in ('temp1', 'temp2') order by relname;
+ relname | ?column? | ?column? 
+---------+----------+----------
+ temp1   | f        | f
+ temp2   | f        | f
+(2 rows)
+
diff -ruN a/contrib/fasttrun/fasttrun--1.0.sql b/contrib/fasttrun/fasttrun--1.0.sql
--- a/contrib/fasttrun/fasttrun--1.0.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fasttrun/fasttrun--1.0.sql	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,3 @@
+CREATE OR REPLACE FUNCTION fasttruncate(text)
+RETURNS void AS 'MODULE_PATHNAME'
+LANGUAGE C RETURNS NULL ON NULL INPUT VOLATILE;
diff -ruN a/contrib/fasttrun/fasttrun.c b/contrib/fasttrun/fasttrun.c
--- a/contrib/fasttrun/fasttrun.c	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fasttrun/fasttrun.c	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,74 @@
+#include "postgres.h"
+
+#include "access/genam.h"
+#include "access/heapam.h"
+#include "miscadmin.h"
+#include "storage/lmgr.h"
+#include "storage/bufmgr.h"
+#include "catalog/namespace.h"
+#include "utils/lsyscache.h"
+#include "utils/builtins.h"
+#include "utils/varlena.h"
+#include <fmgr.h>
+#include <funcapi.h>
+#include <access/heapam.h>
+#include <catalog/pg_type.h>
+#include <catalog/heap.h>
+#include <commands/vacuum.h>
+
+#ifdef PG_MODULE_MAGIC
+PG_MODULE_MAGIC;
+#endif
+
+PG_FUNCTION_INFO_V1(fasttruncate);
+Datum	fasttruncate(PG_FUNCTION_ARGS);
+Datum	
+fasttruncate(PG_FUNCTION_ARGS) {
+	text    *name=PG_GETARG_TEXT_P(0);
+	List	*relname_list;
+	RangeVar	*relvar;
+	Oid		relOid;
+	Relation	rel;
+	bool	makeanalyze = false;
+
+	relname_list = textToQualifiedNameList(name);
+	elog(LOG,"fast-truncating relation %s",NameListToString(relname_list));
+	relvar = makeRangeVarFromNameList(relname_list);
+	relOid = RangeVarGetRelid(relvar, AccessExclusiveLock, false);
+
+	if ( get_rel_relkind(relOid) != RELKIND_RELATION )
+		elog(ERROR,"Relation isn't a ordinary table");
+
+	rel = heap_open(relOid, NoLock);
+
+	if ( !isTempNamespace(get_rel_namespace(relOid)) )
+		elog(ERROR,"Relation isn't a temporary table");
+
+	heap_truncate(list_make1_oid(relOid));
+
+	if ( rel->rd_rel->relpages > 0 || rel->rd_rel->reltuples > 0 )
+		makeanalyze = true;
+
+	/*
+	 * heap_truncate doesn't unlock the table,
+	 * so we should unlock it.
+	 */
+
+	heap_close(rel, AccessExclusiveLock);
+
+	if ( makeanalyze ) {
+		VacuumParams	params;
+
+		params.freeze_min_age = -1;
+		params.freeze_table_age = -1;
+		params.multixact_freeze_min_age = -1;
+		params.multixact_freeze_table_age = -1;
+		params.is_wraparound = false;
+		params.log_min_duration = -1;
+
+		vacuum(VACOPT_ANALYZE, NULL, relOid, &params, NULL,
+				GetAccessStrategy(BAS_VACUUM), false);
+	}
+
+	PG_RETURN_VOID();
+}
diff -ruN a/contrib/fasttrun/fasttrun.control b/contrib/fasttrun/fasttrun.control
--- a/contrib/fasttrun/fasttrun.control	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fasttrun/fasttrun.control	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,5 @@
+# fasttrun extension
+comment = 'Functions to truncates the temporary table and does not grow pg_class size'
+default_version = '1.0'
+module_pathname = '$libdir/fasttrun'
+relocatable = true
\ No newline at end of file
diff -ruN a/contrib/fasttrun/Makefile b/contrib/fasttrun/Makefile
--- a/contrib/fasttrun/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fasttrun/Makefile	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,17 @@
+MODULE_big = fasttrun
+OBJS = fasttrun.o $(WIN32RES)
+EXTENSION = fasttrun
+DATA = fasttrun--1.0.sql
+DOCS = README.fasttrun
+REGRESS = fasttrun
+PGFIELDDESC = "fasttrun - functions to truncates the temporary table and doesn't grow pg_class size."
+
+ifdef USE_PGXS
+PGXS := $(shell pg_config --pgxs)
+include $(PGXS)
+else
+subdir = contrib/fasttrun
+top_builddir = ../..
+include $(top_builddir)/src/Makefile.global
+include $(top_srcdir)/contrib/contrib-global.mk
+endif
diff -ruN a/contrib/fasttrun/README.fasttrun b/contrib/fasttrun/README.fasttrun
--- a/contrib/fasttrun/README.fasttrun	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fasttrun/README.fasttrun	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,17 @@
+select fasttruncate('TABLE_NAME');
+
+Function truncates the temporary table and doesn't grow
+pg_class size.
+
+Warning: function isn't transaction safe!
+
+For tests:
+create or replace function f() returns void as $$
+begin
+for i in 1..1000
+loop
+         PERFORM fasttruncate('tt1');
+end loop;
+end;
+$$ language plpgsql;
+
diff -ruN a/contrib/fasttrun/sql/fasttrun.sql b/contrib/fasttrun/sql/fasttrun.sql
--- a/contrib/fasttrun/sql/fasttrun.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fasttrun/sql/fasttrun.sql	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,48 @@
+CREATE EXTENSION fasttrun;
+
+create table persist ( a int );
+insert into persist values (1);
+select fasttruncate('persist');
+insert into persist values (2);
+select * from persist order by a;
+
+create temp table temp1 (a int);
+insert into temp1 values (1);
+
+BEGIN;
+
+create temp table temp2 (a int);
+insert into temp2 values (1);
+
+select * from temp1 order by a;
+select * from temp2 order by a;
+
+insert into temp1 (select * from generate_series(1,10000));
+insert into temp2 (select * from generate_series(1,11000));
+
+analyze temp2;
+select relname,  relpages>0, reltuples>0 from pg_class where relname in ('temp1', 'temp2') order by relname;
+
+select fasttruncate('temp1');
+select fasttruncate('temp2');
+
+insert into temp1 values (-2);
+insert into temp2 values (-2);
+
+select * from temp1 order by a;
+select * from temp2 order by a;
+
+COMMIT;
+
+select * from temp1 order by a;
+select * from temp2 order by a;
+
+select relname,  relpages>0, reltuples>0 from pg_class where relname in ('temp1', 'temp2') order by relname;
+
+select fasttruncate('temp1');
+select fasttruncate('temp2');
+
+select * from temp1 order by a;
+select * from temp2 order by a;
+
+select relname,  relpages>0, reltuples>0 from pg_class where relname in ('temp1', 'temp2') order by relname;
diff -ruN a/contrib/fulleq/expected/fulleq.out b/contrib/fulleq/expected/fulleq.out
--- a/contrib/fulleq/expected/fulleq.out	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fulleq/expected/fulleq.out	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,61 @@
+CREATE EXTENSION fulleq;
+select 4::int == 4;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 4::int == 5;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 4::int == NULL;
+ ?column? 
+----------
+ f
+(1 row)
+
+select NULL::int == 5;
+ ?column? 
+----------
+ f
+(1 row)
+
+select NULL::int == NULL;
+ ?column? 
+----------
+ t
+(1 row)
+
+select '4'::text == '4';
+ ?column? 
+----------
+ t
+(1 row)
+
+select '4'::text == '5';
+ ?column? 
+----------
+ f
+(1 row)
+
+select '4'::text == NULL;
+ ?column? 
+----------
+ f
+(1 row)
+
+select NULL::text == '5';
+ ?column? 
+----------
+ f
+(1 row)
+
+select NULL::text == NULL;
+ ?column? 
+----------
+ t
+(1 row)
+
diff -ruN a/contrib/fulleq/fulleq--1.0.sql b/contrib/fulleq/fulleq--1.0.sql
--- a/contrib/fulleq/fulleq--1.0.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fulleq/fulleq--1.0.sql	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,678 @@
+\echo Use "CREATE EXTENSION fulleq" to load this file. \quit
+SET search_path = public;
+-- For bool
+
+CREATE OR REPLACE FUNCTION isfulleq_bool(bool, bool) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_bool(bool)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= bool,
+	RIGHTARG	= bool,
+	PROCEDURE	= isfulleq_bool,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS bool_fill_ops
+ FOR TYPE bool USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_bool(bool);
+
+-- For bytea
+
+CREATE OR REPLACE FUNCTION isfulleq_bytea(bytea, bytea) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_bytea(bytea)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= bytea,
+	RIGHTARG	= bytea,
+	PROCEDURE	= isfulleq_bytea,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS bytea_fill_ops
+ FOR TYPE bytea USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_bytea(bytea);
+
+-- For char
+
+CREATE OR REPLACE FUNCTION isfulleq_char(char, char) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_char(char)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= char,
+	RIGHTARG	= char,
+	PROCEDURE	= isfulleq_char,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS char_fill_ops
+ FOR TYPE char USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_char(char);
+
+-- For name
+
+CREATE OR REPLACE FUNCTION isfulleq_name(name, name) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_name(name)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= name,
+	RIGHTARG	= name,
+	PROCEDURE	= isfulleq_name,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS name_fill_ops
+ FOR TYPE name USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_name(name);
+
+-- For int8
+
+CREATE OR REPLACE FUNCTION isfulleq_int8(int8, int8) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_int8(int8)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= int8,
+	RIGHTARG	= int8,
+	PROCEDURE	= isfulleq_int8,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS int8_fill_ops
+ FOR TYPE int8 USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_int8(int8);
+
+-- For int2
+
+CREATE OR REPLACE FUNCTION isfulleq_int2(int2, int2) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_int2(int2)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= int2,
+	RIGHTARG	= int2,
+	PROCEDURE	= isfulleq_int2,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS int2_fill_ops
+ FOR TYPE int2 USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_int2(int2);
+
+-- For int4
+
+CREATE OR REPLACE FUNCTION isfulleq_int4(int4, int4) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_int4(int4)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= int4,
+	RIGHTARG	= int4,
+	PROCEDURE	= isfulleq_int4,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS int4_fill_ops
+ FOR TYPE int4 USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_int4(int4);
+
+-- For text
+
+CREATE OR REPLACE FUNCTION isfulleq_text(text, text) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_text(text)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= text,
+	RIGHTARG	= text,
+	PROCEDURE	= isfulleq_text,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS text_fill_ops
+ FOR TYPE text USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_text(text);
+
+-- For oid
+
+CREATE OR REPLACE FUNCTION isfulleq_oid(oid, oid) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_oid(oid)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= oid,
+	RIGHTARG	= oid,
+	PROCEDURE	= isfulleq_oid,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS oid_fill_ops
+ FOR TYPE oid USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_oid(oid);
+
+-- For xid
+
+CREATE OR REPLACE FUNCTION isfulleq_xid(xid, xid) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_xid(xid)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= xid,
+	RIGHTARG	= xid,
+	PROCEDURE	= isfulleq_xid,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS xid_fill_ops
+ FOR TYPE xid USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_xid(xid);
+
+-- For cid
+
+CREATE OR REPLACE FUNCTION isfulleq_cid(cid, cid) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_cid(cid)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= cid,
+	RIGHTARG	= cid,
+	PROCEDURE	= isfulleq_cid,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS cid_fill_ops
+ FOR TYPE cid USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_cid(cid);
+
+-- For oidvector
+
+CREATE OR REPLACE FUNCTION isfulleq_oidvector(oidvector, oidvector) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_oidvector(oidvector)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= oidvector,
+	RIGHTARG	= oidvector,
+	PROCEDURE	= isfulleq_oidvector,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS oidvector_fill_ops
+ FOR TYPE oidvector USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_oidvector(oidvector);
+
+-- For float4
+
+CREATE OR REPLACE FUNCTION isfulleq_float4(float4, float4) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_float4(float4)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= float4,
+	RIGHTARG	= float4,
+	PROCEDURE	= isfulleq_float4,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS float4_fill_ops
+ FOR TYPE float4 USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_float4(float4);
+
+-- For float8
+
+CREATE OR REPLACE FUNCTION isfulleq_float8(float8, float8) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_float8(float8)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= float8,
+	RIGHTARG	= float8,
+	PROCEDURE	= isfulleq_float8,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS float8_fill_ops
+ FOR TYPE float8 USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_float8(float8);
+
+-- For abstime
+
+CREATE OR REPLACE FUNCTION isfulleq_abstime(abstime, abstime) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_abstime(abstime)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= abstime,
+	RIGHTARG	= abstime,
+	PROCEDURE	= isfulleq_abstime,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS abstime_fill_ops
+ FOR TYPE abstime USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_abstime(abstime);
+
+-- For reltime
+
+CREATE OR REPLACE FUNCTION isfulleq_reltime(reltime, reltime) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_reltime(reltime)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= reltime,
+	RIGHTARG	= reltime,
+	PROCEDURE	= isfulleq_reltime,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS reltime_fill_ops
+ FOR TYPE reltime USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_reltime(reltime);
+
+-- For macaddr
+
+CREATE OR REPLACE FUNCTION isfulleq_macaddr(macaddr, macaddr) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_macaddr(macaddr)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= macaddr,
+	RIGHTARG	= macaddr,
+	PROCEDURE	= isfulleq_macaddr,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS macaddr_fill_ops
+ FOR TYPE macaddr USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_macaddr(macaddr);
+
+-- For inet
+
+CREATE OR REPLACE FUNCTION isfulleq_inet(inet, inet) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_inet(inet)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= inet,
+	RIGHTARG	= inet,
+	PROCEDURE	= isfulleq_inet,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS inet_fill_ops
+ FOR TYPE inet USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_inet(inet);
+
+-- For cidr
+
+CREATE OR REPLACE FUNCTION isfulleq_cidr(cidr, cidr) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_cidr(cidr)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= cidr,
+	RIGHTARG	= cidr,
+	PROCEDURE	= isfulleq_cidr,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS cidr_fill_ops
+ FOR TYPE cidr USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_cidr(cidr);
+
+-- For varchar
+
+CREATE OR REPLACE FUNCTION isfulleq_varchar(varchar, varchar) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_varchar(varchar)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= varchar,
+	RIGHTARG	= varchar,
+	PROCEDURE	= isfulleq_varchar,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS varchar_fill_ops
+ FOR TYPE varchar USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_varchar(varchar);
+
+-- For date
+
+CREATE OR REPLACE FUNCTION isfulleq_date(date, date) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_date(date)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= date,
+	RIGHTARG	= date,
+	PROCEDURE	= isfulleq_date,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS date_fill_ops
+ FOR TYPE date USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_date(date);
+
+-- For time
+
+CREATE OR REPLACE FUNCTION isfulleq_time(time, time) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_time(time)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= time,
+	RIGHTARG	= time,
+	PROCEDURE	= isfulleq_time,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS time_fill_ops
+ FOR TYPE time USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_time(time);
+
+-- For timestamp
+
+CREATE OR REPLACE FUNCTION isfulleq_timestamp(timestamp, timestamp) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_timestamp(timestamp)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= timestamp,
+	RIGHTARG	= timestamp,
+	PROCEDURE	= isfulleq_timestamp,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS timestamp_fill_ops
+ FOR TYPE timestamp USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_timestamp(timestamp);
+
+-- For timestamptz
+
+CREATE OR REPLACE FUNCTION isfulleq_timestamptz(timestamptz, timestamptz) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_timestamptz(timestamptz)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= timestamptz,
+	RIGHTARG	= timestamptz,
+	PROCEDURE	= isfulleq_timestamptz,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS timestamptz_fill_ops
+ FOR TYPE timestamptz USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_timestamptz(timestamptz);
+
+-- For interval
+
+CREATE OR REPLACE FUNCTION isfulleq_interval(interval, interval) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_interval(interval)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= interval,
+	RIGHTARG	= interval,
+	PROCEDURE	= isfulleq_interval,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS interval_fill_ops
+ FOR TYPE interval USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_interval(interval);
+
+-- For timetz
+
+CREATE OR REPLACE FUNCTION isfulleq_timetz(timetz, timetz) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_timetz(timetz)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= timetz,
+	RIGHTARG	= timetz,
+	PROCEDURE	= isfulleq_timetz,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS timetz_fill_ops
+ FOR TYPE timetz USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_timetz(timetz);
+
diff -ruN a/contrib/fulleq/fulleq--1.0.sql.in.in b/contrib/fulleq/fulleq--1.0.sql.in.in
--- a/contrib/fulleq/fulleq--1.0.sql.in.in	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fulleq/fulleq--1.0.sql.in.in	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,26 @@
+-- For ARGTYPE
+
+CREATE OR REPLACE FUNCTION isfulleq_ARGTYPE(ARGTYPE, ARGTYPE) 
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_ARGTYPE(ARGTYPE)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+	LEFTARG		= ARGTYPE,
+	RIGHTARG	= ARGTYPE,
+	PROCEDURE	= isfulleq_ARGTYPE,
+	COMMUTATOR	= '==',
+	RESTRICT	= eqsel,
+	JOIN		= eqjoinsel,
+	HASHES
+);
+
+CREATE OPERATOR CLASS ARGTYPE_fill_ops
+ FOR TYPE ARGTYPE USING hash AS
+	OPERATOR	1	==,
+	FUNCTION	1	fullhash_ARGTYPE(ARGTYPE);
+
diff -ruN a/contrib/fulleq/fulleq.c b/contrib/fulleq/fulleq.c
--- a/contrib/fulleq/fulleq.c	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fulleq/fulleq.c	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,74 @@
+#include "postgres.h"
+#include "fmgr.h"
+#include "access/hash.h"
+#include "utils/builtins.h"
+#include "utils/bytea.h"
+#include "utils/int8.h"
+#include "utils/nabstime.h"
+#include "utils/timestamp.h"
+#include "utils/date.h"
+
+#ifdef PG_MODULE_MAGIC
+PG_MODULE_MAGIC;
+#endif
+
+#define	NULLHASHVALUE		(-2147483647)
+
+#define	FULLEQ_FUNC(type, cmpfunc, hashfunc)			\
+PG_FUNCTION_INFO_V1( isfulleq_##type );					\
+Datum	isfulleq_##type(PG_FUNCTION_ARGS);				\
+Datum													\
+isfulleq_##type(PG_FUNCTION_ARGS) {						\
+	if ( PG_ARGISNULL(0) && PG_ARGISNULL(1) )			\
+		PG_RETURN_BOOL(true);							\
+	else if ( PG_ARGISNULL(0) || PG_ARGISNULL(1) )		\
+		PG_RETURN_BOOL(false);							\
+														\
+	PG_RETURN_DATUM( DirectFunctionCall2( cmpfunc,		\
+			PG_GETARG_DATUM(0),							\
+			PG_GETARG_DATUM(1)							\
+	) );												\
+}														\
+														\
+PG_FUNCTION_INFO_V1( fullhash_##type );					\
+Datum	fullhash_##type(PG_FUNCTION_ARGS);				\
+Datum													\
+fullhash_##type(PG_FUNCTION_ARGS) {						\
+	if ( PG_ARGISNULL(0) )								\
+		PG_RETURN_INT32(NULLHASHVALUE);					\
+														\
+	PG_RETURN_DATUM( DirectFunctionCall1( hashfunc,		\
+			PG_GETARG_DATUM(0)							\
+	) );												\
+}
+
+
+FULLEQ_FUNC( bool        , booleq         , hashchar       );
+FULLEQ_FUNC( bytea       , byteaeq        , hashvarlena    );
+FULLEQ_FUNC( char        , chareq         , hashchar       );
+FULLEQ_FUNC( name        , nameeq         , hashname       );
+FULLEQ_FUNC( int8        , int8eq         , hashint8       );
+FULLEQ_FUNC( int2        , int2eq         , hashint2       );
+/* FULLEQ_FUNC( int2vector  , int2vectoreq   , hashint2vector );v10 drop
+ * support for int2vector equality and hash operator in commit
+ * 5c80642aa8de8393b08cd3cbf612b325cedd98dc */
+FULLEQ_FUNC( int4        , int4eq         , hashint4       );
+FULLEQ_FUNC( text        , texteq         , hashtext       );
+FULLEQ_FUNC( oid         , oideq          , hashoid        );
+FULLEQ_FUNC( xid         , xideq          , hashint4       );
+FULLEQ_FUNC( cid         , cideq          , hashint4       );
+FULLEQ_FUNC( oidvector   , oidvectoreq    , hashoidvector  );
+FULLEQ_FUNC( float4      , float4eq       , hashfloat4     );
+FULLEQ_FUNC( float8      , float8eq       , hashfloat8     );
+FULLEQ_FUNC( abstime     , abstimeeq      , hashint4       );
+FULLEQ_FUNC( reltime     , reltimeeq      , hashint4       );
+FULLEQ_FUNC( macaddr     , macaddr_eq     , hashmacaddr    );
+FULLEQ_FUNC( inet        , network_eq     , hashinet       );
+FULLEQ_FUNC( cidr        , network_eq     , hashinet       );
+FULLEQ_FUNC( varchar     , texteq         , hashtext       );
+FULLEQ_FUNC( date        , date_eq        , hashint4       );
+FULLEQ_FUNC( time        , time_eq        , hashfloat8     );
+FULLEQ_FUNC( timestamp   , timestamp_eq   , hashfloat8     );
+FULLEQ_FUNC( timestamptz , timestamp_eq   , hashfloat8     );
+FULLEQ_FUNC( interval    , interval_eq    , interval_hash  );
+FULLEQ_FUNC( timetz      , timetz_eq      , timetz_hash    );
diff -ruN a/contrib/fulleq/fulleq.control b/contrib/fulleq/fulleq.control
--- a/contrib/fulleq/fulleq.control	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fulleq/fulleq.control	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,5 @@
+# fulleq extension
+comment = 'Introduce operator == which returns true when operands are equal or both are nulls.'
+default_version = '1.0'
+module_pathname = '$libdir/fulleq'
+relocatable = true
\ No newline at end of file
diff -ruN a/contrib/fulleq/Makefile b/contrib/fulleq/Makefile
--- a/contrib/fulleq/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fulleq/Makefile	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,33 @@
+MODULE_big = fulleq
+OBJS = fulleq.o	
+EXTENSION = fulleq
+DATA = fulleq--1.0.sql
+DOCS = README.fulleq
+REGRESS = fulleq
+PGFIELDDESC = "fulleq - introduce operator == which returns true when operands are equal or both are nulls."
+
+ARGTYPE = bool bytea char name int8 int2 int4 text \
+	oid xid cid oidvector float4 float8 abstime reltime macaddr \
+	inet cidr varchar date time timestamp timestamptz \
+	interval timetz
+
+#EXTRA_CLEAN = fulleq--1.0.sql
+
+ifdef USE_PGXS
+PGXS := $(shell pg_config --pgxs)
+include $(PGXS)
+else
+subdir = contrib/fulleq
+top_builddir = ../..
+include $(top_builddir)/src/Makefile.global
+include $(top_srcdir)/contrib/contrib-global.mk
+endif
+
+fulleq--1.0.sql:	fulleq--1.0.sql.in.in
+	echo '\echo Use "CREATE EXTENSION fulleq" to load this file. \quit' >	$@
+	echo 'SET search_path = public;' >> $@
+	for type in	$(ARGTYPE);	\
+	do	\
+		sed -e "s/ARGTYPE/$$type/g" < $< >> $@;	\
+	done
+
diff -ruN a/contrib/fulleq/README.fulleq b/contrib/fulleq/README.fulleq
--- a/contrib/fulleq/README.fulleq	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fulleq/README.fulleq	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,3 @@
+Introduce operator == which returns true when
+operands are equal or both are nulls.
+
diff -ruN a/contrib/fulleq/sql/fulleq.sql b/contrib/fulleq/sql/fulleq.sql
--- a/contrib/fulleq/sql/fulleq.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/fulleq/sql/fulleq.sql	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,14 @@
+CREATE EXTENSION fulleq;
+
+select 4::int == 4;
+select 4::int == 5;
+select 4::int == NULL;
+select NULL::int == 5;
+select NULL::int == NULL;
+
+select '4'::text == '4';
+select '4'::text == '5';
+select '4'::text == NULL;
+select NULL::text == '5';
+select NULL::text == NULL;
+
diff -ruN a/contrib/Makefile b/contrib/Makefile
--- a/contrib/Makefile	2017-12-28 14:57:41.807569550 +0300
+++ b/contrib/Makefile	2017-12-28 14:58:03.463305255 +0300
@@ -19,7 +19,9 @@
 		dict_int	\
 		dict_xsyn	\
 		earthdistance	\
+		fasttrun	\
 		file_fdw	\
+		fulleq		\
 		fuzzystrmatch	\
 		hstore		\
 		intagg		\
@@ -28,6 +30,7 @@
 		lo		\
 		ltree		\
 		oid2name	\
+		online_analyze	\
 		pageinspect	\
 		passwordcheck	\
 		pg_buffercache	\
@@ -40,6 +43,7 @@
 		pgrowlocks	\
 		pgstattuple	\
 		pg_visibility	\
+		plantuner	\
 		postgres_fdw	\
 		seg		\
 		spi		\
@@ -87,6 +91,12 @@
 ALWAYS_SUBDIRS += hstore_plpython ltree_plpython
 endif
 
+ifeq ($(with_icu),yes)
+SUBDIRS += mchar
+else
+ALWAYS_SUBDIRS += mchar
+endif
+
 # Missing:
 #		start-scripts	\ (does not have a makefile)
 
diff -ruN a/contrib/mchar/Changes b/contrib/mchar/Changes
--- a/contrib/mchar/Changes	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/Changes	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,19 @@
+0.17  add == operation:
+		a == b   =>   ( a = b or a is null and b is null )
+0.16  fix pg_dump - now mchar in pg_catalog scheme, not public
+ 	  fix bug in mvarchar_substr()
+0.15  add upper()/lower()
+0.14  Add ESCAPE for LIKE, SIMILAR TO [ESCAPE], POSIX regexp 
+0.13  Outer binary format is now different from
+	  inner: it's just a UTF-16 string
+0.12  Fix copy binary
+0.11  Force UTF-8 convertor if server_encoding='UTF8'
+0.10  add (mchar|mvarchar)_(send|recv) functions to
+      allow binary copying. Note: that functions
+	  don't recode values.
+0.9	index support for like, improve recoding functions
+0.8 initial suport for like optimizioation with index:
+    still thres no algo to find the nearest greater string
+0.7	hash indexes and enable a hash joins
+0.6	implicit casting mchar-mvarchar
+	cross type comparison operations
diff -ruN a/contrib/mchar/expected/compat.out b/contrib/mchar/expected/compat.out
--- a/contrib/mchar/expected/compat.out	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/expected/compat.out	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,66 @@
+--- table based checks
+select '<' || ch || '>', '<' || vch || '>' from chvch;
+    ?column?    |   ?column?   
+----------------+--------------
+ <No spaces   > | <No spaces>
+ <One space   > | <One space >
+ <1 space     > | <1 space >
+(3 rows)
+
+select * from chvch where vch = 'One space';
+      ch      |    vch     
+--------------+------------
+ One space    | One space 
+(1 row)
+
+select * from chvch where vch = 'One space ';
+      ch      |    vch     
+--------------+------------
+ One space    | One space 
+(1 row)
+
+select * from ch where chcol = 'abcd' order by chcol;
+              chcol               
+----------------------------------
+ abcd                            
+ AbcD                            
+(2 rows)
+
+select * from ch t1 join ch t2 on t1.chcol = t2.chcol order by t1.chcol, t2.chcol;
+              chcol               |              chcol               
+----------------------------------+----------------------------------
+ abcd                             | AbcD                            
+ abcd                             | abcd                            
+ AbcD                             | AbcD                            
+ AbcD                             | abcd                            
+ abcz                             | abcz                            
+ defg                             | dEfg                            
+ defg                             | defg                            
+ dEfg                             | dEfg                            
+ dEfg                             | defg                            
+ ee                               | Ee                              
+ ee                               | ee                              
+ Ee                               | Ee                              
+ Ee                               | ee                              
+(13 rows)
+
+select * from ch where chcol > 'abcd' and chcol<'ee';
+              chcol               
+----------------------------------
+ abcz                            
+ defg                            
+ dEfg                            
+(3 rows)
+
+select * from ch order by chcol;
+              chcol               
+----------------------------------
+ abcd                            
+ AbcD                            
+ abcz                            
+ defg                            
+ dEfg                            
+ ee                              
+ Ee                              
+(7 rows)
+
diff -ruN a/contrib/mchar/expected/init.out b/contrib/mchar/expected/init.out
--- a/contrib/mchar/expected/init.out	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/expected/init.out	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,19 @@
+CREATE EXTENSION mchar;
+SET search_path = public;
+create table ch (
+	chcol mchar(32)
+) without oids;
+insert into ch values('abcd');
+insert into ch values('AbcD');
+insert into ch values('abcz');
+insert into ch values('defg');
+insert into ch values('dEfg');
+insert into ch values('ee');
+insert into ch values('Ee');
+create table chvch (
+    ch      mchar(12),
+	vch     mvarchar(12)
+) without oids;
+insert into chvch values('No spaces', 'No spaces');
+insert into chvch values('One space ', 'One space ');
+insert into chvch values('1 space', '1 space ');
diff -ruN a/contrib/mchar/expected/like.out b/contrib/mchar/expected/like.out
--- a/contrib/mchar/expected/like.out	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/expected/like.out	2017-12-28 14:58:03.463305255 +0300
@@ -0,0 +1,791 @@
+-- simplest examples
+-- E061-04 like predicate
+SELECT 'hawkeye'::mchar LIKE 'h%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mchar NOT LIKE 'h%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye'::mchar LIKE 'H%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mchar NOT LIKE 'H%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye'::mchar LIKE 'indio%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye'::mchar NOT LIKE 'indio%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mchar LIKE 'h%eye' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mchar NOT LIKE 'h%eye' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mchar LIKE '_ndio' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio'::mchar NOT LIKE '_ndio' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mchar LIKE 'in__o' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio'::mchar NOT LIKE 'in__o' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mchar LIKE 'in_o' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mchar NOT LIKE 'in_o' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mvarchar LIKE 'h%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mvarchar NOT LIKE 'h%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye'::mvarchar LIKE 'H%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mvarchar NOT LIKE 'H%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye'::mvarchar LIKE 'indio%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye'::mvarchar NOT LIKE 'indio%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mvarchar LIKE 'h%eye' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mvarchar NOT LIKE 'h%eye' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mvarchar LIKE '_ndio' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio'::mvarchar NOT LIKE '_ndio' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mvarchar LIKE 'in__o' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio'::mvarchar NOT LIKE 'in__o' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mvarchar LIKE 'in_o' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mvarchar NOT LIKE 'in_o' AS "true";
+ true 
+------
+ t
+(1 row)
+
+-- unused escape character
+SELECT 'hawkeye'::mchar LIKE 'h%'::mchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mchar NOT LIKE 'h%'::mchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mchar LIKE 'ind_o'::mchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio'::mchar NOT LIKE 'ind_o'::mchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+-- escape character
+-- E061-05 like predicate with escape clause
+SELECT 'h%'::mchar LIKE 'h#%'::mchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%'::mchar NOT LIKE 'h#%'::mchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%wkeye'::mchar LIKE 'h#%'::mchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%wkeye'::mchar NOT LIKE 'h#%'::mchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%wkeye'::mchar LIKE 'h#%%'::mchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%wkeye'::mchar NOT LIKE 'h#%%'::mchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%awkeye'::mchar LIKE 'h#%a%k%e'::mchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%awkeye'::mchar NOT LIKE 'h#%a%k%e'::mchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mchar LIKE '_ndio'::mchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio'::mchar NOT LIKE '_ndio'::mchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'i_dio'::mchar LIKE 'i$_d_o'::mchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'i_dio'::mchar NOT LIKE 'i$_d_o'::mchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'i_dio'::mchar LIKE 'i$_nd_o'::mchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'i_dio'::mchar NOT LIKE 'i$_nd_o'::mchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'i_dio'::mchar LIKE 'i$_d%o'::mchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'i_dio'::mchar NOT LIKE 'i$_d%o'::mchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+-- escape character same as pattern character
+SELECT 'maca'::mchar LIKE 'm%aca' ESCAPE '%'::mchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'maca'::mchar NOT LIKE 'm%aca' ESCAPE '%'::mchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'ma%a'::mchar LIKE 'm%a%%a' ESCAPE '%'::mchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'ma%a'::mchar NOT LIKE 'm%a%%a' ESCAPE '%'::mchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'bear'::mchar LIKE 'b_ear' ESCAPE '_'::mchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'bear'::mchar NOT LIKE 'b_ear'::mchar ESCAPE '_' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'be_r'::mchar LIKE 'b_e__r' ESCAPE '_'::mchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'be_r'::mchar NOT LIKE 'b_e__r' ESCAPE '_'::mchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'be_r'::mchar LIKE '__e__r' ESCAPE '_'::mchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'be_r'::mchar NOT LIKE '__e__r'::mchar ESCAPE '_' AS "true";
+ true 
+------
+ t
+(1 row)
+
+-- unused escape character
+SELECT 'hawkeye'::mvarchar LIKE 'h%'::mvarchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye'::mvarchar NOT LIKE 'h%'::mvarchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mvarchar LIKE 'ind_o'::mvarchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio'::mvarchar NOT LIKE 'ind_o'::mvarchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+-- escape character
+-- E061-05 like predicate with escape clause
+SELECT 'h%'::mvarchar LIKE 'h#%'::mvarchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%'::mvarchar NOT LIKE 'h#%'::mvarchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%wkeye'::mvarchar LIKE 'h#%'::mvarchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%wkeye'::mvarchar NOT LIKE 'h#%'::mvarchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%wkeye'::mvarchar LIKE 'h#%%'::mvarchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%wkeye'::mvarchar NOT LIKE 'h#%%'::mvarchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%awkeye'::mvarchar LIKE 'h#%a%k%e'::mvarchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%awkeye'::mvarchar NOT LIKE 'h#%a%k%e'::mvarchar ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio'::mvarchar LIKE '_ndio'::mvarchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio'::mvarchar NOT LIKE '_ndio'::mvarchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'i_dio'::mvarchar LIKE 'i$_d_o'::mvarchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'i_dio'::mvarchar NOT LIKE 'i$_d_o'::mvarchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'i_dio'::mvarchar LIKE 'i$_nd_o'::mvarchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'i_dio'::mvarchar NOT LIKE 'i$_nd_o'::mvarchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'i_dio'::mvarchar LIKE 'i$_d%o'::mvarchar ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'i_dio'::mvarchar NOT LIKE 'i$_d%o'::mvarchar ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+-- escape character same as pattern character
+SELECT 'maca'::mvarchar LIKE 'm%aca' ESCAPE '%'::mvarchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'maca'::mvarchar NOT LIKE 'm%aca' ESCAPE '%'::mvarchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'ma%a'::mvarchar LIKE 'm%a%%a' ESCAPE '%'::mvarchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'ma%a'::mvarchar NOT LIKE 'm%a%%a' ESCAPE '%'::mvarchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'bear'::mvarchar LIKE 'b_ear' ESCAPE '_'::mvarchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'bear'::mvarchar NOT LIKE 'b_ear'::mvarchar ESCAPE '_' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'be_r'::mvarchar LIKE 'b_e__r' ESCAPE '_'::mvarchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'be_r'::mvarchar NOT LIKE 'b_e__r' ESCAPE '_'::mvarchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'be_r'::mvarchar LIKE '__e__r' ESCAPE '_'::mvarchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'be_r'::mvarchar NOT LIKE '__e__r'::mvarchar ESCAPE '_' AS "true";
+ true 
+------
+ t
+(1 row)
+
+-- similar to
+SELECT 'abc'::mchar SIMILAR TO 'abc'::mchar   AS   "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'abc'::mchar SIMILAR TO 'a'::mchar      AS  "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'abc'::mchar SIMILAR TO '%(b|d)%'::mchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'abc'::mchar SIMILAR TO '(b|c)%'::mchar AS  "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%'::mchar SIMILAR TO 'h#%'::mchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%'::mchar SIMILAR TO 'h#%'::mchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'abc'::mvarchar SIMILAR TO 'abc'::mvarchar   AS   "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'abc'::mvarchar SIMILAR TO 'a'::mvarchar      AS  "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'abc'::mvarchar SIMILAR TO '%(b|d)%'::mvarchar AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'abc'::mvarchar SIMILAR TO '(b|c)%'::mvarchar AS  "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%'::mvarchar SIMILAR TO 'h#%'::mvarchar AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%'::mvarchar SIMILAR TO 'h#%'::mvarchar ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+-- index support
+SELECT * from ch where chcol like 'aB_d' order by chcol using &<;
+              chcol               
+----------------------------------
+ AbcD                            
+ abcd                            
+(2 rows)
+
+SELECT * from ch where chcol like 'aB%d' order by chcol using &<;
+              chcol               
+----------------------------------
+ AbcD                            
+ abcd                            
+(2 rows)
+
+SELECT * from ch where chcol like 'aB%' order by chcol using &<;
+              chcol               
+----------------------------------
+ AbcD                            
+ abcd                            
+ abcz                            
+(3 rows)
+
+SELECT * from ch where chcol like '%BC%' order by chcol using &<;
+              chcol               
+----------------------------------
+ AbcD                            
+ abcd                            
+ abcz                            
+(3 rows)
+
+set enable_seqscan = off;
+SELECT * from ch where chcol like 'aB_d' order by chcol using &<;
+              chcol               
+----------------------------------
+ AbcD                            
+ abcd                            
+(2 rows)
+
+SELECT * from ch where chcol like 'aB%d' order by chcol using &<;
+              chcol               
+----------------------------------
+ AbcD                            
+ abcd                            
+(2 rows)
+
+SELECT * from ch where chcol like 'aB%' order by chcol using &<;
+              chcol               
+----------------------------------
+ AbcD                            
+ abcd                            
+ abcz                            
+(3 rows)
+
+SELECT * from ch where chcol like '%BC%' order by chcol using &<;
+              chcol               
+----------------------------------
+ AbcD                            
+ abcd                            
+ abcz                            
+(3 rows)
+
+set enable_seqscan = on;
+create table testt (f1 mchar(10));
+insert into testt values ('Abc-000001');
+insert into testt values ('Abc-000002');
+insert into testt values ('0000000001');
+insert into testt values ('0000000002');
+select f1 from testt where f1::mvarchar like E'Abc\\-%'::mvarchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+select * from testt where f1::mchar like E'Abc\\-%'::mchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+create index testindex on testt(f1);
+set enable_seqscan=off;
+select f1 from testt where f1::mvarchar like E'Abc\\-%'::mvarchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+select * from testt where f1::mchar like E'Abc\\-%'::mchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+set enable_seqscan = on;
+drop table testt;
+create table testt (f1 mvarchar(10));
+insert into testt values ('Abc-000001');
+insert into testt values ('Abc-000002');
+insert into testt values ('0000000001');
+insert into testt values ('0000000002');
+select f1 from testt where f1::mvarchar like E'Abc\\-%'::mvarchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+select * from testt where f1::mchar like E'Abc\\-%'::mchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+select * from testt where f1::mchar like E'Abc\\-  %'::mchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+select * from testt where f1::mchar like E'   %'::mchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+ 0000000001
+ 0000000002
+(4 rows)
+
+create index testindex on testt(f1);
+set enable_seqscan=off;
+select f1 from testt where f1::mvarchar like E'Abc\\-%'::mvarchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+select * from testt where f1::mchar like E'Abc\\-%'::mchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+select * from testt where f1::mchar like E'Abc\\-   %'::mchar;
+     f1     
+------------
+ Abc-000001
+ Abc-000002
+(2 rows)
+
+select * from testt where f1::mchar like E'   %'::mchar;
+     f1     
+------------
+ 0000000001
+ 0000000002
+ Abc-000001
+ Abc-000002
+(4 rows)
+
+set enable_seqscan = on;
+drop table testt;
+CREATE TABLE test ( code mchar(5) NOT NULL );
+insert into test values('1111 ');
+insert into test values('111  ');
+insert into test values('11   ');
+insert into test values('1    ');
+SELECT * FROM test WHERE code LIKE ('%    ');
+ code  
+-------
+ 1    
+(1 row)
+
diff -ruN a/contrib/mchar/expected/mchar.out b/contrib/mchar/expected/mchar.out
--- a/contrib/mchar/expected/mchar.out	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/expected/mchar.out	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,363 @@
+-- I/O tests
+select '1'::mchar;
+ mchar 
+-------
+ 1
+(1 row)
+
+select '2  '::mchar;
+ mchar 
+-------
+ 2
+(1 row)
+
+select '10          '::mchar;
+ mchar 
+-------
+ 10
+(1 row)
+
+select '1'::mchar(2);
+ mchar 
+-------
+ 1 
+(1 row)
+
+select '2 '::mchar(2);
+ mchar 
+-------
+ 2 
+(1 row)
+
+select '3  '::mchar(2);
+ mchar 
+-------
+ 3 
+(1 row)
+
+select '10          '::mchar(2);
+ mchar 
+-------
+ 10
+(1 row)
+
+select '                  '::mchar(10); 
+   mchar    
+------------
+           
+(1 row)
+
+select '                  '::mchar; 
+ mchar 
+-------
+ 
+(1 row)
+
+-- operations & functions
+select length('1'::mchar);
+ length 
+--------
+      1
+(1 row)
+
+select length('2  '::mchar);
+ length 
+--------
+      1
+(1 row)
+
+select length('10          '::mchar);
+ length 
+--------
+      2
+(1 row)
+
+select length('1'::mchar(2));
+ length 
+--------
+      1
+(1 row)
+
+select length('2 '::mchar(2));
+ length 
+--------
+      1
+(1 row)
+
+select length('3  '::mchar(2));
+ length 
+--------
+      1
+(1 row)
+
+select length('10          '::mchar(2));
+ length 
+--------
+      2
+(1 row)
+
+select length('                  '::mchar(10)); 
+ length 
+--------
+      0
+(1 row)
+
+select length('                  '::mchar); 
+ length 
+--------
+      0
+(1 row)
+
+select 'asd'::mchar(10) || '>'::mchar(10);
+       ?column?       
+----------------------
+ asd       >         
+(1 row)
+
+select length('asd'::mchar(10) || '>'::mchar(10));
+ length 
+--------
+     11
+(1 row)
+
+select 'asd'::mchar(2)  || '>'::mchar(10);
+   ?column?   
+--------------
+ as>         
+(1 row)
+
+select length('asd'::mchar(2) || '>'::mchar(10));
+ length 
+--------
+      3
+(1 row)
+
+-- Comparisons
+select 'asdf'::mchar = 'aSdf'::mchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar = 'aSdf '::mchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar = 'aSdf 1'::mchar(4);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar = 'aSdf 1'::mchar(5);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar = 'aSdf 1'::mchar(6);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar(3) = 'aSdf 1'::mchar(5);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar(3) = 'aSdf 1'::mchar(3);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar < 'aSdf'::mchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar < 'aSdf '::mchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar < 'aSdf 1'::mchar(4);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar < 'aSdf 1'::mchar(5);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar < 'aSdf 1'::mchar(6);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar <= 'aSdf'::mchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar <= 'aSdf '::mchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar <= 'aSdf 1'::mchar(4);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar <= 'aSdf 1'::mchar(5);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar <= 'aSdf 1'::mchar(6);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar >= 'aSdf'::mchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar >= 'aSdf '::mchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar >= 'aSdf 1'::mchar(4);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar >= 'aSdf 1'::mchar(5);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mchar >= 'aSdf 1'::mchar(6);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar > 'aSdf'::mchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar > 'aSdf '::mchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar > 'aSdf 1'::mchar(4);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar > 'aSdf 1'::mchar(5);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mchar > 'aSdf 1'::mchar(6);
+ ?column? 
+----------
+ f
+(1 row)
+
+select max(ch) from chvch;
+     max      
+--------------
+ One space   
+(1 row)
+
+select min(ch) from chvch;
+     min      
+--------------
+ 1 space     
+(1 row)
+
+select substr('1234567890'::mchar, 3) = '34567890' as "34567890";
+ 34567890 
+----------
+ f
+(1 row)
+
+select substr('1234567890'::mchar, 4, 3) = '456' as "456";
+ 456 
+-----
+ t
+(1 row)
+
+select lower('asdfASDF'::mchar);
+  lower   
+----------
+ asdfasdf
+(1 row)
+
+select upper('asdfASDF'::mchar);
+  upper   
+----------
+ ASDFASDF
+(1 row)
+
+select 'asd'::mchar == 'aSd'::mchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asd'::mchar == 'aCd'::mchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asd'::mchar == NULL;
+ ?column? 
+----------
+ f
+(1 row)
+
+select NULL == 'aCd'::mchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select NULL::mchar == NULL;
+ ?column? 
+----------
+ t
+(1 row)
+
diff -ruN a/contrib/mchar/expected/mm.out b/contrib/mchar/expected/mm.out
--- a/contrib/mchar/expected/mm.out	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/expected/mm.out	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,805 @@
+select 'asd'::mchar::mvarchar;
+ mvarchar 
+----------
+ asd
+(1 row)
+
+select 'asd '::mchar::mvarchar;
+ mvarchar 
+----------
+ asd
+(1 row)
+
+select 'asd'::mchar(2)::mvarchar;
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd '::mchar(2)::mvarchar;
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd'::mchar(5)::mvarchar;
+ mvarchar 
+----------
+ asd  
+(1 row)
+
+select 'asd '::mchar(5)::mvarchar;
+ mvarchar 
+----------
+ asd  
+(1 row)
+
+select 'asd'::mchar::mvarchar(2);
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd '::mchar::mvarchar(2);
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd'::mchar(2)::mvarchar(2);
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd '::mchar(2)::mvarchar(2);
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd'::mchar(5)::mvarchar(2);
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd '::mchar(5)::mvarchar(2);
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd'::mchar::mvarchar(5);
+ mvarchar 
+----------
+ asd
+(1 row)
+
+select 'asd '::mchar::mvarchar(5);
+ mvarchar 
+----------
+ asd
+(1 row)
+
+select 'asd'::mchar(2)::mvarchar(5);
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd '::mchar(2)::mvarchar(5);
+ mvarchar 
+----------
+ as
+(1 row)
+
+select 'asd'::mchar(5)::mvarchar(5);
+ mvarchar 
+----------
+ asd  
+(1 row)
+
+select 'asd '::mchar(5)::mvarchar(5);
+ mvarchar 
+----------
+ asd  
+(1 row)
+
+select 'asd'::mvarchar::mchar;
+ mchar 
+-------
+ asd
+(1 row)
+
+select 'asd '::mvarchar::mchar;
+ mchar 
+-------
+ asd
+(1 row)
+
+select 'asd'::mvarchar(2)::mchar;
+ mchar 
+-------
+ as
+(1 row)
+
+select 'asd '::mvarchar(2)::mchar;
+ mchar 
+-------
+ as
+(1 row)
+
+select 'asd'::mvarchar(5)::mchar;
+ mchar 
+-------
+ asd
+(1 row)
+
+select 'asd '::mvarchar(5)::mchar;
+ mchar 
+-------
+ asd
+(1 row)
+
+select 'asd'::mvarchar::mchar(2);
+ mchar 
+-------
+ as
+(1 row)
+
+select 'asd '::mvarchar::mchar(2);
+ mchar 
+-------
+ as
+(1 row)
+
+select 'asd'::mvarchar(2)::mchar(2);
+ mchar 
+-------
+ as
+(1 row)
+
+select 'asd '::mvarchar(2)::mchar(2);
+ mchar 
+-------
+ as
+(1 row)
+
+select 'asd'::mvarchar(5)::mchar(2);
+ mchar 
+-------
+ as
+(1 row)
+
+select 'asd '::mvarchar(5)::mchar(2);
+ mchar 
+-------
+ as
+(1 row)
+
+select 'asd'::mvarchar::mchar(5);
+ mchar 
+-------
+ asd  
+(1 row)
+
+select 'asd '::mvarchar::mchar(5);
+ mchar 
+-------
+ asd  
+(1 row)
+
+select 'asd'::mvarchar(2)::mchar(5);
+ mchar 
+-------
+ as   
+(1 row)
+
+select 'asd '::mvarchar(2)::mchar(5);
+ mchar 
+-------
+ as   
+(1 row)
+
+select 'asd'::mvarchar(5)::mchar(5);
+ mchar 
+-------
+ asd  
+(1 row)
+
+select 'asd '::mvarchar(5)::mchar(5);
+ mchar 
+-------
+ asd  
+(1 row)
+
+select 'asd'::mchar || '123';
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd'::mchar || '123'::mchar;
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd'::mchar || '123'::mvarchar;
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd '::mchar || '123';
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd '::mchar || '123'::mchar;
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd '::mchar || '123'::mvarchar;
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd '::mchar || '123 ';
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd '::mchar || '123 '::mchar;
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd '::mchar || '123 '::mvarchar;
+ ?column? 
+----------
+ asd123 
+(1 row)
+
+select 'asd'::mvarchar || '123';
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd'::mvarchar || '123'::mchar;
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd'::mvarchar || '123'::mvarchar;
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd '::mvarchar || '123';
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mvarchar || '123'::mchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mvarchar || '123'::mvarchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mvarchar || '123 ';
+ ?column? 
+----------
+ asd 123 
+(1 row)
+
+select 'asd '::mvarchar || '123 '::mchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mvarchar || '123 '::mvarchar;
+ ?column? 
+----------
+ asd 123 
+(1 row)
+
+select 'asd'::mchar(2) || '123';
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd'::mchar(2) || '123'::mchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd'::mchar(2) || '123'::mvarchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mchar(2) || '123';
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mchar(2) || '123'::mchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mchar(2) || '123'::mvarchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mchar(2) || '123 ';
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mchar(2) || '123 '::mchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mchar(2) || '123 '::mvarchar;
+ ?column? 
+----------
+ as123 
+(1 row)
+
+select 'asd'::mvarchar(2) || '123';
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd'::mvarchar(2) || '123'::mchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd'::mvarchar(2) || '123'::mvarchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mvarchar(2) || '123';
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mvarchar(2) || '123'::mchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mvarchar(2) || '123'::mvarchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mvarchar(2) || '123 ';
+ ?column? 
+----------
+ as123 
+(1 row)
+
+select 'asd '::mvarchar(2) || '123 '::mchar;
+ ?column? 
+----------
+ as123
+(1 row)
+
+select 'asd '::mvarchar(2) || '123 '::mvarchar;
+ ?column? 
+----------
+ as123 
+(1 row)
+
+select 'asd'::mchar(4) || '143';
+ ?column? 
+----------
+ asd 143
+(1 row)
+
+select 'asd'::mchar(4) || '123'::mchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd'::mchar(4) || '123'::mvarchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mchar(4) || '123';
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mchar(4) || '123'::mchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mchar(4) || '123'::mvarchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mchar(4) || '123 ';
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mchar(4) || '123 '::mchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mchar(4) || '123 '::mvarchar;
+ ?column? 
+----------
+ asd 123 
+(1 row)
+
+select 'asd'::mvarchar(4) || '123';
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd'::mvarchar(4) || '123'::mchar;
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd'::mvarchar(4) || '123'::mvarchar;
+ ?column? 
+----------
+ asd123
+(1 row)
+
+select 'asd '::mvarchar(4) || '123';
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mvarchar(4) || '123'::mchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mvarchar(4) || '123'::mvarchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mvarchar(4) || '123 ';
+ ?column? 
+----------
+ asd 123 
+(1 row)
+
+select 'asd '::mvarchar(4) || '123 '::mchar;
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 'asd '::mvarchar(4) || '123 '::mvarchar;
+ ?column? 
+----------
+ asd 123 
+(1 row)
+
+select 'asd '::mvarchar(4) || '123 '::mchar(4);
+ ?column? 
+----------
+ asd 123 
+(1 row)
+
+select 'asd '::mvarchar(4) || '123 '::mvarchar(4);
+ ?column? 
+----------
+ asd 123 
+(1 row)
+
+select 'asd '::mvarchar(4) || '123'::mchar(4);
+ ?column? 
+----------
+ asd 123 
+(1 row)
+
+select 'asd '::mvarchar(4) || '123'::mvarchar(4);
+ ?column? 
+----------
+ asd 123
+(1 row)
+
+select 1 where 'f'::mchar='F'::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f'::mchar='F '::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f '::mchar='F'::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f '::mchar='F '::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f'::mchar='F'::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f'::mchar='F '::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f '::mchar='F'::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f '::mchar='F '::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f'::mchar(2)='F'::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f'::mchar(2)='F '::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f '::mchar(2)='F'::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f '::mchar(2)='F '::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f'::mchar(2)='F'::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f'::mchar(2)='F '::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f '::mchar(2)='F'::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'f '::mchar(2)='F '::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'foo'::mchar='FOO'::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'foo'::mchar='FOO '::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'foo '::mchar='FOO'::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'foo '::mchar='FOO '::mvarchar;
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'foo'::mchar='FOO'::mvarchar(2);
+ ?column? 
+----------
+(0 rows)
+
+select 1 where 'foo'::mchar='FOO '::mvarchar(2);
+ ?column? 
+----------
+(0 rows)
+
+select 1 where 'foo '::mchar='FOO'::mvarchar(2);
+ ?column? 
+----------
+(0 rows)
+
+select 1 where 'foo '::mchar='FOO '::mvarchar(2);
+ ?column? 
+----------
+(0 rows)
+
+select 1 where 'foo'::mchar(2)='FOO'::mvarchar;
+ ?column? 
+----------
+(0 rows)
+
+select 1 where 'foo'::mchar(2)='FOO '::mvarchar;
+ ?column? 
+----------
+(0 rows)
+
+select 1 where 'foo '::mchar(2)='FOO'::mvarchar;
+ ?column? 
+----------
+(0 rows)
+
+select 1 where 'foo '::mchar(2)='FOO '::mvarchar;
+ ?column? 
+----------
+(0 rows)
+
+select 1 where 'foo'::mchar(2)='FOO'::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'foo'::mchar(2)='FOO '::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'foo '::mchar(2)='FOO'::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+select 1 where 'foo '::mchar(2)='FOO '::mvarchar(2);
+ ?column? 
+----------
+        1
+(1 row)
+
+Select 'f'::mchar(1) Union Select 'o'::mvarchar(1);
+ mchar 
+-------
+ f
+ o
+(2 rows)
+
+Select 'f'::mvarchar(1) Union Select 'o'::mchar(1);
+ mvarchar 
+----------
+ f
+ o
+(2 rows)
+
+select * from chvch where ch=vch;
+      ch      |    vch     
+--------------+------------
+ No spaces    | No spaces
+ One space    | One space 
+ 1 space      | 1 space 
+(3 rows)
+
+select ch.* from ch, (select 'dEfg'::mvarchar as q) as p  where  chcol > p.q;
+              chcol               
+----------------------------------
+ ee                              
+ Ee                              
+(2 rows)
+
+create index qq on ch (chcol);
+set enable_seqscan=off;
+select ch.* from ch, (select 'dEfg'::mvarchar as q) as p  where  chcol > p.q;
+              chcol               
+----------------------------------
+ ee                              
+ Ee                              
+(2 rows)
+
+set enable_seqscan=on;
+--\copy chvch to 'results/chvch.dump' binary
+--truncate table chvch;
+--\copy chvch from 'results/chvch.dump' binary
+--test joins
+CREATE TABLE a (mchar2 MCHAR(2) NOT NULL);
+CREATE TABLE c (mvarchar255 mvarchar NOT NULL);
+SELECT * FROM a, c WHERE mchar2 = mvarchar255;
+ mchar2 | mvarchar255 
+--------+-------------
+(0 rows)
+
+SELECT * FROM a, c WHERE mvarchar255 = mchar2;
+ mchar2 | mvarchar255 
+--------+-------------
+(0 rows)
+
+DROP TABLE a;
+DROP TABLE c;
diff -ruN a/contrib/mchar/expected/mvarchar.out b/contrib/mchar/expected/mvarchar.out
--- a/contrib/mchar/expected/mvarchar.out	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/expected/mvarchar.out	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,363 @@
+-- I/O tests
+select '1'::mvarchar;
+ mvarchar 
+----------
+ 1
+(1 row)
+
+select '2  '::mvarchar;
+ mvarchar 
+----------
+ 2  
+(1 row)
+
+select '10          '::mvarchar;
+   mvarchar   
+--------------
+ 10          
+(1 row)
+
+select '1'::mvarchar(2);
+ mvarchar 
+----------
+ 1
+(1 row)
+
+select '2 '::mvarchar(2);
+ mvarchar 
+----------
+ 2 
+(1 row)
+
+select '3  '::mvarchar(2);
+ mvarchar 
+----------
+ 3 
+(1 row)
+
+select '10          '::mvarchar(2);
+ mvarchar 
+----------
+ 10
+(1 row)
+
+select '                  '::mvarchar(10); 
+  mvarchar  
+------------
+           
+(1 row)
+
+select '                  '::mvarchar; 
+      mvarchar      
+--------------------
+                   
+(1 row)
+
+-- operations & functions
+select length('1'::mvarchar);
+ length 
+--------
+      1
+(1 row)
+
+select length('2  '::mvarchar);
+ length 
+--------
+      1
+(1 row)
+
+select length('10          '::mvarchar);
+ length 
+--------
+      2
+(1 row)
+
+select length('1'::mvarchar(2));
+ length 
+--------
+      1
+(1 row)
+
+select length('2 '::mvarchar(2));
+ length 
+--------
+      1
+(1 row)
+
+select length('3  '::mvarchar(2));
+ length 
+--------
+      1
+(1 row)
+
+select length('10          '::mvarchar(2));
+ length 
+--------
+      2
+(1 row)
+
+select length('                  '::mvarchar(10)); 
+ length 
+--------
+      0
+(1 row)
+
+select length('                  '::mvarchar); 
+ length 
+--------
+      0
+(1 row)
+
+select 'asd'::mvarchar(10) || '>'::mvarchar(10);
+ ?column? 
+----------
+ asd>
+(1 row)
+
+select length('asd'::mvarchar(10) || '>'::mvarchar(10));
+ length 
+--------
+      4
+(1 row)
+
+select 'asd'::mvarchar(2)  || '>'::mvarchar(10);
+ ?column? 
+----------
+ as>
+(1 row)
+
+select length('asd'::mvarchar(2) || '>'::mvarchar(10));
+ length 
+--------
+      3
+(1 row)
+
+-- Comparisons
+select 'asdf'::mvarchar = 'aSdf'::mvarchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar = 'aSdf '::mvarchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar = 'aSdf 1'::mvarchar(4);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar = 'aSdf 1'::mvarchar(5);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar = 'aSdf 1'::mvarchar(6);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar(3) = 'aSdf 1'::mvarchar(5);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar(3) = 'aSdf 1'::mvarchar(3);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar < 'aSdf'::mvarchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar < 'aSdf '::mvarchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar < 'aSdf 1'::mvarchar(4);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar < 'aSdf 1'::mvarchar(5);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar < 'aSdf 1'::mvarchar(6);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar <= 'aSdf'::mvarchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar <= 'aSdf '::mvarchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar <= 'aSdf 1'::mvarchar(4);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar <= 'aSdf 1'::mvarchar(5);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar <= 'aSdf 1'::mvarchar(6);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar >= 'aSdf'::mvarchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar >= 'aSdf '::mvarchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar >= 'aSdf 1'::mvarchar(4);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar >= 'aSdf 1'::mvarchar(5);
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asdf'::mvarchar >= 'aSdf 1'::mvarchar(6);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar > 'aSdf'::mvarchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar > 'aSdf '::mvarchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar > 'aSdf 1'::mvarchar(4);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar > 'aSdf 1'::mvarchar(5);
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asdf'::mvarchar > 'aSdf 1'::mvarchar(6);
+ ?column? 
+----------
+ f
+(1 row)
+
+select max(vch) from chvch;
+    max     
+------------
+ One space 
+(1 row)
+
+select min(vch) from chvch;
+   min    
+----------
+ 1 space 
+(1 row)
+
+select substr('1234567890'::mvarchar, 3) = '34567890' as "34567890";
+ 34567890 
+----------
+ f
+(1 row)
+
+select substr('1234567890'::mvarchar, 4, 3) = '456' as "456";
+ 456 
+-----
+ t
+(1 row)
+
+select lower('asdfASDF'::mvarchar);
+  lower   
+----------
+ asdfasdf
+(1 row)
+
+select upper('asdfASDF'::mvarchar);
+  upper   
+----------
+ ASDFASDF
+(1 row)
+
+select 'asd'::mvarchar == 'aSd'::mvarchar;
+ ?column? 
+----------
+ t
+(1 row)
+
+select 'asd'::mvarchar == 'aCd'::mvarchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select 'asd'::mvarchar == NULL;
+ ?column? 
+----------
+ f
+(1 row)
+
+select NULL == 'aCd'::mvarchar;
+ ?column? 
+----------
+ f
+(1 row)
+
+select NULL::mvarchar == NULL;
+ ?column? 
+----------
+ t
+(1 row)
+
diff -ruN a/contrib/mchar/Makefile b/contrib/mchar/Makefile
--- a/contrib/mchar/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/Makefile	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,21 @@
+MODULE_big = mchar
+OBJS = mchar_io.o mchar_proc.o mchar_op.o mchar_recode.o \
+	   mchar_like.o
+EXTENSION = mchar
+DATA = mchar--1.0.sql
+DOCS = README.mchar
+REGRESS = init mchar mvarchar mm like compat
+PGFIELDDESC = "mchar - mchar type implementation"
+
+ifdef USE_PGXS
+PGXS := $(shell pg_config --pgxs)
+include $(PGXS)
+else
+subdir = contrib/mchar
+top_builddir = ../..
+include $(top_builddir)/src/Makefile.global
+include $(top_srcdir)/contrib/contrib-global.mk
+ifeq ($(PORTNAME),darwin)
+LDFLAGS := $(LDFLAGS) $(ICU_LIBS)
+endif
+endif
diff -ruN a/contrib/mchar/mchar--1.0.sql b/contrib/mchar/mchar--1.0.sql
--- a/contrib/mchar/mchar--1.0.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/mchar--1.0.sql	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,1322 @@
+SET search_path = public;
+
+-- I/O functions
+
+CREATE FUNCTION mchartypmod_in(cstring[])
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchartypmod_out(int4)
+RETURNS cstring
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_in(cstring)
+RETURNS mchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_out(mchar)
+RETURNS cstring
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_send(mchar)
+RETURNS bytea
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_recv(internal)
+RETURNS mchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE TYPE mchar (
+    INTERNALLENGTH = -1,
+	INPUT = mchar_in,
+	OUTPUT = mchar_out,
+	TYPMOD_IN	= mchartypmod_in,
+	TYPMOD_OUT	= mchartypmod_out,
+	RECEIVE	= mchar_recv,
+	SEND = mchar_send,
+	STORAGE = extended
+);
+
+CREATE FUNCTION mchar(mchar, integer, boolean)
+RETURNS mchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE CAST (mchar as mchar)
+WITH FUNCTION mchar(mchar, integer, boolean) as IMPLICIT;
+
+CREATE FUNCTION mvarchar_in(cstring)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_out(mvarchar)
+RETURNS cstring
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_send(mvarchar)
+RETURNS bytea
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_recv(internal)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE TYPE mvarchar (
+    INTERNALLENGTH = -1,
+	INPUT = mvarchar_in,
+	OUTPUT = mvarchar_out,
+	TYPMOD_IN	= mchartypmod_in,
+	TYPMOD_OUT	= mchartypmod_out,
+	RECEIVE	= mvarchar_recv,
+	SEND = mvarchar_send,
+	STORAGE = extended
+);
+
+CREATE FUNCTION mvarchar(mvarchar, integer, boolean)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE CAST (mvarchar as mvarchar)
+WITH FUNCTION mvarchar(mvarchar, integer, boolean) as IMPLICIT;
+
+--Operations and functions
+
+CREATE FUNCTION length(mchar)
+RETURNS int4
+AS 'MODULE_PATHNAME', 'mchar_length'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION upper(mchar)
+RETURNS mchar
+AS 'MODULE_PATHNAME', 'mchar_upper'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION lower(mchar)
+RETURNS mchar
+AS 'MODULE_PATHNAME', 'mchar_lower'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_hash(mchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_concat(mchar, mchar)
+RETURNS	mchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE OPERATOR || (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	= 	mchar_concat
+);
+
+CREATE FUNCTION mchar_like(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_notlike(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE OPERATOR ~~ (
+	LEFTARG     =   mchar,
+	RIGHTARG	= 	mvarchar,
+	PROCEDURE	= 	mchar_like,
+	RESTRICT	= 	likesel,
+	JOIN		= 	likejoinsel,
+	NEGATOR		= 	'!~~'
+);
+
+CREATE OPERATOR !~~ (
+	LEFTARG     =   mchar,
+	RIGHTARG	= 	mvarchar,
+	PROCEDURE	= 	mchar_notlike,
+	RESTRICT	= 	nlikesel,
+	JOIN		= 	nlikejoinsel,
+	NEGATOR		= 	'~~'
+);
+
+CREATE FUNCTION mchar_regexeq(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_regexne(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE OPERATOR ~ (
+	LEFTARG     =   mchar,
+	RIGHTARG	= 	mchar,
+	PROCEDURE	= 	mchar_regexeq,
+	RESTRICT	= 	regexeqsel,
+	JOIN		= 	regexeqjoinsel,
+	NEGATOR		= 	'!~'
+);
+
+CREATE OPERATOR !~ (
+	LEFTARG     =   mchar,
+	RIGHTARG	= 	mchar,
+	PROCEDURE	= 	mchar_regexne,
+	RESTRICT	= 	regexnesel,
+	JOIN		= 	regexnejoinsel,
+	NEGATOR		= 	'~'
+);
+
+CREATE FUNCTION similar_escape(mchar, mchar)
+RETURNS mchar
+AS 'MODULE_PATHNAME', 'mchar_similar_escape'
+LANGUAGE C IMMUTABLE;
+
+CREATE FUNCTION length(mvarchar)
+RETURNS int4
+AS 'MODULE_PATHNAME', 'mvarchar_length'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION upper(mvarchar)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME', 'mvarchar_upper'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION lower(mvarchar)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME', 'mvarchar_lower'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_hash(mvarchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_concat(mvarchar, mvarchar)
+RETURNS	mvarchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE OPERATOR || (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	= 	mvarchar_concat
+);
+
+CREATE FUNCTION mvarchar_like(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION like_escape(mvarchar, mvarchar)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME', 'mvarchar_like_escape'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_notlike(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE OPERATOR ~~ (
+	LEFTARG     =   mvarchar,
+	RIGHTARG	= 	mvarchar,
+	PROCEDURE	= 	mvarchar_like,
+	RESTRICT	= 	likesel,
+	JOIN		= 	likejoinsel,
+	NEGATOR		= 	'!~~'
+);
+
+CREATE OPERATOR !~~ (
+	LEFTARG     =   mvarchar,
+	RIGHTARG	= 	mvarchar,
+	PROCEDURE	= 	mvarchar_notlike,
+	RESTRICT	= 	nlikesel,
+	JOIN		= 	nlikejoinsel,
+	NEGATOR		= 	'~~'
+);
+
+CREATE FUNCTION mvarchar_regexeq(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_regexne(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE OPERATOR ~ (
+	LEFTARG     =   mvarchar,
+	RIGHTARG	= 	mvarchar,
+	PROCEDURE	= 	mvarchar_regexeq,
+	RESTRICT	= 	regexeqsel,
+	JOIN		= 	regexeqjoinsel,
+	NEGATOR		= 	'!~'
+);
+
+CREATE OPERATOR !~ (
+	LEFTARG     =   mvarchar,
+	RIGHTARG	= 	mvarchar,
+	PROCEDURE	= 	mvarchar_regexne,
+	RESTRICT	= 	regexnesel,
+	JOIN		= 	regexnejoinsel,
+	NEGATOR		= 	'~'
+);
+
+CREATE FUNCTION similar_escape(mvarchar, mvarchar)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME', 'mvarchar_similar_escape'
+LANGUAGE C IMMUTABLE;
+
+CREATE FUNCTION substr (mchar, int4)
+RETURNS mchar
+AS 'MODULE_PATHNAME', 'mchar_substring_no_len'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION substr (mchar, int4, int4)
+RETURNS mchar
+AS 'MODULE_PATHNAME', 'mchar_substring'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION substr (mvarchar, int4)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME', 'mvarchar_substring_no_len'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION substr (mvarchar, int4, int4)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME', 'mvarchar_substring'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+-- Comparing
+--    MCHAR
+
+CREATE FUNCTION mchar_icase_cmp(mchar, mchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_icase_eq(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_icase_ne(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_icase_lt(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_icase_le(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_icase_gt(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_icase_ge(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+
+CREATE OPERATOR < (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_icase_lt,
+	COMMUTATOR	= 	'>',
+	NEGATOR		= 	'>=',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR > (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_icase_gt,
+	COMMUTATOR	= 	'<',
+	NEGATOR		= 	'<=',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR <= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_icase_le,
+	COMMUTATOR	= 	'>=',
+	NEGATOR		= 	'>',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR >= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_icase_ge,
+	COMMUTATOR	= 	'<=',
+	NEGATOR		= 	'<',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR = (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_icase_eq,
+	COMMUTATOR	= 	'=',
+	NEGATOR		= 	'<>',
+	RESTRICT	= 	eqsel,
+	JOIN		= 	eqjoinsel,
+	SORT1 		= 	'<',
+	SORT2 		= 	'<',
+	HASHES
+);
+
+CREATE OPERATOR <> (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_icase_ne,
+	COMMUTATOR	= 	'<>',
+	NEGATOR		= 	'=',
+	RESTRICT	= 	neqsel,
+	JOIN		= 	neqjoinsel
+);
+
+CREATE FUNCTION mchar_case_cmp(mchar, mchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_case_eq(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_case_ne(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_case_lt(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_case_le(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_case_gt(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_case_ge(mchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+
+CREATE OPERATOR &< (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_case_lt,
+	COMMUTATOR	= 	'&>',
+	NEGATOR		= 	'&>=',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR &> (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_case_gt,
+	COMMUTATOR	= 	'&<',
+	NEGATOR		= 	'&<=',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR &<= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_case_le,
+	COMMUTATOR	= 	'&>=',
+	NEGATOR		= 	'&>',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR &>= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_case_ge,
+	COMMUTATOR	= 	'&<=',
+	NEGATOR		= 	'&<',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR &= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_case_eq,
+	COMMUTATOR	= 	'&=',
+	NEGATOR		= 	'&<>',
+	RESTRICT	= 	eqsel,
+	JOIN		= 	eqjoinsel,
+	SORT1 		= 	'&<',
+	SORT2 		= 	'&<'
+);
+
+CREATE OPERATOR &<> (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mchar_case_ne,
+	COMMUTATOR	= 	'&<>',
+	NEGATOR		= 	'&=',
+	RESTRICT	= 	neqsel,
+	JOIN		= 	neqjoinsel
+);
+
+--MVARCHAR
+
+CREATE FUNCTION mvarchar_icase_cmp(mvarchar, mvarchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_icase_eq(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_icase_ne(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_icase_lt(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_icase_le(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_icase_gt(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_icase_ge(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+
+CREATE OPERATOR < (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_icase_lt,
+	COMMUTATOR	= 	'>',
+	NEGATOR		= 	'>=',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR > (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_icase_gt,
+	COMMUTATOR	= 	'<',
+	NEGATOR		= 	'<=',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR <= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_icase_le,
+	COMMUTATOR	= 	'>=',
+	NEGATOR		= 	'>',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR >= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_icase_ge,
+	COMMUTATOR	= 	'<=',
+	NEGATOR		= 	'<',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR = (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_icase_eq,
+	COMMUTATOR	= 	'=',
+	NEGATOR		= 	'<>',
+	RESTRICT	= 	eqsel,
+	JOIN		= 	eqjoinsel,
+	SORT1 		= 	'<',
+	SORT2 		= 	'<',
+	HASHES
+);
+
+CREATE OPERATOR <> (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_icase_ne,
+	COMMUTATOR	= 	'<>',
+	NEGATOR		= 	'=',
+	RESTRICT	= 	neqsel,
+	JOIN		= 	neqjoinsel
+);
+
+CREATE FUNCTION mvarchar_case_cmp(mvarchar, mvarchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_case_eq(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_case_ne(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_case_lt(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_case_le(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_case_gt(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mvarchar_case_ge(mvarchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+
+CREATE OPERATOR &< (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_case_lt,
+	COMMUTATOR	= 	'&>',
+	NEGATOR		= 	'&>=',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR &> (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_case_gt,
+	COMMUTATOR	= 	'&<',
+	NEGATOR		= 	'&<=',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR &<= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_case_le,
+	COMMUTATOR	= 	'&>=',
+	NEGATOR		= 	'&>',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR &>= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_case_ge,
+	COMMUTATOR	= 	'&<=',
+	NEGATOR		= 	'&<',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR &= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_case_eq,
+	COMMUTATOR	= 	'&=',
+	NEGATOR		= 	'&<>',
+	RESTRICT	= 	eqsel,
+	JOIN		= 	eqjoinsel,
+	SORT1 		= 	'&<',
+	SORT2 		= 	'&<'
+);
+
+CREATE OPERATOR &<> (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mvarchar_case_ne,
+	COMMUTATOR	= 	'&<>',
+	NEGATOR		= 	'&=',
+	RESTRICT	= 	neqsel,
+	JOIN		= 	neqjoinsel
+);
+
+--    MCHAR <> MVARCHAR
+
+CREATE FUNCTION mc_mv_icase_cmp(mchar, mvarchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_icase_eq(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_icase_ne(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_icase_lt(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_icase_le(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_icase_gt(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_icase_ge(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+
+CREATE OPERATOR < (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_icase_lt,
+	COMMUTATOR	= 	'>',
+	NEGATOR		= 	'>=',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR > (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_icase_gt,
+	COMMUTATOR	= 	'<',
+	NEGATOR		= 	'<=',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR <= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_icase_le,
+	COMMUTATOR	= 	'>=',
+	NEGATOR		= 	'>',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR >= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_icase_ge,
+	COMMUTATOR	= 	'<=',
+	NEGATOR		= 	'<',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR = (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_icase_eq,
+	COMMUTATOR	= 	'=',
+	NEGATOR		= 	'<>',
+	RESTRICT	= 	eqsel,
+	JOIN		= 	eqjoinsel,
+	SORT1 		= 	'<',
+	SORT2 		= 	'<'
+);
+
+CREATE OPERATOR <> (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_icase_ne,
+	COMMUTATOR	= 	'<>',
+	NEGATOR		= 	'=',
+	RESTRICT	= 	neqsel,
+	JOIN		= 	neqjoinsel
+);
+
+CREATE FUNCTION mc_mv_case_cmp(mchar, mvarchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_case_eq(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_case_ne(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_case_lt(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_case_le(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_case_gt(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mc_mv_case_ge(mchar, mvarchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+
+CREATE OPERATOR &< (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_case_lt,
+	COMMUTATOR	= 	'&>',
+	NEGATOR		= 	'&>=',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR &> (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_case_gt,
+	COMMUTATOR	= 	'&<',
+	NEGATOR		= 	'&<=',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR &<= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_case_le,
+	COMMUTATOR	= 	'&>=',
+	NEGATOR		= 	'&>',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR &>= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_case_ge,
+	COMMUTATOR	= 	'&<=',
+	NEGATOR		= 	'&<',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR &= (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_case_eq,
+	COMMUTATOR	= 	'&=',
+	NEGATOR		= 	'&<>',
+	RESTRICT	= 	eqsel,
+	JOIN		= 	eqjoinsel,
+	SORT1 		= 	'&<',
+	SORT2 		= 	'&<'
+);
+
+CREATE OPERATOR &<> (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	=	mc_mv_case_ne,
+	COMMUTATOR	= 	'&<>',
+	NEGATOR		= 	'&=',
+	RESTRICT	= 	neqsel,
+	JOIN		= 	neqjoinsel
+);
+
+--    MVARCHAR <> MCHAR
+
+CREATE FUNCTION mv_mc_icase_cmp(mvarchar, mchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_icase_eq(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_icase_ne(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_icase_lt(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_icase_le(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_icase_gt(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_icase_ge(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+
+CREATE OPERATOR < (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_icase_lt,
+	COMMUTATOR	= 	'>',
+	NEGATOR		= 	'>=',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR > (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_icase_gt,
+	COMMUTATOR	= 	'<',
+	NEGATOR		= 	'<=',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR <= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_icase_le,
+	COMMUTATOR	= 	'>=',
+	NEGATOR		= 	'>',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR >= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_icase_ge,
+	COMMUTATOR	= 	'<=',
+	NEGATOR		= 	'<',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR = (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_icase_eq,
+	COMMUTATOR	= 	'=',
+	NEGATOR		= 	'<>',
+	RESTRICT	= 	eqsel,
+	JOIN		= 	eqjoinsel,
+	SORT1 		= 	'<',
+	SORT2 		= 	'<'
+);
+
+CREATE OPERATOR <> (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_icase_ne,
+	COMMUTATOR	= 	'<>',
+	NEGATOR		= 	'=',
+	RESTRICT	= 	neqsel,
+	JOIN		= 	neqjoinsel
+);
+
+CREATE FUNCTION mv_mc_case_cmp(mvarchar, mchar)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_case_eq(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_case_ne(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_case_lt(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_case_le(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_case_gt(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mv_mc_case_ge(mvarchar, mchar)
+RETURNS bool
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+
+CREATE OPERATOR &< (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_case_lt,
+	COMMUTATOR	= 	'&>',
+	NEGATOR		= 	'&>=',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR &> (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_case_gt,
+	COMMUTATOR	= 	'&<',
+	NEGATOR		= 	'&<=',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR &<= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_case_le,
+	COMMUTATOR	= 	'&>=',
+	NEGATOR		= 	'&>',
+	RESTRICT	= 	scalarltsel,
+	JOIN		= 	scalarltjoinsel
+);
+
+CREATE OPERATOR &>= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_case_ge,
+	COMMUTATOR	= 	'&<=',
+	NEGATOR		= 	'&<',
+	RESTRICT	= 	scalargtsel,
+	JOIN		= 	scalargtjoinsel
+);
+
+CREATE OPERATOR &= (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_case_eq,
+	COMMUTATOR	= 	'&=',
+	NEGATOR		= 	'&<>',
+	RESTRICT	= 	eqsel,
+	JOIN		= 	eqjoinsel,
+	SORT1 		= 	'&<',
+	SORT2 		= 	'&<'
+);
+
+CREATE OPERATOR &<> (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	=	mv_mc_case_ne,
+	COMMUTATOR	= 	'&<>',
+	NEGATOR		= 	'&=',
+	RESTRICT	= 	neqsel,
+	JOIN		= 	neqjoinsel
+);
+
+-- MCHAR - VARCHAR operations
+
+CREATE FUNCTION mchar_mvarchar_concat(mchar, mvarchar)
+RETURNS	mvarchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE OPERATOR || (
+	LEFTARG		=	mchar,
+	RIGHTARG	=	mvarchar,
+	PROCEDURE	= 	mchar_mvarchar_concat
+);
+
+CREATE FUNCTION mvarchar_mchar_concat(mvarchar, mchar)
+RETURNS	mvarchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE OPERATOR || (
+	LEFTARG		=	mvarchar,
+	RIGHTARG	=	mchar,
+	PROCEDURE	= 	mvarchar_mchar_concat
+);
+
+CREATE FUNCTION mvarchar_mchar(mvarchar, integer, boolean)
+RETURNS mchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE CAST (mvarchar as mchar)
+WITH FUNCTION mvarchar_mchar(mvarchar, integer, boolean) as IMPLICIT;
+
+CREATE FUNCTION mchar_mvarchar(mchar, integer, boolean)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE CAST (mchar as mvarchar)
+WITH FUNCTION mchar_mvarchar(mchar, integer, boolean) as IMPLICIT;
+
+-- Aggregates
+
+CREATE FUNCTION mchar_larger(mchar, mchar)
+RETURNS mchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE AGGREGATE max (
+	BASETYPE	= 	mchar,
+	SFUNC 		= 	mchar_larger,
+	STYPE		= 	mchar,
+	SORTOP		= 	'>'
+);
+
+CREATE FUNCTION mchar_smaller(mchar, mchar)
+RETURNS mchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE AGGREGATE min (
+	BASETYPE	= 	mchar,
+	SFUNC 		= 	mchar_smaller,
+	STYPE		= 	mchar,
+	SORTOP		= 	'<'
+);
+
+CREATE FUNCTION mvarchar_larger(mvarchar, mvarchar)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE AGGREGATE max (
+	BASETYPE	= 	mvarchar,
+	SFUNC 		= 	mvarchar_larger,
+	STYPE		= 	mvarchar,
+	SORTOP		= 	'>'
+);
+
+CREATE FUNCTION mvarchar_smaller(mvarchar, mvarchar)
+RETURNS mvarchar
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE AGGREGATE min (
+	BASETYPE	= 	mvarchar,
+	SFUNC 		= 	mvarchar_smaller,
+	STYPE		= 	mvarchar,
+	SORTOP		= 	'<'
+);
+
+-- B-tree support
+CREATE OPERATOR FAMILY icase_ops USING btree;
+CREATE OPERATOR FAMILY case_ops USING btree;
+
+CREATE OPERATOR CLASS mchar_icase_ops
+DEFAULT FOR TYPE mchar USING btree FAMILY icase_ops AS
+        OPERATOR        1       <  ,
+		OPERATOR        2       <= ,
+		OPERATOR        3       =  ,
+		OPERATOR        4       >= ,
+		OPERATOR        5       >  ,
+		FUNCTION        1       mchar_icase_cmp(mchar, mchar),
+        OPERATOR        1       <  (mchar, mvarchar),
+		OPERATOR        2       <= (mchar, mvarchar),
+		OPERATOR        3       =  (mchar, mvarchar),
+		OPERATOR        4       >= (mchar, mvarchar),
+		OPERATOR        5       >  (mchar, mvarchar),
+		FUNCTION        1       mc_mv_icase_cmp(mchar, mvarchar);
+
+CREATE OPERATOR CLASS mchar_case_ops
+FOR TYPE mchar USING btree FAMILY case_ops AS
+        OPERATOR        1       &<  ,
+		OPERATOR        2       &<= ,
+		OPERATOR        3       &=  ,
+		OPERATOR        4       &>= ,
+		OPERATOR        5       &>  ,
+		FUNCTION        1       mchar_case_cmp(mchar, mchar),
+        OPERATOR        1       &<  (mchar, mvarchar),
+		OPERATOR        2       &<= (mchar, mvarchar),
+		OPERATOR        3       &=  (mchar, mvarchar),
+		OPERATOR        4       &>= (mchar, mvarchar),
+		OPERATOR        5       &>  (mchar, mvarchar),
+		FUNCTION        1       mc_mv_case_cmp(mchar, mvarchar);
+
+CREATE OPERATOR CLASS mchar_icase_ops
+DEFAULT FOR TYPE mchar USING hash AS
+		OPERATOR        1       =  ,
+		FUNCTION        1       mchar_hash(mchar);
+
+CREATE OPERATOR CLASS mvarchar_icase_ops
+DEFAULT FOR TYPE mvarchar USING btree FAMILY icase_ops AS
+        OPERATOR        1       <  ,
+		OPERATOR        2       <= ,
+		OPERATOR        3       =  ,
+		OPERATOR        4       >= ,
+		OPERATOR        5       >  ,
+		FUNCTION        1       mvarchar_icase_cmp(mvarchar, mvarchar),
+        OPERATOR        1       <  (mvarchar, mchar),
+		OPERATOR        2       <= (mvarchar, mchar),
+		OPERATOR        3       =  (mvarchar, mchar),
+		OPERATOR        4       >= (mvarchar, mchar),
+		OPERATOR        5       >  (mvarchar, mchar),
+		FUNCTION        1       mv_mc_icase_cmp(mvarchar, mchar);
+
+CREATE OPERATOR CLASS mvarchar_case_ops
+FOR TYPE mvarchar USING btree FAMILY case_ops AS
+        OPERATOR        1       &<  ,
+		OPERATOR        2       &<= ,
+		OPERATOR        3       &=  ,
+		OPERATOR        4       &>= ,
+		OPERATOR        5       &>  ,
+		FUNCTION        1       mvarchar_case_cmp(mvarchar, mvarchar),
+        OPERATOR        1       &<  (mvarchar, mchar),
+		OPERATOR        2       &<= (mvarchar, mchar),
+		OPERATOR        3       &=  (mvarchar, mchar),
+		OPERATOR        4       &>= (mvarchar, mchar),
+		OPERATOR        5       &>  (mvarchar, mchar),
+		FUNCTION        1       mv_mc_case_cmp(mvarchar, mchar);
+
+CREATE OPERATOR CLASS mvarchar_icase_ops
+DEFAULT FOR TYPE mvarchar USING hash AS
+		OPERATOR        1       =  ,
+		FUNCTION        1       mvarchar_hash(mvarchar);
+
+
+-- Index support for LIKE
+
+CREATE FUNCTION mchar_pattern_fixed_prefix(internal, internal, internal)
+RETURNS int4
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE FUNCTION mchar_greaterstring(internal)
+RETURNS internal
+AS 'MODULE_PATHNAME'
+LANGUAGE C IMMUTABLE RETURNS NULL ON NULL INPUT;
+
+CREATE OR REPLACE FUNCTION isfulleq_mchar(mchar, mchar)
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_mchar(mchar)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+    LEFTARG     = mchar,
+    RIGHTARG    = mchar,
+    PROCEDURE   = isfulleq_mchar,
+    COMMUTATOR  = '==',
+    RESTRICT    = eqsel,
+    JOIN        = eqjoinsel,
+    HASHES
+);
+
+CREATE OPERATOR CLASS mchar_fill_ops
+ FOR TYPE mchar USING hash AS
+    OPERATOR    1   ==,
+    FUNCTION    1   fullhash_mchar(mchar);
+
+CREATE OR REPLACE FUNCTION isfulleq_mvarchar(mvarchar, mvarchar)
+RETURNS bool AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+CREATE OR REPLACE FUNCTION fullhash_mvarchar(mvarchar)
+RETURNS int4 AS 'MODULE_PATHNAME'
+LANGUAGE C CALLED ON NULL INPUT IMMUTABLE;
+
+
+CREATE OPERATOR == (
+    LEFTARG     = mvarchar,
+    RIGHTARG    = mvarchar,
+    PROCEDURE   = isfulleq_mvarchar,
+    COMMUTATOR  = '==',
+    RESTRICT    = eqsel,
+    JOIN        = eqjoinsel,
+    HASHES
+);
+
+CREATE OPERATOR CLASS mvarchar_fill_ops
+ FOR TYPE mvarchar USING hash AS
+    OPERATOR    1   ==,
+    FUNCTION    1   fullhash_mvarchar(mvarchar);
diff -ruN a/contrib/mchar/mchar.control b/contrib/mchar/mchar.control
--- a/contrib/mchar/mchar.control	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/mchar.control	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,5 @@
+# mchar extension
+comment = 'mchar type implementation'
+default_version = '1.0'
+module_pathname = '$libdir/mchar'
+relocatable = true
\ No newline at end of file
diff -ruN a/contrib/mchar/mchar.h b/contrib/mchar/mchar.h
--- a/contrib/mchar/mchar.h	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/mchar.h	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,62 @@
+#ifndef __MCHAR_H__
+#define __MCHAR_H__
+
+#include "postgres.h"
+#include "mb/pg_wchar.h"
+#include "utils/builtins.h"
+#include "unicode/uchar.h"
+#include "unicode/ustring.h"
+
+typedef struct {
+	int32	len;
+	int32 	typmod;
+	UChar	data[1];
+} MChar;
+
+#define MCHARHDRSZ	offsetof(MChar, data)	
+#define MCHARLENGTH(m)	( VARSIZE(m)-MCHARHDRSZ )
+#define UCHARLENGTH(m)  ( MCHARLENGTH(m)/sizeof(UChar) )	
+
+#define DatumGetMChar(m)	((MChar*)DatumGetPointer(m))
+#define MCharGetDatum(m)	PointerGetDatum(m)
+
+#define	PG_GETARG_MCHAR(n)	DatumGetMChar(PG_DETOAST_DATUM(PG_GETARG_DATUM(n)))
+#define	PG_GETARG_MCHAR_COPY(n)	DatumGetMChar(PG_DETOAST_DATUM_COPY(PG_GETARG_DATUM(n)))
+
+#define PG_RETURN_MCHAR(m)	PG_RETURN_POINTER(m)
+
+typedef struct {
+	int32	len;
+	UChar	data[1];
+} MVarChar;
+
+#define MVARCHARHDRSZ 	offsetof(MVarChar, data)
+#define MVARCHARLENGTH(m)  ( VARSIZE(m)-MVARCHARHDRSZ )
+#define UVARCHARLENGTH(m)  ( MVARCHARLENGTH(m)/sizeof(UChar) )
+
+#define DatumGetMVarChar(m)	((MVarChar*)DatumGetPointer(m))
+#define MVarCharGetDatum(m)	PointerGetDatum(m)
+
+#define	PG_GETARG_MVARCHAR(n)	DatumGetMVarChar(PG_DETOAST_DATUM(PG_GETARG_DATUM(n)))
+#define	PG_GETARG_MVARCHAR_COPY(n)	DatumGetMVarChar(PG_DETOAST_DATUM_COPY(PG_GETARG_DATUM(n)))
+
+#define PG_RETURN_MVARCHAR(m)	PG_RETURN_POINTER(m)
+
+
+int Char2UChar(const char * src, int srclen, UChar *dst); 
+int UChar2Char(const UChar * src, int srclen, char *dst); 
+int UChar2Wchar(UChar * src, int srclen, pg_wchar *dst);
+int UCharCompare(UChar * a, int alen, UChar *b, int blen); 
+int UCharCaseCompare(UChar * a, int alen, UChar *b, int blen); 
+
+void FillWhiteSpace( UChar *dst, int n );
+
+int lengthWithoutSpaceVarChar(MVarChar *m);
+int lengthWithoutSpaceChar(MChar *m);
+
+extern Datum       mchar_hash(PG_FUNCTION_ARGS);
+extern Datum       mvarchar_hash(PG_FUNCTION_ARGS);
+
+int m_isspace(UChar c); /* is == ' ' */
+
+#endif
diff -ruN a/contrib/mchar/mchar_io.c b/contrib/mchar/mchar_io.c
--- a/contrib/mchar/mchar_io.c	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/mchar_io.c	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,372 @@
+#include "mchar.h"
+#include "mb/pg_wchar.h"
+#include "fmgr.h"
+#include "libpq/pqformat.h"
+#include <utils/array.h>
+
+#ifdef PG_MODULE_MAGIC
+PG_MODULE_MAGIC;
+#endif
+
+PG_FUNCTION_INFO_V1(mchar_in);
+Datum       mchar_in(PG_FUNCTION_ARGS);
+PG_FUNCTION_INFO_V1(mchar_out);
+Datum       mchar_out(PG_FUNCTION_ARGS);
+PG_FUNCTION_INFO_V1(mchar);
+Datum       mchar(PG_FUNCTION_ARGS);
+
+PG_FUNCTION_INFO_V1(mvarchar_in);
+Datum       mvarchar_in(PG_FUNCTION_ARGS);
+PG_FUNCTION_INFO_V1(mvarchar_out);
+Datum       mvarchar_out(PG_FUNCTION_ARGS);
+PG_FUNCTION_INFO_V1(mvarchar);
+Datum       mvarchar(PG_FUNCTION_ARGS);
+
+PG_FUNCTION_INFO_V1(mchartypmod_in);
+Datum mchartypmod_in(PG_FUNCTION_ARGS);
+Datum 
+mchartypmod_in(PG_FUNCTION_ARGS) {
+	ArrayType  *ta = PG_GETARG_ARRAYTYPE_P(0);
+	int32      *tl;
+	int         n;
+
+	tl = ArrayGetIntegerTypmods(ta, &n);
+
+	if (n != 1)
+		ereport(ERROR,
+				(errcode(ERRCODE_INVALID_PARAMETER_VALUE),
+				errmsg("invalid type modifier")));
+	if (*tl < 1)
+			ereport(ERROR,
+				(errcode(ERRCODE_INVALID_PARAMETER_VALUE),
+					errmsg("length for type mchar/mvarchar must be at least 1")));
+
+	return *tl;
+}
+
+PG_FUNCTION_INFO_V1(mchartypmod_out);
+Datum mchartypmod_out(PG_FUNCTION_ARGS);
+Datum 
+mchartypmod_out(PG_FUNCTION_ARGS) {
+	int32       typmod = PG_GETARG_INT32(0);
+	char       *res = (char *) palloc(64);
+
+	if (typmod >0) 
+		snprintf(res, 64, "(%d)", (int) (typmod));
+	else
+		*res = '\0';
+
+	PG_RETURN_CSTRING( res );
+}
+
+static void
+mchar_strip( MChar * m, int atttypmod ) {
+	int maxlen;
+	
+	if ( atttypmod<=0 ) {
+		atttypmod =-1;
+	} else {
+		int	charlen = u_countChar32( m->data, UCHARLENGTH(m) );
+
+		if ( charlen > atttypmod ) {
+			int i=0;
+			U16_FWD_N( m->data, i, UCHARLENGTH(m), atttypmod);
+			SET_VARSIZE( m, sizeof(UChar) * i + MCHARHDRSZ );
+		}
+	}
+
+	m->typmod = atttypmod;
+
+	maxlen = UCHARLENGTH(m);
+	while( maxlen>0 && m_isspace( m->data[ maxlen-1 ] ) )
+		maxlen--;
+
+	SET_VARSIZE(m, sizeof(UChar) * maxlen + MCHARHDRSZ);
+}
+
+
+Datum
+mchar_in(PG_FUNCTION_ARGS) {
+	char       *s = PG_GETARG_CSTRING(0);
+#ifdef NOT_USED
+	Oid         typelem = PG_GETARG_OID(1);
+#endif
+	int32       atttypmod = PG_GETARG_INT32(2);
+	MChar	*result;
+	int32	slen = strlen(s), rlen;
+
+	pg_verifymbstr(s, slen, false);
+
+	result = (MChar*)palloc( MCHARHDRSZ + slen * sizeof(UChar) * 4 /* upper limit of length */ );
+	rlen = Char2UChar( s, slen, result->data );
+	SET_VARSIZE(result, sizeof(UChar) * rlen + MCHARHDRSZ);
+
+	mchar_strip(result, atttypmod);
+
+	PG_RETURN_MCHAR(result);
+}
+
+Datum
+mchar_out(PG_FUNCTION_ARGS) {
+	MChar	*in = PG_GETARG_MCHAR(0);
+	char	*out;
+	size_t	size, inlen = UCHARLENGTH(in);
+	size_t  charlen = u_countChar32(in->data, inlen);
+
+	Assert( in->typmod < 0 || charlen<=in->typmod );
+	size = ( in->typmod < 0 ) ? inlen : in->typmod;
+	size *= pg_database_encoding_max_length();
+
+	out = (char*)palloc( size+1 );
+	size = UChar2Char( in->data, inlen, out );
+
+	if ( in->typmod>0 && charlen < in->typmod ) {
+		memset( out+size, ' ', in->typmod - charlen);
+		size += in->typmod - charlen;
+	}
+
+	out[size] = '\0';
+
+	PG_FREE_IF_COPY(in,0);
+
+	PG_RETURN_CSTRING(out);
+}
+
+Datum
+mchar(PG_FUNCTION_ARGS) {
+	MChar	*source = PG_GETARG_MCHAR(0);
+	MChar	*result;
+	int32    typmod = PG_GETARG_INT32(1);
+#ifdef NOT_USED
+	bool     isExplicit = PG_GETARG_BOOL(2);
+#endif
+
+	result = palloc( VARSIZE(source) );
+	memcpy( result, source, VARSIZE(source) );
+	PG_FREE_IF_COPY(source,0);
+
+	mchar_strip(result, typmod);
+
+	PG_RETURN_MCHAR(result);
+}
+
+Datum
+mvarchar_in(PG_FUNCTION_ARGS) {
+	char       *s = PG_GETARG_CSTRING(0);
+#ifdef NOT_USED
+	Oid         typelem = PG_GETARG_OID(1);
+#endif
+	int32       atttypmod = PG_GETARG_INT32(2);
+	MVarChar	*result;
+	int32		slen = strlen(s), rlen;
+
+	pg_verifymbstr(s, slen, false);
+
+	result = (MVarChar*)palloc( MVARCHARHDRSZ + slen * sizeof(UChar) * 2 /* upper limit of length */ );
+	rlen = Char2UChar( s, slen, result->data );
+	SET_VARSIZE(result, sizeof(UChar) * rlen + MVARCHARHDRSZ);
+
+	if ( atttypmod > 0 && atttypmod < u_countChar32(result->data, UVARCHARLENGTH(result)) )
+		elog(ERROR,"value too long for type mvarchar(%d)", atttypmod);
+
+	PG_RETURN_MVARCHAR(result);
+}
+
+Datum
+mvarchar_out(PG_FUNCTION_ARGS) {
+	MVarChar	*in = PG_GETARG_MVARCHAR(0);
+	char	*out;
+	size_t	size = UVARCHARLENGTH(in);
+
+	size *= pg_database_encoding_max_length();
+
+	out = (char*)palloc( size+1 );
+	size = UChar2Char( in->data, UVARCHARLENGTH(in), out );
+
+	out[size] = '\0';
+
+	PG_FREE_IF_COPY(in,0);
+
+	PG_RETURN_CSTRING(out);
+}
+
+static void
+mvarchar_strip(MVarChar *m, int atttypmod) {
+	int     charlen = u_countChar32(m->data, UVARCHARLENGTH(m));
+
+	if ( atttypmod>=0 && atttypmod < charlen ) {
+		int i=0;
+		U16_FWD_N( m->data, i, charlen, atttypmod);
+		SET_VARSIZE(m, sizeof(UChar) * i + MVARCHARHDRSZ);
+	}
+}
+
+Datum
+mvarchar(PG_FUNCTION_ARGS) {
+	MVarChar	*source = PG_GETARG_MVARCHAR(0);
+	MVarChar	*result;
+	int32    typmod = PG_GETARG_INT32(1);
+	bool     isExplicit = PG_GETARG_BOOL(2);
+	int		charlen = u_countChar32(source->data, UVARCHARLENGTH(source)); 
+
+	result = palloc( VARSIZE(source) );
+	memcpy( result, source, VARSIZE(source) );
+	PG_FREE_IF_COPY(source,0);
+
+	if ( typmod>=0 && typmod < charlen ) {
+		if ( isExplicit )
+			mvarchar_strip(result, typmod);
+		else
+			elog(ERROR,"value too long for type mvarchar(%d)", typmod);
+	}
+
+	PG_RETURN_MVARCHAR(result);
+}
+
+PG_FUNCTION_INFO_V1(mvarchar_mchar);
+Datum       mvarchar_mchar(PG_FUNCTION_ARGS);
+Datum       
+mvarchar_mchar(PG_FUNCTION_ARGS) {
+	MVarChar	*source = PG_GETARG_MVARCHAR(0);
+	MChar	*result;
+	int32    typmod = PG_GETARG_INT32(1);
+#ifdef NOT_USED
+	bool     isExplicit = PG_GETARG_BOOL(2);
+#endif
+
+	result = palloc( MVARCHARLENGTH(source) +  MCHARHDRSZ );
+	SET_VARSIZE(result, MVARCHARLENGTH(source) +  MCHARHDRSZ);
+	memcpy( result->data, source->data, MVARCHARLENGTH(source));
+
+	PG_FREE_IF_COPY(source,0);
+	
+	mchar_strip( result, typmod );
+
+	PG_RETURN_MCHAR(result);
+}
+
+PG_FUNCTION_INFO_V1(mchar_mvarchar);
+Datum       mchar_mvarchar(PG_FUNCTION_ARGS);
+Datum       
+mchar_mvarchar(PG_FUNCTION_ARGS) {
+	MChar	*source = PG_GETARG_MCHAR(0);
+	MVarChar	*result;
+	int32    typmod = PG_GETARG_INT32(1);
+	int32	 scharlen = u_countChar32(source->data, UCHARLENGTH(source));
+	int32	 curlen = 0, maxcharlen;
+#ifdef NOT_USED
+	bool     isExplicit = PG_GETARG_BOOL(2);
+#endif
+
+	maxcharlen = (source->typmod > 0) ? source->typmod : scharlen;
+
+	result = palloc( MVARCHARHDRSZ + sizeof(UChar) * 2 * maxcharlen );
+
+	curlen = UCHARLENGTH( source );
+	if ( curlen > 0 )
+		memcpy( result->data, source->data, MCHARLENGTH(source) );
+	if ( source->typmod > 0 && scharlen < source->typmod  ) {
+		FillWhiteSpace( result->data + curlen, source->typmod-scharlen );
+		curlen += source->typmod-scharlen;
+	}
+	SET_VARSIZE(result, MVARCHARHDRSZ + curlen *sizeof(UChar));
+
+	PG_FREE_IF_COPY(source,0);
+	
+	mvarchar_strip( result, typmod );
+
+	PG_RETURN_MCHAR(result);
+}
+
+PG_FUNCTION_INFO_V1(mchar_send);
+Datum       mchar_send(PG_FUNCTION_ARGS);
+Datum       
+mchar_send(PG_FUNCTION_ARGS) {
+	MChar	*in = PG_GETARG_MCHAR(0);
+	size_t	inlen = UCHARLENGTH(in);
+	size_t  charlen = u_countChar32(in->data, inlen);
+	StringInfoData buf;
+
+	Assert( in->typmod < 0 || charlen<=in->typmod );
+
+	pq_begintypsend(&buf);
+	pq_sendbytes(&buf, (char*)in->data, inlen * sizeof(UChar) );
+
+	if ( in->typmod>0 && charlen < in->typmod ) {
+		int		nw = in->typmod - charlen;
+		UChar	*white = palloc( sizeof(UChar) * nw );
+
+		FillWhiteSpace( white, nw );
+		pq_sendbytes(&buf, (char*)white, sizeof(UChar) * nw);
+		pfree(white);
+	}
+
+	PG_FREE_IF_COPY(in,0);
+
+	PG_RETURN_BYTEA_P(pq_endtypsend(&buf));	
+}
+
+PG_FUNCTION_INFO_V1(mchar_recv);
+Datum       mchar_recv(PG_FUNCTION_ARGS);
+Datum       
+mchar_recv(PG_FUNCTION_ARGS) {
+	StringInfo  buf = (StringInfo) PG_GETARG_POINTER(0);
+	MChar		*res; 
+	int			nbytes;
+#ifdef NOT_USED
+	Oid         typelem = PG_GETARG_OID(1);
+#endif
+	int32       atttypmod = PG_GETARG_INT32(2);
+
+	nbytes = buf->len - buf->cursor;
+	res = (MChar*)palloc( nbytes + MCHARHDRSZ );
+	res->len = nbytes + MCHARHDRSZ;
+	res->typmod = -1;
+	SET_VARSIZE(res, res->len);
+	pq_copymsgbytes(buf, (char*)res->data, nbytes);
+
+	mchar_strip( res, atttypmod );
+
+	PG_RETURN_MCHAR(res);	
+}
+
+PG_FUNCTION_INFO_V1(mvarchar_send);
+Datum       mvarchar_send(PG_FUNCTION_ARGS);
+Datum       
+mvarchar_send(PG_FUNCTION_ARGS) {
+	MVarChar	*in = PG_GETARG_MVARCHAR(0);
+	size_t	inlen = UVARCHARLENGTH(in);
+	StringInfoData buf;
+
+	pq_begintypsend(&buf);
+	pq_sendbytes(&buf, (char*)in->data, inlen * sizeof(UChar) );
+
+	PG_FREE_IF_COPY(in,0);
+
+	PG_RETURN_BYTEA_P(pq_endtypsend(&buf));	
+}
+
+PG_FUNCTION_INFO_V1(mvarchar_recv);
+Datum       mvarchar_recv(PG_FUNCTION_ARGS);
+Datum       
+mvarchar_recv(PG_FUNCTION_ARGS) {
+	StringInfo  buf = (StringInfo) PG_GETARG_POINTER(0);
+	MVarChar	*res; 
+	int			nbytes;
+#ifdef NOT_USED
+	Oid         typelem = PG_GETARG_OID(1);
+#endif
+	int32       atttypmod = PG_GETARG_INT32(2);
+
+	nbytes = buf->len - buf->cursor;
+	res = (MVarChar*)palloc( nbytes + MVARCHARHDRSZ );
+	res->len = nbytes + MVARCHARHDRSZ;
+	SET_VARSIZE(res, res->len);
+	pq_copymsgbytes(buf, (char*)res->data, nbytes);
+
+	mvarchar_strip( res, atttypmod );
+
+	PG_RETURN_MVARCHAR(res);	
+}
+
+
diff -ruN a/contrib/mchar/mchar_like.c b/contrib/mchar/mchar_like.c
--- a/contrib/mchar/mchar_like.c	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/mchar_like.c	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,862 @@
+#include "mchar.h"
+#include "mb/pg_wchar.h"
+
+#include "catalog/pg_collation.h"
+#include "utils/selfuncs.h"
+#include "nodes/primnodes.h"
+#include "nodes/makefuncs.h"
+#include "regex/regex.h"
+
+/*
+**  Originally written by Rich $alz, mirror!rs, Wed Nov 26 19:03:17 EST 1986.
+**  Rich $alz is now <rsalz@bbn.com>.
+**  Special thanks to Lars Mathiesen <thorinn@diku.dk> for the LABORT code.
+**
+**  This code was shamelessly stolen from the "pql" code by myself and
+**  slightly modified :)
+**
+**  All references to the word "star" were replaced by "percent"
+**  All references to the word "wild" were replaced by "like"
+**
+**  All the nice shell RE matching stuff was replaced by just "_" and "%"
+**
+**  As I don't have a copy of the SQL standard handy I wasn't sure whether
+**  to leave in the '\' escape character handling.
+**
+**  Keith Parks. <keith@mtcc.demon.co.uk>
+**
+**  SQL92 lets you specify the escape character by saying
+**  LIKE <pattern> ESCAPE <escape character>. We are a small operation
+**  so we force you to use '\'. - ay 7/95
+**
+**  Now we have the like_escape() function that converts patterns with
+**  any specified escape character (or none at all) to the internal
+**  default escape character, which is still '\'. - tgl 9/2000
+**
+** The code is rewritten to avoid requiring null-terminated strings,
+** which in turn allows us to leave out some memcpy() operations.
+** This code should be faster and take less memory, but no promises...
+** - thomas 2000-08-06
+**
+** Adopted for UTF-16 by teodor
+*/
+
+#define LIKE_TRUE                       1
+#define LIKE_FALSE                      0
+#define LIKE_ABORT                      (-1)
+
+
+static int
+uchareq(UChar *p1, UChar *p2) {
+	int l1=0, l2=0;
+	/*
+	 * Count length of char:
+	 * We suppose that string is correct!!
+	 */
+	U16_FWD_1(p1, l1, 2);
+	U16_FWD_1(p2, l2, 2);
+
+	return (UCharCaseCompare(p1, l1, p2, l2)==0) ? 1 : 0;
+}
+
+#define NextChar(p, plen) 			\
+	do {							\
+		int __l = 0;				\
+		U16_FWD_1((p), __l, (plen));\
+		(p) +=__l;					\
+		(plen) -=__l;				\
+	} while(0)
+
+#define CopyAdvChar(dst, src, srclen) 	\
+	do { 								\
+		int __l = 0;					\
+		U16_FWD_1((src), __l, (srclen));\
+		(srclen) -= __l;				\
+		while (__l-- > 0)				\
+			*(dst)++ = *(src)++;		\
+	} while (0)
+		
+
+static UChar	UCharPercent = 0;
+static UChar	UCharBackSlesh = 0;
+static UChar	UCharUnderLine = 0;
+static UChar	UCharStar = 0;
+static UChar	UCharDotDot = 0;
+static UChar	UCharUp = 0;
+static UChar	UCharLBracket = 0;
+static UChar	UCharQ = 0;
+static UChar	UCharRBracket = 0;
+static UChar	UCharDollar = 0;
+static UChar	UCharDot = 0;
+static UChar	UCharLFBracket = 0;
+static UChar	UCharRFBracket = 0;
+static UChar	UCharQuote = 0;
+static UChar	UCharSpace = 0;
+
+#define MkUChar(uc, c) 	do {			\
+	char __c = (c); 					\
+	u_charsToUChars( &__c, &(uc), 1 );	\
+} while(0)
+
+#define	SET_UCHAR	if ( UCharPercent == 0 ) {	\
+		MkUChar( UCharPercent, '%' );			\
+		MkUChar( UCharBackSlesh, '\\' );		\
+		MkUChar( UCharUnderLine, '_' );			\
+		MkUChar( UCharStar, '*' );				\
+		MkUChar( UCharDotDot, ':' );			\
+		MkUChar( UCharUp, '^' );				\
+		MkUChar( UCharLBracket, '(' );			\
+		MkUChar( UCharQ, '?' );					\
+		MkUChar( UCharRBracket, ')' );			\
+		MkUChar( UCharDollar, '$' );			\
+		MkUChar( UCharDot, '.' );				\
+		MkUChar( UCharLFBracket, '{' );			\
+		MkUChar( UCharRFBracket, '}' );			\
+		MkUChar( UCharQuote, '"' );				\
+		MkUChar( UCharSpace, ' ' );				\
+	}
+
+int
+m_isspace(UChar c) {
+	SET_UCHAR;
+
+	return (c == UCharSpace);
+}
+
+static int
+MatchUChar(UChar *t, int tlen, UChar *p, int plen) {
+	SET_UCHAR;
+	
+	/* Fast path for match-everything pattern */
+	if ((plen == 1) && (*p == UCharPercent))
+		return LIKE_TRUE;
+
+	while ((tlen > 0) && (plen > 0)) {
+		if (*p == UCharBackSlesh) {
+			/* Next pattern char must match literally, whatever it is */
+			NextChar(p, plen);
+			if ((plen <= 0) || !uchareq(t, p))
+				return LIKE_FALSE;
+		} else if (*p == UCharPercent) {
+			/* %% is the same as % according to the SQL standard */
+			/* Advance past all %'s */
+			while ((plen > 0) && (*p == UCharPercent))
+				NextChar(p, plen);
+			/* Trailing percent matches everything. */
+			if (plen <= 0)
+				return LIKE_TRUE;
+
+			/*
+			 * Otherwise, scan for a text position at which we can match the
+			 * rest of the pattern.
+			 */
+			while (tlen > 0) {
+				/*
+				 * Optimization to prevent most recursion: don't recurse
+				 * unless first pattern char might match this text char.
+				 */
+				if (uchareq(t, p) || (*p == UCharBackSlesh) || (*p == UCharUnderLine)) {
+					int         matched = MatchUChar(t, tlen, p, plen);
+
+					if (matched != LIKE_FALSE)
+						return matched; /* TRUE or ABORT */
+				}
+
+				NextChar(t, tlen);
+			}
+
+			/*
+			 * End of text with no match, so no point in trying later places
+			 * to start matching this pattern.
+			 */
+			return LIKE_ABORT;
+		} if ((*p != UCharUnderLine) && !uchareq(t, p)) {
+			/*
+			 * Not the single-character wildcard and no explicit match? Then
+			 * time to quit...
+			 */
+			return LIKE_FALSE;
+		}
+
+		NextChar(t, tlen);
+		NextChar(p, plen);
+	}
+
+	if (tlen > 0)
+		return LIKE_FALSE;      /* end of pattern, but not of text */
+
+	/* End of input string.  Do we have matching pattern remaining? */
+	while ((plen > 0) && (*p == UCharPercent))   /* allow multiple %'s at end of
+										 		  * pattern */
+		NextChar(p, plen);
+	if (plen <= 0)
+		return LIKE_TRUE;
+
+	/*
+	 * End of text with no match, so no point in trying later places to start
+	 * matching this pattern.
+	 */
+
+	return LIKE_ABORT;
+}
+
+PG_FUNCTION_INFO_V1( mvarchar_like );
+Datum mvarchar_like( PG_FUNCTION_ARGS );
+Datum
+mvarchar_like( PG_FUNCTION_ARGS ) {
+	MVarChar *str = PG_GETARG_MVARCHAR(0);
+	MVarChar *pat = PG_GETARG_MVARCHAR(1);
+	bool        result;
+
+	result = MatchUChar( str->data, UVARCHARLENGTH(str), pat->data, UVARCHARLENGTH(pat) );
+
+	PG_FREE_IF_COPY(str,0);
+	PG_FREE_IF_COPY(pat,1);
+
+	PG_RETURN_BOOL(result == LIKE_TRUE);
+}
+
+PG_FUNCTION_INFO_V1( mvarchar_notlike );
+Datum mvarchar_notlike( PG_FUNCTION_ARGS );
+Datum
+mvarchar_notlike( PG_FUNCTION_ARGS ) {
+	bool res = DatumGetBool( DirectFunctionCall2(
+			mvarchar_like, 
+			PG_GETARG_DATUM(0), 
+			PG_GETARG_DATUM(1)
+		));
+	PG_RETURN_BOOL( !res );
+}
+
+/*
+ * Removes trailing spaces in '111 %' pattern
+ */
+static UChar *
+removeTrailingSpaces( UChar *src, int srclen, int *dstlen, bool *isSpecialLast) {
+	UChar* dst = src;
+	UChar *ptr, *dptr, *markptr;
+
+	*dstlen = srclen;
+	ptr = src + srclen-1;
+	SET_UCHAR;
+
+	*isSpecialLast = ( srclen > 0 && (u_isspace(*ptr) || *ptr == UCharPercent || *ptr == UCharUnderLine ) ) ? true : false; 
+	while( ptr>=src ) {
+		if ( *ptr == UCharPercent || *ptr == UCharUnderLine ) {
+			if ( ptr==src )
+				return dst; /* first character */
+
+			if ( *(ptr-1) == UCharBackSlesh )
+				return dst; /* use src as is */
+
+			if ( u_isspace( *(ptr-1) ) ) {
+				ptr--;
+				break; /* % or _ is after space which should be removed */
+			}
+		} else {
+			return dst;
+		}
+		ptr--;
+	}
+
+	markptr = ptr+1;
+	dst = (UChar*)palloc( sizeof(UChar) * srclen );
+
+	/* find last non-space character */
+	while( ptr>=src && u_isspace(*ptr) )
+		ptr--;
+
+	dptr = dst + (ptr-src+1);
+
+	if ( ptr>=src ) 
+		memcpy( dst, src, sizeof(UChar) * (ptr-src+1) );
+
+	while( markptr - src < srclen ) {
+		*dptr = *markptr;
+		dptr++;
+		markptr++;
+	}
+
+	*dstlen = dptr - dst;
+	return dst;
+}
+
+static UChar*
+addTrailingSpace( MChar *src, int *newlen ) {
+	int	scharlen = u_countChar32(src->data, UCHARLENGTH(src));
+
+	if ( src->typmod > scharlen ) {
+		UChar	*res = (UChar*) palloc( sizeof(UChar) * (UCHARLENGTH(src) + src->typmod) );
+
+		memcpy( res, src->data, sizeof(UChar) * UCHARLENGTH(src));
+		FillWhiteSpace( res+UCHARLENGTH(src), src->typmod - scharlen );
+
+		*newlen = src->typmod;
+
+		return res;
+	} else {
+		*newlen = UCHARLENGTH(src);
+		return src->data;
+	}
+}
+
+PG_FUNCTION_INFO_V1( mchar_like );
+Datum mchar_like( PG_FUNCTION_ARGS );
+Datum
+mchar_like( PG_FUNCTION_ARGS ) {
+	MChar *str = PG_GETARG_MCHAR(0);
+	MVarChar *pat = PG_GETARG_MVARCHAR(1);
+	bool        result, isNeedAdd = false;
+	UChar		*cleaned, *filled;
+	int			clen=0, flen=0;
+
+	cleaned = removeTrailingSpaces(pat->data, UVARCHARLENGTH(pat), &clen, &isNeedAdd);
+	if ( isNeedAdd )
+		filled  = addTrailingSpace(str, &flen);
+	else {
+		filled = str->data;
+		flen = UCHARLENGTH(str);
+	}
+
+	result = MatchUChar( filled, flen, cleaned, clen );
+
+	if ( pat->data != cleaned )
+		pfree( cleaned );
+	if ( str->data != filled )
+		pfree( filled );
+
+	PG_FREE_IF_COPY(str,0);
+	PG_FREE_IF_COPY(pat,1);
+
+	
+	PG_RETURN_BOOL(result == LIKE_TRUE);
+}
+
+PG_FUNCTION_INFO_V1( mchar_notlike );
+Datum mchar_notlike( PG_FUNCTION_ARGS );
+Datum
+mchar_notlike( PG_FUNCTION_ARGS ) {
+	bool res = DatumGetBool( DirectFunctionCall2(
+			mchar_like, 
+			PG_GETARG_DATUM(0), 
+			PG_GETARG_DATUM(1)
+		));
+
+	PG_RETURN_BOOL( !res );
+}
+
+
+
+PG_FUNCTION_INFO_V1( mchar_pattern_fixed_prefix );
+Datum mchar_pattern_fixed_prefix( PG_FUNCTION_ARGS );
+Datum
+mchar_pattern_fixed_prefix( PG_FUNCTION_ARGS ) {
+	Const			*patt = 	(Const*)PG_GETARG_POINTER(0);
+	Pattern_Type	ptype = 	(Pattern_Type)PG_GETARG_INT32(1);
+	Const			**prefix = 	(Const**)PG_GETARG_POINTER(2);
+	UChar			*spatt;	
+	int32			slen, prefixlen=0, restlen=0, i=0;
+	MVarChar		*sprefix;
+	MVarChar		*srest;
+	Pattern_Prefix_Status	status = Pattern_Prefix_None; 
+
+	*prefix = NULL;
+
+	if ( ptype != Pattern_Type_Like )
+		PG_RETURN_INT32(Pattern_Prefix_None);
+
+	SET_UCHAR;
+
+	spatt = ((MVarChar*)DatumGetPointer(patt->constvalue))->data;
+	slen = UVARCHARLENGTH( DatumGetPointer(patt->constvalue) );
+
+	sprefix = (MVarChar*)palloc( MCHARHDRSZ /*The biggest hdr!! */ + sizeof(UChar) * slen );
+	srest = (MVarChar*)palloc( MCHARHDRSZ /*The biggest hdr!! */ + sizeof(UChar) * slen );
+
+	while( prefixlen < slen && i < slen ) {
+		if ( spatt[i] == UCharPercent || spatt[i] == UCharUnderLine )
+			break;
+		else if ( spatt[i] == UCharBackSlesh ) {
+			i++;
+			if ( i>= slen )
+				break;
+		}
+		sprefix->data[ prefixlen++ ] = spatt[i++];
+	}
+
+	while( prefixlen > 0 ) {
+		if ( ! u_isspace( sprefix->data[ prefixlen-1 ] ) ) 
+			break;
+		prefixlen--;
+	}
+
+	if ( prefixlen == 0 )
+		PG_RETURN_INT32(Pattern_Prefix_None);
+
+	for(;i<slen;i++) 
+		srest->data[ restlen++ ] = spatt[i];
+
+	SET_VARSIZE(sprefix, sizeof(UChar) * prefixlen + MVARCHARHDRSZ);	
+	SET_VARSIZE(srest, sizeof(UChar) * restlen + MVARCHARHDRSZ);	
+
+	*prefix = makeConst( patt->consttype, -1, DEFAULT_COLLATION_OID, VARSIZE(sprefix), PointerGetDatum(sprefix), false, false );
+
+	if ( prefixlen == slen )	/* in LIKE, an empty pattern is an exact match! */
+		status = Pattern_Prefix_Exact;
+	else if ( prefixlen > 0 )
+		status = Pattern_Prefix_Partial;
+
+	PG_RETURN_INT32( status );	
+}
+
+static bool 
+checkCmp( UChar *left, int32 leftlen, UChar *right, int32 rightlen ) {
+
+	return  (UCharCaseCompare( left, leftlen, right, rightlen) < 0 ) ? true : false;
+}
+
+
+PG_FUNCTION_INFO_V1( mchar_greaterstring );
+Datum mchar_greaterstring( PG_FUNCTION_ARGS );
+Datum
+mchar_greaterstring( PG_FUNCTION_ARGS ) {
+	Const			*patt = 	(Const*)PG_GETARG_POINTER(0);
+	char			*src  = 	(char*)DatumGetPointer( patt->constvalue ); 
+	int				dstlen, srclen  = 	VARSIZE(src);
+	char 			*dst = palloc( srclen );
+	UChar			*ptr, *srcptr;
+
+	memcpy( dst, src, srclen );
+
+	srclen = dstlen = UVARCHARLENGTH( dst );
+	ptr    = ((MVarChar*)dst)->data;
+	srcptr    = ((MVarChar*)src)->data;
+
+	while( dstlen > 0 ) {
+		UChar	*lastchar = ptr + dstlen - 1;
+
+		if ( !U16_IS_LEAD( *lastchar ) ) {
+			while( *lastchar<0xffff ) {
+
+				(*lastchar)++;
+
+				if ( ublock_getCode(*lastchar) == UBLOCK_INVALID_CODE || !checkCmp( srcptr, srclen, ptr, dstlen ) )
+					continue;
+				else {
+					SET_VARSIZE(dst, sizeof(UChar) * dstlen + MVARCHARHDRSZ);
+				
+					PG_RETURN_POINTER( makeConst( patt->consttype, -1, DEFAULT_COLLATION_OID, VARSIZE(dst), PointerGetDatum(dst), false, false ) );
+				}
+			}
+		}
+				
+		dstlen--;
+	}
+
+	PG_RETURN_POINTER(NULL);
+}
+
+static int 
+do_like_escape( UChar *pat, int plen, UChar *esc, int elen, UChar *result) {
+	UChar	*p = pat,*e =esc ,*r;
+	bool	afterescape;
+
+	r = result;
+	SET_UCHAR;
+
+	if ( elen == 0 ) {
+		/*
+		 * No escape character is wanted.  Double any backslashes in the
+		 * pattern to make them act like ordinary characters.
+		 */
+		while (plen > 0) {
+			if (*p == UCharBackSlesh ) 
+				*r++ = UCharBackSlesh;
+			CopyAdvChar(r, p, plen);
+		}
+	} else {
+		/*
+		 * The specified escape must be only a single character.
+		 */
+		NextChar(e, elen);
+
+		if (elen != 0)
+			ereport(ERROR,
+				(errcode(ERRCODE_INVALID_ESCAPE_SEQUENCE),
+				errmsg("invalid escape string"),
+				errhint("Escape string must be empty or one character.")));
+
+		e = esc;
+
+		/*
+		 * If specified escape is '\', just copy the pattern as-is.
+		 */
+		if ( *e == UCharBackSlesh ) {
+			memcpy(result, pat, plen * sizeof(UChar));
+			return plen;
+		}
+
+		/*
+		 * Otherwise, convert occurrences of the specified escape character to
+		 * '\', and double occurrences of '\' --- unless they immediately
+		 * follow an escape character!
+		 */
+		afterescape = false;
+
+		while (plen > 0) {
+			if ( uchareq(p,e) && !afterescape) {
+				*r++ = UCharBackSlesh;
+				NextChar(p, plen);
+				afterescape = true;
+			} else if ( *p == UCharBackSlesh ) {
+				*r++ = UCharBackSlesh;
+				if (!afterescape)
+					*r++ = UCharBackSlesh;
+				NextChar(p, plen);
+				afterescape = false;
+			} else {
+				CopyAdvChar(r, p, plen);
+				afterescape = false;
+			}
+		}
+	}
+
+	return  ( r -  result );
+}
+
+PG_FUNCTION_INFO_V1( mvarchar_like_escape );
+Datum mvarchar_like_escape( PG_FUNCTION_ARGS );
+Datum
+mvarchar_like_escape( PG_FUNCTION_ARGS ) {
+	MVarChar	*pat = PG_GETARG_MVARCHAR(0);
+	MVarChar	*esc = PG_GETARG_MVARCHAR(1);
+	MVarChar	*result;
+
+	result = (MVarChar*)palloc( MVARCHARHDRSZ + sizeof(UChar)*2*UVARCHARLENGTH(pat) );
+	result->len = MVARCHARHDRSZ + do_like_escape( pat->data, UVARCHARLENGTH(pat),
+							 	  				  esc->data, UVARCHARLENGTH(esc),
+								  				  result->data ) * sizeof(UChar);
+
+	SET_VARSIZE(result, result->len);
+	PG_FREE_IF_COPY(pat,0);
+	PG_FREE_IF_COPY(esc,1);
+
+	PG_RETURN_MVARCHAR(result);
+}
+
+#define RE_CACHE_SIZE	32
+typedef struct ReCache {
+	UChar	*pattern;
+	int		length;
+	int		flags;
+	regex_t	re;
+} ReCache;
+
+static int  num_res = 0;
+static ReCache re_array[RE_CACHE_SIZE];  /* cached re's */
+static const int mchar_regex_flavor = REG_ADVANCED | REG_ICASE;
+
+static regex_t *
+RE_compile_and_cache(UChar *text_re, int text_re_len, int cflags) {
+	pg_wchar	*pattern;
+	size_t		pattern_len;
+	int			i;
+	int			regcomp_result;
+	ReCache		re_temp;
+	char		errMsg[128];
+
+
+	for (i = 0; i < num_res; i++) {
+		if ( re_array[i].length == text_re_len &&
+			 re_array[i].flags == cflags &&
+			 memcmp(re_array[i].pattern, text_re, sizeof(UChar)*text_re_len) == 0 ) {
+
+			 /* Found, move it to front */
+			 if ( i>0 ) {
+				re_temp = re_array[i];
+				memmove(&re_array[1], &re_array[0], i * sizeof(ReCache));
+				re_array[0] = re_temp;
+			}
+
+			return &re_array[0].re;
+		}
+	}
+
+	pattern = (pg_wchar *) palloc((1 + text_re_len) * sizeof(pg_wchar));
+	pattern_len =  UChar2Wchar(text_re, text_re_len, pattern);
+
+	regcomp_result = pg_regcomp(&re_temp.re,
+								pattern,
+								pattern_len,
+								cflags,
+								DEFAULT_COLLATION_OID);
+	pfree( pattern );
+
+	if (regcomp_result != REG_OKAY) {
+		pg_regerror(regcomp_result, &re_temp.re, errMsg, sizeof(errMsg));
+		ereport(ERROR,
+				(errcode(ERRCODE_INVALID_REGULAR_EXPRESSION),
+				errmsg("invalid regular expression: %s", errMsg)));
+	}
+
+	re_temp.pattern = malloc( text_re_len*sizeof(UChar) );
+	if ( re_temp.pattern == NULL )
+		elog(ERROR,"Out of memory");
+
+	memcpy(re_temp.pattern, text_re, text_re_len*sizeof(UChar) );
+	re_temp.length = text_re_len;
+	re_temp.flags = cflags;
+
+	if (num_res >= RE_CACHE_SIZE) {
+		--num_res;
+		Assert(num_res < RE_CACHE_SIZE);
+		pg_regfree(&re_array[num_res].re);
+		free(re_array[num_res].pattern);
+	}
+
+	if (num_res > 0)
+		memmove(&re_array[1], &re_array[0], num_res * sizeof(ReCache));
+
+	re_array[0] = re_temp;
+	num_res++;
+
+	return &re_array[0].re;
+}
+
+static bool
+RE_compile_and_execute(UChar *pat, int pat_len, UChar *dat, int dat_len,
+						int cflags, int nmatch, regmatch_t *pmatch) {
+	pg_wchar   *data;
+	size_t      data_len;
+	int         regexec_result;
+	regex_t    *re;
+	char        errMsg[128];
+
+	data = (pg_wchar *) palloc((1+dat_len) * sizeof(pg_wchar));
+	data_len = UChar2Wchar(dat, dat_len, data);
+
+	re = RE_compile_and_cache(pat, pat_len, cflags);
+
+	regexec_result = pg_regexec(re,
+								data,
+								data_len,
+								0,
+								NULL,
+								nmatch,
+								pmatch,
+								0);
+	pfree(data);
+
+	if (regexec_result != REG_OKAY && regexec_result != REG_NOMATCH) {
+		/* re failed??? */
+		pg_regerror(regexec_result, re, errMsg, sizeof(errMsg));
+		ereport(ERROR,
+				(errcode(ERRCODE_INVALID_REGULAR_EXPRESSION),
+				errmsg("regular expression failed: %s", errMsg)));
+	}
+
+	return (regexec_result == REG_OKAY);
+}
+
+PG_FUNCTION_INFO_V1( mchar_regexeq );
+Datum mchar_regexeq( PG_FUNCTION_ARGS );
+Datum
+mchar_regexeq( PG_FUNCTION_ARGS ) {
+	MChar	*t = PG_GETARG_MCHAR(0);
+	MChar	*p = PG_GETARG_MCHAR(1);
+	bool 	res;
+
+	res = RE_compile_and_execute(p->data, UCHARLENGTH(p),
+								 t->data, UCHARLENGTH(t),
+								 mchar_regex_flavor,
+								 0, NULL);
+	PG_FREE_IF_COPY(t, 0);
+	PG_FREE_IF_COPY(p, 1);
+
+	PG_RETURN_BOOL(res);
+}
+
+PG_FUNCTION_INFO_V1( mchar_regexne );
+Datum mchar_regexne( PG_FUNCTION_ARGS );
+Datum
+mchar_regexne( PG_FUNCTION_ARGS ) {
+	MChar	*t = PG_GETARG_MCHAR(0);
+	MChar	*p = PG_GETARG_MCHAR(1);
+	bool 	res;
+
+	res = RE_compile_and_execute(p->data, UCHARLENGTH(p),
+								 t->data, UCHARLENGTH(t),
+								 mchar_regex_flavor,
+								 0, NULL);
+	PG_FREE_IF_COPY(t, 0);
+	PG_FREE_IF_COPY(p, 1);
+
+	PG_RETURN_BOOL(!res);
+}
+
+PG_FUNCTION_INFO_V1( mvarchar_regexeq );
+Datum mvarchar_regexeq( PG_FUNCTION_ARGS );
+Datum
+mvarchar_regexeq( PG_FUNCTION_ARGS ) {
+	MVarChar	*t = PG_GETARG_MVARCHAR(0);
+	MVarChar	*p = PG_GETARG_MVARCHAR(1);
+	bool 	res;
+
+	res = RE_compile_and_execute(p->data, UVARCHARLENGTH(p),
+								 t->data, UVARCHARLENGTH(t),
+								 mchar_regex_flavor,
+								 0, NULL);
+	PG_FREE_IF_COPY(t, 0);
+	PG_FREE_IF_COPY(p, 1);
+
+	PG_RETURN_BOOL(res);
+}
+
+PG_FUNCTION_INFO_V1( mvarchar_regexne );
+Datum mvarchar_regexne( PG_FUNCTION_ARGS );
+Datum
+mvarchar_regexne( PG_FUNCTION_ARGS ) {
+	MVarChar	*t = PG_GETARG_MVARCHAR(0);
+	MVarChar	*p = PG_GETARG_MVARCHAR(1);
+	bool 	res;
+
+	res = RE_compile_and_execute(p->data, UVARCHARLENGTH(p),
+								 t->data, UVARCHARLENGTH(t),
+								 mchar_regex_flavor,
+								 0, NULL);
+	PG_FREE_IF_COPY(t, 0);
+	PG_FREE_IF_COPY(p, 1);
+
+	PG_RETURN_BOOL(!res);
+}
+
+static int 
+do_similar_escape(UChar *p, int plen, UChar *e, int elen, UChar *result) {
+	UChar		*r;
+	bool        afterescape = false;
+	int         nquotes = 0;
+
+ 	SET_UCHAR;
+
+	if (e==NULL || elen <0 ) {
+		e = &UCharBackSlesh;
+		elen = 1;
+	} else {
+		if ( elen == 0 )
+			e = NULL;
+		else if ( elen != 1)
+			ereport(ERROR,
+					(errcode(ERRCODE_INVALID_ESCAPE_SEQUENCE),
+					errmsg("invalid escape string"),
+					errhint("Escape string must be empty or one character.")));
+	}
+
+	/*
+	 * Look explanation of following in ./utils/adt/regexp.c 
+	 */
+	r = result;
+
+	*r++ = UCharStar;
+	*r++ = UCharStar;
+	*r++ = UCharStar;
+	*r++ = UCharDotDot;
+	*r++ = UCharUp;
+	*r++ = UCharLBracket;
+	*r++ = UCharQ;
+	*r++ = UCharDotDot;
+
+	while( plen>0 ) {
+		if (afterescape) {
+			if ( *p == UCharQuote ) {
+				*r++ = ((nquotes++ % 2) == 0) ? UCharLBracket : UCharRBracket;
+			} else {
+				*r++ = UCharBackSlesh;
+				*r++ = *p;
+			}
+			 afterescape = false;
+		} else if ( e && *p == *e ) {
+			 afterescape = true;
+		} else if ( *p == UCharPercent ) {
+			*r++ = UCharDot;
+			*r++ = UCharStar;
+		} else if ( *p == UCharUnderLine ) {
+			*r++ = UCharDot;
+		} else if ( *p == UCharBackSlesh || *p == UCharDot || *p == UCharQ || *p == UCharLFBracket ) {
+			*r++ = UCharBackSlesh;
+			*r++ = *p;
+		} else
+			*r++ = *p;
+
+		p++, plen--;
+	}
+	
+	*r++ = UCharRBracket;
+	*r++ = UCharDollar;
+
+	return r-result;
+}
+
+PG_FUNCTION_INFO_V1( mchar_similar_escape );
+Datum mchar_similar_escape( PG_FUNCTION_ARGS );
+Datum
+mchar_similar_escape( PG_FUNCTION_ARGS ) {
+	MChar	*pat;
+	MChar	*esc;
+	MChar	*result;
+
+	if (PG_ARGISNULL(0))
+		PG_RETURN_NULL();
+	pat = PG_GETARG_MCHAR(0);
+
+	if (PG_ARGISNULL(1)) {
+		esc = NULL;
+	} else {
+		esc = PG_GETARG_MCHAR(1);
+	}
+
+	result = (MChar*)palloc( MCHARHDRSZ + sizeof(UChar)*(10 + 2*UCHARLENGTH(pat)) );
+	result->len = MCHARHDRSZ + do_similar_escape( pat->data, UCHARLENGTH(pat),
+							 	  (esc) ? esc->data : NULL, (esc) ? UCHARLENGTH(esc) : -1,
+								  result->data ) * sizeof(UChar);
+	result->typmod=-1;
+
+	SET_VARSIZE(result, result->len);
+	PG_FREE_IF_COPY(pat,0);
+	if ( esc )
+		PG_FREE_IF_COPY(esc,1);
+
+	PG_RETURN_MCHAR(result);
+}
+
+PG_FUNCTION_INFO_V1( mvarchar_similar_escape );
+Datum mvarchar_similar_escape( PG_FUNCTION_ARGS );
+Datum
+mvarchar_similar_escape( PG_FUNCTION_ARGS ) {
+	MVarChar	*pat;
+	MVarChar	*esc;
+	MVarChar	*result;
+
+	if (PG_ARGISNULL(0))
+		PG_RETURN_NULL();
+	pat = PG_GETARG_MVARCHAR(0);
+
+	if (PG_ARGISNULL(1)) {
+		esc = NULL;
+	} else {
+		esc = PG_GETARG_MVARCHAR(1);
+	}
+
+	result = (MVarChar*)palloc( MVARCHARHDRSZ + sizeof(UChar)*(10 + 2*UVARCHARLENGTH(pat)) );
+	result->len = MVARCHARHDRSZ + do_similar_escape( pat->data, UVARCHARLENGTH(pat),
+							 	  				(esc) ? esc->data : NULL, (esc) ? UVARCHARLENGTH(esc) : -1,
+								  				  result->data ) * sizeof(UChar);
+
+	SET_VARSIZE(result, result->len);
+	PG_FREE_IF_COPY(pat,0);
+	if ( esc )
+		PG_FREE_IF_COPY(esc,1);
+
+	PG_RETURN_MVARCHAR(result);
+}
+
+#define RE_CACHE_SIZE	32
diff -ruN a/contrib/mchar/mchar_op.c b/contrib/mchar/mchar_op.c
--- a/contrib/mchar/mchar_op.c	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/mchar_op.c	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,449 @@
+#include "mchar.h"
+
+int
+lengthWithoutSpaceVarChar(MVarChar	*m) {
+	int l = UVARCHARLENGTH(m);
+
+	while( l>0 && m_isspace( m->data[ l-1 ] ) ) 
+		l--;
+
+	return l;
+}
+
+int
+lengthWithoutSpaceChar(MChar	*m) {
+	int l = UCHARLENGTH(m);
+
+	while( l>0 && m_isspace( m->data[ l-1 ] ) ) 
+		l--;
+
+	return l;
+}
+
+static inline int
+mchar_icase_compare( MChar *a, MChar *b ) {
+	return UCharCaseCompare( 
+		a->data, lengthWithoutSpaceChar(a),
+		b->data, lengthWithoutSpaceChar(b)
+	);
+}
+
+static inline int
+mchar_case_compare( MChar *a, MChar *b ) {
+	return UCharCompare( 
+		a->data, lengthWithoutSpaceChar(a),
+		b->data, lengthWithoutSpaceChar(b)
+	);
+}
+
+#define MCHARCMPFUNC( c, type, action, ret ) 		\
+PG_FUNCTION_INFO_V1( mchar_##c##_##type ); 		\
+Datum      mchar_##c##_##type(PG_FUNCTION_ARGS);\
+Datum											\
+mchar_##c##_##type(PG_FUNCTION_ARGS) {			\
+	MChar *a = PG_GETARG_MCHAR(0);				\
+	MChar *b = PG_GETARG_MCHAR(1);				\
+	int 	res = mchar_##c##_compare(a,b);		\
+												\
+	PG_FREE_IF_COPY(a,0);						\
+	PG_FREE_IF_COPY(b,1);						\
+	PG_RETURN_##ret( res action 0 );			\
+}
+
+
+MCHARCMPFUNC( case, eq, ==, BOOL )
+MCHARCMPFUNC( case, ne, !=, BOOL )
+MCHARCMPFUNC( case, lt, <, BOOL )
+MCHARCMPFUNC( case, le, <=, BOOL )
+MCHARCMPFUNC( case, ge, >=, BOOL )
+MCHARCMPFUNC( case, gt, >, BOOL )
+MCHARCMPFUNC( case, cmp, +, INT32 )
+
+MCHARCMPFUNC( icase, eq, ==, BOOL )
+MCHARCMPFUNC( icase, ne, !=, BOOL )
+MCHARCMPFUNC( icase, lt, <, BOOL )
+MCHARCMPFUNC( icase, le, <=, BOOL )
+MCHARCMPFUNC( icase, ge, >=, BOOL )
+MCHARCMPFUNC( icase, gt, >, BOOL )
+MCHARCMPFUNC( icase, cmp, +, INT32 )
+
+PG_FUNCTION_INFO_V1( mchar_larger );
+Datum mchar_larger( PG_FUNCTION_ARGS );
+Datum
+mchar_larger( PG_FUNCTION_ARGS ) {
+	MChar *a = PG_GETARG_MCHAR(0);
+	MChar *b = PG_GETARG_MCHAR(1);
+	MChar *r;
+
+	r = ( mchar_icase_compare(a,b) > 0 ) ? a : b;
+
+	PG_RETURN_MCHAR(r);
+}
+
+PG_FUNCTION_INFO_V1( mchar_smaller );
+Datum mchar_smaller( PG_FUNCTION_ARGS );
+Datum
+mchar_smaller( PG_FUNCTION_ARGS ) {
+	MChar *a = PG_GETARG_MCHAR(0);
+	MChar *b = PG_GETARG_MCHAR(1);
+	MChar *r;
+
+	r = ( mchar_icase_compare(a,b) < 0 ) ? a : b;
+
+	PG_RETURN_MCHAR(r);
+}
+
+
+PG_FUNCTION_INFO_V1( mchar_concat );
+Datum mchar_concat( PG_FUNCTION_ARGS );
+Datum
+mchar_concat( PG_FUNCTION_ARGS ) {
+	MChar *a = PG_GETARG_MCHAR(0);
+	MChar *b = PG_GETARG_MCHAR(1);
+	MChar *result;
+	int	maxcharlen, curlen;
+	int	acharlen = u_countChar32(a->data, UCHARLENGTH(a)),
+		bcharlen = u_countChar32(b->data, UCHARLENGTH(b));
+
+
+	maxcharlen = ((a->typmod<=0) ? acharlen : a->typmod) + 
+				 ((b->typmod<=0) ? bcharlen : b->typmod);
+
+	result = (MChar*)palloc( MCHARHDRSZ + sizeof(UChar) * 2 * maxcharlen );
+
+	curlen = UCHARLENGTH( a );
+	if ( curlen > 0 )
+		memcpy( result->data, a->data, MCHARLENGTH(a) );
+	if ( a->typmod > 0 && acharlen < a->typmod  ) {
+		FillWhiteSpace( result->data + curlen, a->typmod-acharlen );
+		curlen += a->typmod-acharlen;
+	}
+
+	if ( UCHARLENGTH(b) > 0 ) {
+		memcpy( result->data + curlen, b->data, MCHARLENGTH( b ) );
+		curlen += UCHARLENGTH( b );
+	}
+	if ( b->typmod > 0 && bcharlen < b->typmod  ) {
+		FillWhiteSpace( result->data + curlen, b->typmod-bcharlen );
+		curlen += b->typmod-bcharlen;
+	}
+
+
+	result->typmod = -1;
+	SET_VARSIZE(result, sizeof(UChar) * curlen + MCHARHDRSZ);
+
+	PG_FREE_IF_COPY(a,0);
+	PG_FREE_IF_COPY(b,1);
+
+	PG_RETURN_MCHAR(result);
+}
+
+static inline int
+mvarchar_icase_compare( MVarChar *a, MVarChar *b ) {
+	
+	return UCharCaseCompare( 
+		a->data, lengthWithoutSpaceVarChar(a),
+		b->data, lengthWithoutSpaceVarChar(b)
+	);
+}
+
+static inline int
+mvarchar_case_compare( MVarChar *a, MVarChar *b ) {
+	return UCharCompare( 
+		a->data, lengthWithoutSpaceVarChar(a),
+		b->data, lengthWithoutSpaceVarChar(b)
+	);
+}
+
+#define MVARCHARCMPFUNC( c, type, action, ret ) 	\
+PG_FUNCTION_INFO_V1( mvarchar_##c##_##type ); 		\
+Datum      mvarchar_##c##_##type(PG_FUNCTION_ARGS);	\
+Datum												\
+mvarchar_##c##_##type(PG_FUNCTION_ARGS) {			\
+	MVarChar *a = PG_GETARG_MVARCHAR(0);			\
+	MVarChar *b = PG_GETARG_MVARCHAR(1);			\
+	int 	res = mvarchar_##c##_compare(a,b);		\
+													\
+	PG_FREE_IF_COPY(a,0);							\
+	PG_FREE_IF_COPY(b,1);							\
+	PG_RETURN_##ret( res action	0 );				\
+}
+
+
+MVARCHARCMPFUNC( case, eq, ==, BOOL )
+MVARCHARCMPFUNC( case, ne, !=, BOOL )
+MVARCHARCMPFUNC( case, lt, <, BOOL )
+MVARCHARCMPFUNC( case, le, <=, BOOL )
+MVARCHARCMPFUNC( case, ge, >=, BOOL )
+MVARCHARCMPFUNC( case, gt, >, BOOL )
+MVARCHARCMPFUNC( case, cmp, +, INT32 )
+
+MVARCHARCMPFUNC( icase, eq, ==, BOOL )
+MVARCHARCMPFUNC( icase, ne, !=, BOOL )
+MVARCHARCMPFUNC( icase, lt, <, BOOL )
+MVARCHARCMPFUNC( icase, le, <=, BOOL )
+MVARCHARCMPFUNC( icase, ge, >=, BOOL )
+MVARCHARCMPFUNC( icase, gt, >, BOOL )
+MVARCHARCMPFUNC( icase, cmp, +, INT32 )
+
+PG_FUNCTION_INFO_V1( mvarchar_larger );
+Datum mvarchar_larger( PG_FUNCTION_ARGS );
+Datum
+mvarchar_larger( PG_FUNCTION_ARGS ) {
+	MVarChar *a = PG_GETARG_MVARCHAR(0);
+	MVarChar *b = PG_GETARG_MVARCHAR(1);
+	MVarChar *r;
+
+	r = ( mvarchar_icase_compare(a,b) > 0 ) ? a : b;
+
+	PG_RETURN_MVARCHAR(r);
+}
+
+PG_FUNCTION_INFO_V1( mvarchar_smaller );
+Datum mvarchar_smaller( PG_FUNCTION_ARGS );
+Datum
+mvarchar_smaller( PG_FUNCTION_ARGS ) {
+	MVarChar *a = PG_GETARG_MVARCHAR(0);
+	MVarChar *b = PG_GETARG_MVARCHAR(1);
+	MVarChar *r;
+
+	r = ( mvarchar_icase_compare(a,b) < 0 ) ? a : b;
+
+	PG_RETURN_MVARCHAR(r);
+}
+
+PG_FUNCTION_INFO_V1( mvarchar_concat );
+Datum mvarchar_concat( PG_FUNCTION_ARGS );
+Datum
+mvarchar_concat( PG_FUNCTION_ARGS ) {
+	MVarChar *a = PG_GETARG_MVARCHAR(0);
+	MVarChar *b = PG_GETARG_MVARCHAR(1);
+	MVarChar *result;
+	int	curlen;
+	int	acharlen = u_countChar32(a->data, UVARCHARLENGTH(a)),
+		bcharlen = u_countChar32(b->data, UVARCHARLENGTH(b));
+
+	result = (MVarChar*)palloc( MVARCHARHDRSZ + sizeof(UChar) * 2 * (acharlen + bcharlen) );
+
+	curlen = UVARCHARLENGTH( a );
+	if ( curlen > 0 )
+		memcpy( result->data, a->data, MVARCHARLENGTH(a) );
+
+	if ( UVARCHARLENGTH(b) > 0 ) {
+		memcpy( result->data + curlen, b->data, MVARCHARLENGTH( b ) );
+		curlen += UVARCHARLENGTH( b );
+	}
+
+	SET_VARSIZE(result, sizeof(UChar) * curlen + MVARCHARHDRSZ);
+
+	PG_FREE_IF_COPY(a,0);
+	PG_FREE_IF_COPY(b,1);
+
+	PG_RETURN_MVARCHAR(result);
+}
+
+PG_FUNCTION_INFO_V1( mchar_mvarchar_concat );
+Datum mchar_mvarchar_concat( PG_FUNCTION_ARGS );
+Datum                                            
+mchar_mvarchar_concat( PG_FUNCTION_ARGS ) {
+	MChar *a = PG_GETARG_MCHAR(0);
+	MVarChar *b = PG_GETARG_MVARCHAR(1);
+	MVarChar *result;
+	int	curlen, maxcharlen;
+	int	acharlen = u_countChar32(a->data, UCHARLENGTH(a)),
+		bcharlen = u_countChar32(b->data, UVARCHARLENGTH(b));
+
+	maxcharlen = ((a->typmod<=0) ? acharlen : a->typmod) + bcharlen;
+
+	result = (MVarChar*)palloc( MVARCHARHDRSZ + sizeof(UChar) * 2 * maxcharlen );
+
+	curlen = UCHARLENGTH( a );
+	if ( curlen > 0 )
+		memcpy( result->data, a->data, MCHARLENGTH(a) );
+	if ( a->typmod > 0 && acharlen < a->typmod  ) {
+		FillWhiteSpace( result->data + curlen, a->typmod-acharlen );
+		curlen += a->typmod-acharlen;
+	}
+
+	if ( UVARCHARLENGTH(b) > 0 ) {
+		memcpy( result->data + curlen, b->data, MVARCHARLENGTH( b ) );
+		curlen += UVARCHARLENGTH( b );
+	}
+
+	SET_VARSIZE(result, sizeof(UChar) * curlen + MVARCHARHDRSZ);
+
+	PG_FREE_IF_COPY(a,0);
+	PG_FREE_IF_COPY(b,1);
+
+	PG_RETURN_MVARCHAR(result);
+}
+
+PG_FUNCTION_INFO_V1( mvarchar_mchar_concat );
+Datum mvarchar_mchar_concat( PG_FUNCTION_ARGS );
+Datum                                            
+mvarchar_mchar_concat( PG_FUNCTION_ARGS ) {
+	MVarChar *a = PG_GETARG_MVARCHAR(0);
+	MChar *b = PG_GETARG_MCHAR(1);
+	MVarChar *result;
+	int	curlen, maxcharlen;
+	int	acharlen = u_countChar32(a->data, UVARCHARLENGTH(a)),
+		bcharlen = u_countChar32(b->data, UCHARLENGTH(b));
+
+	maxcharlen = acharlen + ((b->typmod<=0) ? bcharlen : b->typmod);
+
+	result = (MVarChar*)palloc( MVARCHARHDRSZ + sizeof(UChar) * 2 * maxcharlen );
+
+	curlen = UVARCHARLENGTH( a );
+	if ( curlen > 0 )
+		memcpy( result->data, a->data, MVARCHARLENGTH(a) );
+
+	if ( UCHARLENGTH(b) > 0 ) {
+		memcpy( result->data + curlen, b->data, MCHARLENGTH( b ) );
+		curlen += UCHARLENGTH( b );
+	}
+	if ( b->typmod > 0 && bcharlen < b->typmod  ) {
+		FillWhiteSpace( result->data + curlen, b->typmod-bcharlen );
+		curlen += b->typmod-bcharlen;
+	}
+
+	SET_VARSIZE(result, sizeof(UChar) * curlen + MVARCHARHDRSZ);
+
+	PG_FREE_IF_COPY(a,0);
+	PG_FREE_IF_COPY(b,1);
+
+	PG_RETURN_MVARCHAR(result);
+}
+
+/*
+ * mchar <> mvarchar 
+ */
+static inline int
+mc_mv_icase_compare( MChar *a, MVarChar *b ) {
+	return UCharCaseCompare( 
+		a->data, lengthWithoutSpaceChar(a),
+		b->data, lengthWithoutSpaceVarChar(b)
+	);
+}
+
+static inline int
+mc_mv_case_compare( MChar *a, MVarChar *b ) {
+	return UCharCompare( 
+		a->data, lengthWithoutSpaceChar(a),
+		b->data, lengthWithoutSpaceVarChar(b)
+	);
+}
+
+#define MC_MV_CHARCMPFUNC( c, type, action, ret ) 		\
+PG_FUNCTION_INFO_V1( mc_mv_##c##_##type ); 		\
+Datum      mc_mv_##c##_##type(PG_FUNCTION_ARGS);\
+Datum											\
+mc_mv_##c##_##type(PG_FUNCTION_ARGS) {			\
+	MChar *a = PG_GETARG_MCHAR(0);				\
+	MVarChar *b = PG_GETARG_MVARCHAR(1);		\
+	int 	res = mc_mv_##c##_compare(a,b);		\
+												\
+	PG_FREE_IF_COPY(a,0);						\
+	PG_FREE_IF_COPY(b,1);						\
+	PG_RETURN_##ret( res action 0 );			\
+}
+
+
+MC_MV_CHARCMPFUNC( case, eq, ==, BOOL )
+MC_MV_CHARCMPFUNC( case, ne, !=, BOOL )
+MC_MV_CHARCMPFUNC( case, lt, <, BOOL )
+MC_MV_CHARCMPFUNC( case, le, <=, BOOL )
+MC_MV_CHARCMPFUNC( case, ge, >=, BOOL )
+MC_MV_CHARCMPFUNC( case, gt, >, BOOL )
+MC_MV_CHARCMPFUNC( case, cmp, +, INT32 )
+
+MC_MV_CHARCMPFUNC( icase, eq, ==, BOOL )
+MC_MV_CHARCMPFUNC( icase, ne, !=, BOOL )
+MC_MV_CHARCMPFUNC( icase, lt, <, BOOL )
+MC_MV_CHARCMPFUNC( icase, le, <=, BOOL )
+MC_MV_CHARCMPFUNC( icase, ge, >=, BOOL )
+MC_MV_CHARCMPFUNC( icase, gt, >, BOOL )
+MC_MV_CHARCMPFUNC( icase, cmp, +, INT32 )
+
+/*
+ * mvarchar <> mchar 
+ */
+static inline int
+mv_mc_icase_compare( MVarChar *a, MChar *b ) {
+	return UCharCaseCompare( 
+		a->data, lengthWithoutSpaceVarChar(a),
+		b->data, lengthWithoutSpaceChar(b)
+	);
+}
+
+static inline int
+mv_mc_case_compare( MVarChar *a, MChar *b ) {
+	return UCharCompare( 
+		a->data, lengthWithoutSpaceVarChar(a),
+		b->data, lengthWithoutSpaceChar(b)
+	);
+}
+
+#define MV_MC_CHARCMPFUNC( c, type, action, ret ) 		\
+PG_FUNCTION_INFO_V1( mv_mc_##c##_##type ); 		\
+Datum      mv_mc_##c##_##type(PG_FUNCTION_ARGS);\
+Datum											\
+mv_mc_##c##_##type(PG_FUNCTION_ARGS) {			\
+	MVarChar *a = PG_GETARG_MVARCHAR(0);		\
+	MChar *b = PG_GETARG_MCHAR(1);				\
+	int 	res = mv_mc_##c##_compare(a,b);		\
+												\
+	PG_FREE_IF_COPY(a,0);						\
+	PG_FREE_IF_COPY(b,1);						\
+	PG_RETURN_##ret( res action 0 );			\
+}
+
+
+MV_MC_CHARCMPFUNC( case, eq, ==, BOOL )
+MV_MC_CHARCMPFUNC( case, ne, !=, BOOL )
+MV_MC_CHARCMPFUNC( case, lt, <, BOOL )
+MV_MC_CHARCMPFUNC( case, le, <=, BOOL )
+MV_MC_CHARCMPFUNC( case, ge, >=, BOOL )
+MV_MC_CHARCMPFUNC( case, gt, >, BOOL )
+MV_MC_CHARCMPFUNC( case, cmp, +, INT32 )
+
+MV_MC_CHARCMPFUNC( icase, eq, ==, BOOL )
+MV_MC_CHARCMPFUNC( icase, ne, !=, BOOL )
+MV_MC_CHARCMPFUNC( icase, lt, <, BOOL )
+MV_MC_CHARCMPFUNC( icase, le, <=, BOOL )
+MV_MC_CHARCMPFUNC( icase, ge, >=, BOOL )
+MV_MC_CHARCMPFUNC( icase, gt, >, BOOL )
+MV_MC_CHARCMPFUNC( icase, cmp, +, INT32 )
+
+#define NULLHASHVALUE       (-2147483647)
+
+#define FULLEQ_FUNC(type, cmpfunc, hashfunc)            \
+PG_FUNCTION_INFO_V1( isfulleq_##type );                 \
+Datum   isfulleq_##type(PG_FUNCTION_ARGS);              \
+Datum                                                   \
+isfulleq_##type(PG_FUNCTION_ARGS) {                     \
+    if ( PG_ARGISNULL(0) && PG_ARGISNULL(1) )           \
+        PG_RETURN_BOOL(true);                           \
+    else if ( PG_ARGISNULL(0) || PG_ARGISNULL(1) )      \
+        PG_RETURN_BOOL(false);                          \
+                                                        \
+    PG_RETURN_DATUM( DirectFunctionCall2( cmpfunc,      \
+            PG_GETARG_DATUM(0),                         \
+            PG_GETARG_DATUM(1)                          \
+    ) );                                                \
+}                                                       \
+                                                        \
+PG_FUNCTION_INFO_V1( fullhash_##type );                 \
+Datum   fullhash_##type(PG_FUNCTION_ARGS);              \
+Datum                                                   \
+fullhash_##type(PG_FUNCTION_ARGS) {                     \
+    if ( PG_ARGISNULL(0) )                              \
+        PG_RETURN_INT32(NULLHASHVALUE);                 \
+                                                        \
+    PG_RETURN_DATUM( DirectFunctionCall1( hashfunc,     \
+            PG_GETARG_DATUM(0)                          \
+    ) );                                                \
+}
+
+FULLEQ_FUNC( mchar, mchar_icase_eq, mchar_hash );
+FULLEQ_FUNC( mvarchar, mvarchar_icase_eq, mvarchar_hash );
+
diff -ruN a/contrib/mchar/mchar_proc.c b/contrib/mchar/mchar_proc.c
--- a/contrib/mchar/mchar_proc.c	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/mchar_proc.c	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,339 @@
+#include "mchar.h"
+#include "mb/pg_wchar.h"
+#include "access/hash.h"
+
+PG_FUNCTION_INFO_V1(mchar_length);
+Datum       mchar_length(PG_FUNCTION_ARGS);
+
+Datum
+mchar_length(PG_FUNCTION_ARGS) {
+	MChar	*m = PG_GETARG_MCHAR(0);
+	int32	l = UCHARLENGTH(m);
+
+	while( l>0 && m_isspace( m->data[ l-1 ] ) )
+		l--;
+
+	l = u_countChar32(m->data, l);
+
+	PG_FREE_IF_COPY(m,0);
+
+	PG_RETURN_INT32(l);
+}
+
+PG_FUNCTION_INFO_V1(mvarchar_length);
+Datum       mvarchar_length(PG_FUNCTION_ARGS);
+
+Datum
+mvarchar_length(PG_FUNCTION_ARGS) {
+	MVarChar	*m = PG_GETARG_MVARCHAR(0);
+	int32	l = UVARCHARLENGTH(m);
+
+	while( l>0 && m_isspace( m->data[ l-1 ] ) )
+		l--;
+
+	l = u_countChar32(m->data, l);
+
+	PG_FREE_IF_COPY(m,0);
+
+	PG_RETURN_INT32(l);
+}
+
+static int32
+uchar_substring( 
+		UChar *str, int32 strl,
+		int32 start, int32 length, bool length_not_specified,
+		UChar *dst) {
+	int32	S = start-1;	/* start position */
+	int32	S1;			/* adjusted start position */
+	int32	L1;			/* adjusted substring length */
+	int32	subbegin=0, subend=0;
+
+	S1 = Max(S, 0);
+	if (length_not_specified)
+		L1 = -1;
+	else {
+		/* end position */
+		int32 E = S + length;
+
+		/*
+		 * A negative value for L is the only way for the end position to
+		 * be before the start. SQL99 says to throw an error.
+		 */
+
+		if (E < S)
+			ereport(ERROR,
+					(errcode(ERRCODE_SUBSTRING_ERROR),
+					 errmsg("negative substring length not allowed")));
+
+		/*
+		 * A zero or negative value for the end position can happen if the
+		 * start was negative or one. SQL99 says to return a zero-length
+		 * string.
+		 */
+		if (E < 0) 
+			return 0;
+
+		L1 = E - S1;
+	}
+		 
+	U16_FWD_N( str, subbegin, strl, S1 );
+	if ( subbegin >= strl ) 
+		return 0;
+	subend = subbegin;
+	U16_FWD_N( str, subend, strl, L1 );
+
+	memcpy( dst, str+subbegin, sizeof(UChar)*(subend-subbegin) );
+
+	return subend-subbegin;
+}
+
+PG_FUNCTION_INFO_V1(mchar_substring);
+Datum       mchar_substring(PG_FUNCTION_ARGS);
+Datum
+mchar_substring(PG_FUNCTION_ARGS) {
+	MChar	*src = PG_GETARG_MCHAR(0);
+	MChar	*dst;
+	int32	length;
+
+	dst = (MChar*)palloc( VARSIZE(src) );
+	length = uchar_substring( 
+		src->data, UCHARLENGTH(src),
+		PG_GETARG_INT32(1), PG_GETARG_INT32(2), false,
+		dst->data);
+
+	dst->typmod = src->typmod;
+	SET_VARSIZE(dst, MCHARHDRSZ + length *sizeof(UChar));
+	
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_MCHAR(dst);
+}
+
+PG_FUNCTION_INFO_V1(mchar_substring_no_len);
+Datum       mchar_substring_no_len(PG_FUNCTION_ARGS);
+Datum
+mchar_substring_no_len(PG_FUNCTION_ARGS) {
+	MChar	*src = PG_GETARG_MCHAR(0);
+	MChar	*dst;
+	int32	length;
+
+	dst = (MChar*)palloc( VARSIZE(src) );
+	length = uchar_substring( 
+		src->data, UCHARLENGTH(src),
+		PG_GETARG_INT32(1), -1, true,
+		dst->data);
+
+	dst->typmod = src->typmod;
+	SET_VARSIZE(dst, MCHARHDRSZ + length *sizeof(UChar));
+
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_MCHAR(dst);
+}
+
+PG_FUNCTION_INFO_V1(mvarchar_substring);
+Datum       mvarchar_substring(PG_FUNCTION_ARGS);
+Datum
+mvarchar_substring(PG_FUNCTION_ARGS) {
+	MVarChar	*src = PG_GETARG_MVARCHAR(0);
+	MVarChar	*dst;
+	int32	length;
+
+	dst = (MVarChar*)palloc( VARSIZE(src) );
+	length = uchar_substring( 
+		src->data, UVARCHARLENGTH(src),
+		PG_GETARG_INT32(1), PG_GETARG_INT32(2), false,
+		dst->data);
+
+	SET_VARSIZE(dst, MVARCHARHDRSZ + length *sizeof(UChar));
+
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_MVARCHAR(dst);
+}
+
+PG_FUNCTION_INFO_V1(mvarchar_substring_no_len);
+Datum       mvarchar_substring_no_len(PG_FUNCTION_ARGS);
+Datum
+mvarchar_substring_no_len(PG_FUNCTION_ARGS) {
+	MVarChar	*src = PG_GETARG_MVARCHAR(0);
+	MVarChar	*dst;
+	int32	length;
+
+	dst = (MVarChar*)palloc( VARSIZE(src) );
+	length = uchar_substring( 
+		src->data, UVARCHARLENGTH(src),
+		PG_GETARG_INT32(1), -1, true,
+		dst->data);
+
+	SET_VARSIZE(dst, MVARCHARHDRSZ + length *sizeof(UChar));
+
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_MVARCHAR(dst);
+}
+
+static Datum
+hash_uchar( UChar *s, int len ) {
+	int32	length;
+	UErrorCode err = 0;
+	UChar	*d;
+	Datum res;
+
+	if ( len == 0 )
+		return hash_any( NULL, 0 );
+
+	err = 0;
+	d = (UChar*) palloc( sizeof(UChar) * len * 2 );
+	length = u_strFoldCase(d, len*2, s, len, U_FOLD_CASE_DEFAULT, &err);
+
+	if ( U_FAILURE(err) )
+		elog(ERROR,"ICU u_strFoldCase fails and returns %d (%s)", err,  u_errorName(err));
+
+	res = hash_any( (unsigned char*) d,  length * sizeof(UChar) );
+
+	pfree(d);
+	return res;
+}
+
+PG_FUNCTION_INFO_V1(mvarchar_hash);
+Datum
+mvarchar_hash(PG_FUNCTION_ARGS) {
+	MVarChar	*src = PG_GETARG_MVARCHAR(0);
+	Datum		res;
+
+	res = hash_uchar( src->data, lengthWithoutSpaceVarChar(src) );
+
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_DATUM( res );
+}
+
+PG_FUNCTION_INFO_V1(mchar_hash);
+Datum
+mchar_hash(PG_FUNCTION_ARGS) {
+	MChar	*src = PG_GETARG_MCHAR(0);
+	Datum	res;
+
+	res = hash_uchar( src->data, lengthWithoutSpaceChar(src) );
+
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_DATUM( res );
+}
+
+PG_FUNCTION_INFO_V1(mchar_upper);
+Datum       mchar_upper(PG_FUNCTION_ARGS);
+Datum
+mchar_upper(PG_FUNCTION_ARGS) {
+	MChar	*src = PG_GETARG_MCHAR(0);
+	MChar	*dst = (MChar*)palloc( VARSIZE(src) * 2 );
+
+	dst->len = MCHARHDRSZ;
+	dst->typmod = src->typmod;
+	if ( UCHARLENGTH(src) != 0 ) {
+		int 		length;
+		UErrorCode	err=0;
+
+		length = u_strToUpper( dst->data, VARSIZE(src) * 2 - MCHARHDRSZ,
+								src->data, UCHARLENGTH(src),
+								NULL, &err );
+
+		Assert( length <= VARSIZE(src) * 2 - MCHARHDRSZ );
+
+		if ( U_FAILURE(err) )
+			elog(ERROR,"ICU u_strToUpper fails and returns %d (%s)", err,  u_errorName(err));
+
+		dst->len += sizeof(UChar) * length;	
+	}
+
+	SET_VARSIZE( dst, dst->len );
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_MCHAR( dst );
+}
+
+PG_FUNCTION_INFO_V1(mchar_lower);
+Datum       mchar_lower(PG_FUNCTION_ARGS);
+Datum
+mchar_lower(PG_FUNCTION_ARGS) {
+	MChar	*src = PG_GETARG_MCHAR(0);
+	MChar	*dst = (MChar*)palloc( VARSIZE(src) * 2 );
+
+	dst->len = MCHARHDRSZ;
+	dst->typmod = src->typmod;
+	if ( UCHARLENGTH(src) != 0 ) {
+		int 		length;
+		UErrorCode	err=0;
+
+		length = u_strToLower( dst->data, VARSIZE(src) * 2 - MCHARHDRSZ,
+								src->data, UCHARLENGTH(src),
+								NULL, &err );
+
+		Assert( length <= VARSIZE(src) * 2 - MCHARHDRSZ );
+
+		if ( U_FAILURE(err) )
+			elog(ERROR,"ICU u_strToLower fails and returns %d (%s)", err,  u_errorName(err));
+
+		dst->len += sizeof(UChar) * length;	
+	}
+
+	SET_VARSIZE( dst, dst->len );
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_MCHAR( dst );
+}
+
+PG_FUNCTION_INFO_V1(mvarchar_upper);
+Datum       mvarchar_upper(PG_FUNCTION_ARGS);
+Datum
+mvarchar_upper(PG_FUNCTION_ARGS) {
+	MVarChar	*src = PG_GETARG_MVARCHAR(0);
+	MVarChar	*dst = (MVarChar*)palloc( VARSIZE(src) * 2 );
+
+	dst->len = MVARCHARHDRSZ;
+
+	if ( UVARCHARLENGTH(src) != 0 ) {
+		int 		length;
+		UErrorCode	err=0;
+
+		length = u_strToUpper( dst->data, VARSIZE(src) * 2 - MVARCHARHDRSZ,
+								src->data, UVARCHARLENGTH(src),
+								NULL, &err );
+
+		Assert( length <= VARSIZE(src) * 2 - MVARCHARHDRSZ );
+
+		if ( U_FAILURE(err) )
+			elog(ERROR,"ICU u_strToUpper fails and returns %d (%s)", err,  u_errorName(err));
+
+		dst->len += sizeof(UChar) * length;	
+	}
+
+	SET_VARSIZE( dst, dst->len );
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_MVARCHAR( dst );
+}
+
+PG_FUNCTION_INFO_V1(mvarchar_lower);
+Datum       mvarchar_lower(PG_FUNCTION_ARGS);
+Datum
+mvarchar_lower(PG_FUNCTION_ARGS) {
+	MVarChar	*src = PG_GETARG_MVARCHAR(0);
+	MVarChar	*dst = (MVarChar*)palloc( VARSIZE(src) * 2 );
+
+	dst->len = MVARCHARHDRSZ;
+
+	if ( UVARCHARLENGTH(src) != 0 ) {
+		int 		length;
+		UErrorCode	err=0;
+
+		length = u_strToLower( dst->data, VARSIZE(src) * 2 - MVARCHARHDRSZ,
+								src->data, UVARCHARLENGTH(src),
+								NULL, &err );
+
+		Assert( length <= VARSIZE(src) * 2 - MVARCHARHDRSZ );
+
+		if ( U_FAILURE(err) )
+			elog(ERROR,"ICU u_strToLower fails and returns %d (%s)", err,  u_errorName(err));
+
+		dst->len += sizeof(UChar) * length;	
+	}
+
+	SET_VARSIZE( dst, dst->len );
+	PG_FREE_IF_COPY(src, 0);
+	PG_RETURN_MVARCHAR( dst );
+}
+
+
diff -ruN a/contrib/mchar/mchar_recode.c b/contrib/mchar/mchar_recode.c
--- a/contrib/mchar/mchar_recode.c	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/mchar_recode.c	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,142 @@
+#include "mchar.h"
+
+#include "unicode/ucol.h"
+#include "unicode/ucnv.h"
+
+static UConverter *cnvDB = NULL;
+static UCollator  *colCaseInsensitive = NULL;
+static UCollator  *colCaseSensitive = NULL;
+
+static void
+createUObjs() {
+	if ( !cnvDB ) {
+		UErrorCode err = 0;
+
+		if ( GetDatabaseEncoding() == PG_UTF8 )
+			cnvDB = ucnv_open("UTF8", &err);
+	 	else
+			cnvDB = ucnv_open(NULL, &err);
+		if ( U_FAILURE(err) || cnvDB == NULL ) 
+			elog(ERROR,"ICU ucnv_open returns %d (%s)", err,  u_errorName(err));
+	}
+
+	if ( !colCaseInsensitive ) {
+		UErrorCode err = 0;
+
+		colCaseInsensitive = ucol_open("", &err);
+		if ( U_FAILURE(err) || cnvDB == NULL ) { 
+			if ( colCaseSensitive )
+				ucol_close( colCaseSensitive );
+			colCaseSensitive = NULL;
+			elog(ERROR,"ICU ucol_open returns %d (%s)", err,  u_errorName(err));
+		}
+
+		ucol_setStrength( colCaseInsensitive, UCOL_SECONDARY );
+	}
+
+	if ( !colCaseSensitive ) {
+		UErrorCode err = 0;
+
+		colCaseSensitive = ucol_open("", &err);
+		if ( U_FAILURE(err) || cnvDB == NULL ) { 
+			if ( colCaseSensitive )
+				ucol_close( colCaseSensitive );
+			colCaseSensitive = NULL;
+			elog(ERROR,"ICU ucol_open returns %d (%s)", err,  u_errorName(err));
+		}
+
+		ucol_setAttribute(colCaseSensitive, UCOL_CASE_FIRST, UCOL_UPPER_FIRST, &err);				
+		if (U_FAILURE(err)) {
+			if ( colCaseSensitive )
+				ucol_close( colCaseSensitive );
+			colCaseSensitive = NULL;
+			elog(ERROR,"ICU ucol_setAttribute returns %d (%s)", err,  u_errorName(err));
+		}
+	}
+}
+
+int
+Char2UChar(const char * src, int srclen, UChar *dst) {
+	int dstlen=0;
+	UErrorCode err = 0;
+
+	createUObjs();
+	dstlen = ucnv_toUChars( cnvDB, dst, srclen*4, src, srclen, &err ); 
+	if ( U_FAILURE(err)) 
+		elog(ERROR,"ICU ucnv_toUChars returns %d (%s)", err,  u_errorName(err));
+
+	return dstlen;
+}
+
+int
+UChar2Char(const UChar * src, int srclen, char *dst) {
+	int dstlen=0;
+	UErrorCode err = 0;
+
+	createUObjs();
+	dstlen = ucnv_fromUChars( cnvDB, dst, srclen*4, src, srclen, &err ); 
+	if ( U_FAILURE(err) ) 
+		elog(ERROR,"ICU ucnv_fromUChars returns %d (%s)", err,  u_errorName(err));
+
+	return dstlen;
+}
+
+int
+UChar2Wchar(UChar * src, int srclen, pg_wchar *dst) {
+	int dstlen=0;
+	char	*utf = palloc(sizeof(char)*srclen*4);
+
+	dstlen = UChar2Char(src, srclen, utf);
+	dstlen = pg_mb2wchar_with_len( utf, dst, dstlen );
+	pfree(utf);
+
+	return dstlen;
+}
+
+static UChar UCharWhiteSpace = 0;
+
+void
+FillWhiteSpace( UChar *dst, int n ) {
+	if ( UCharWhiteSpace == 0 ) {
+		int len;
+		UErrorCode err = 0;
+
+		u_strFromUTF8( &UCharWhiteSpace, 1, &len, " ", 1, &err);
+
+		Assert( len==1 );
+		Assert( !U_FAILURE(err) );
+	}
+
+	while( n-- > 0 ) 
+		*dst++ = UCharWhiteSpace;
+}
+
+int 
+UCharCaseCompare(UChar * a, int alen, UChar *b, int blen) {
+	int len = Min(alen, blen);
+	int res;
+
+	createUObjs();
+
+	res = (int)ucol_strcoll( colCaseInsensitive,
+							  a, len,
+							  b, len);
+	if ( res == 0 && alen != blen )
+		return (alen > blen) ? 1 : - 1;
+	return res;
+}
+
+int 
+UCharCompare(UChar * a, int alen, UChar *b, int blen) {
+	int len = Min(alen, blen);
+	int res;
+	
+	createUObjs();
+
+	res =  (int)ucol_strcoll( colCaseSensitive,
+							  a, len,
+							  b, len);
+	if ( res == 0 && alen != blen )
+		return (alen > blen) ? 1 : - 1;
+	return res;
+}
diff -ruN a/contrib/mchar/README.mchar b/contrib/mchar/README.mchar
--- a/contrib/mchar/README.mchar	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/README.mchar	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,20 @@
+MCHAR & VARCHAR
+	type modifier
+	length()
+	substr(str, pos[, length])
+	|| - concatenation with any (mchar,mvarchar) arguments
+	< <= = >= >  - case-insensitive comparisons (libICU)
+	&< &<= &= &>= &>  - case-sensitive comparisons (libICU)
+	implicit casting  mchar<->mvarchar
+	B-tree and hash index
+	LIKE [ESCAPE]
+	SIMILAR TO [ESCAPE]
+	~ (POSIX regexp)
+	index support for LIKE
+
+
+Authors:
+	Oleg Bartunov <oleg@sai.msu.ru>
+	Teodor Sigaev <teodor@sigaev.ru>
+
+
diff -ruN a/contrib/mchar/sql/compat.sql b/contrib/mchar/sql/compat.sql
--- a/contrib/mchar/sql/compat.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/sql/compat.sql	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,11 @@
+--- table based checks
+
+select '<' || ch || '>', '<' || vch || '>' from chvch;
+select * from chvch where vch = 'One space';
+select * from chvch where vch = 'One space ';
+
+select * from ch where chcol = 'abcd' order by chcol;
+select * from ch t1 join ch t2 on t1.chcol = t2.chcol order by t1.chcol, t2.chcol;
+select * from ch where chcol > 'abcd' and chcol<'ee';
+select * from ch order by chcol;
+
diff -ruN a/contrib/mchar/sql/init.sql b/contrib/mchar/sql/init.sql
--- a/contrib/mchar/sql/init.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/sql/init.sql	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,25 @@
+CREATE EXTENSION mchar;
+
+SET search_path = public;
+
+create table ch (
+	chcol mchar(32)
+) without oids;
+
+insert into ch values('abcd');
+insert into ch values('AbcD');
+insert into ch values('abcz');
+insert into ch values('defg');
+insert into ch values('dEfg');
+insert into ch values('ee');
+insert into ch values('Ee');
+
+create table chvch (
+    ch      mchar(12),
+	vch     mvarchar(12)
+) without oids;
+
+insert into chvch values('No spaces', 'No spaces');
+insert into chvch values('One space ', 'One space ');
+insert into chvch values('1 space', '1 space ');
+
diff -ruN a/contrib/mchar/sql/like.sql b/contrib/mchar/sql/like.sql
--- a/contrib/mchar/sql/like.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/sql/like.sql	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,216 @@
+-- simplest examples
+-- E061-04 like predicate
+SELECT 'hawkeye'::mchar LIKE 'h%' AS "true";
+SELECT 'hawkeye'::mchar NOT LIKE 'h%' AS "false";
+
+SELECT 'hawkeye'::mchar LIKE 'H%' AS "true";
+SELECT 'hawkeye'::mchar NOT LIKE 'H%' AS "false";
+
+SELECT 'hawkeye'::mchar LIKE 'indio%' AS "false";
+SELECT 'hawkeye'::mchar NOT LIKE 'indio%' AS "true";
+
+SELECT 'hawkeye'::mchar LIKE 'h%eye' AS "true";
+SELECT 'hawkeye'::mchar NOT LIKE 'h%eye' AS "false";
+
+SELECT 'indio'::mchar LIKE '_ndio' AS "true";
+SELECT 'indio'::mchar NOT LIKE '_ndio' AS "false";
+
+SELECT 'indio'::mchar LIKE 'in__o' AS "true";
+SELECT 'indio'::mchar NOT LIKE 'in__o' AS "false";
+
+SELECT 'indio'::mchar LIKE 'in_o' AS "false";
+SELECT 'indio'::mchar NOT LIKE 'in_o' AS "true";
+
+SELECT 'hawkeye'::mvarchar LIKE 'h%' AS "true";
+SELECT 'hawkeye'::mvarchar NOT LIKE 'h%' AS "false";
+
+SELECT 'hawkeye'::mvarchar LIKE 'H%' AS "true";
+SELECT 'hawkeye'::mvarchar NOT LIKE 'H%' AS "false";
+
+SELECT 'hawkeye'::mvarchar LIKE 'indio%' AS "false";
+SELECT 'hawkeye'::mvarchar NOT LIKE 'indio%' AS "true";
+
+SELECT 'hawkeye'::mvarchar LIKE 'h%eye' AS "true";
+SELECT 'hawkeye'::mvarchar NOT LIKE 'h%eye' AS "false";
+
+SELECT 'indio'::mvarchar LIKE '_ndio' AS "true";
+SELECT 'indio'::mvarchar NOT LIKE '_ndio' AS "false";
+
+SELECT 'indio'::mvarchar LIKE 'in__o' AS "true";
+SELECT 'indio'::mvarchar NOT LIKE 'in__o' AS "false";
+
+SELECT 'indio'::mvarchar LIKE 'in_o' AS "false";
+SELECT 'indio'::mvarchar NOT LIKE 'in_o' AS "true";
+
+-- unused escape character
+SELECT 'hawkeye'::mchar LIKE 'h%'::mchar ESCAPE '#' AS "true";
+SELECT 'hawkeye'::mchar NOT LIKE 'h%'::mchar ESCAPE '#' AS "false";
+
+SELECT 'indio'::mchar LIKE 'ind_o'::mchar ESCAPE '$' AS "true";
+SELECT 'indio'::mchar NOT LIKE 'ind_o'::mchar ESCAPE '$' AS "false";
+
+-- escape character
+-- E061-05 like predicate with escape clause
+SELECT 'h%'::mchar LIKE 'h#%'::mchar ESCAPE '#' AS "true";
+SELECT 'h%'::mchar NOT LIKE 'h#%'::mchar ESCAPE '#' AS "false";
+
+SELECT 'h%wkeye'::mchar LIKE 'h#%'::mchar ESCAPE '#' AS "false";
+SELECT 'h%wkeye'::mchar NOT LIKE 'h#%'::mchar ESCAPE '#' AS "true";
+
+SELECT 'h%wkeye'::mchar LIKE 'h#%%'::mchar ESCAPE '#' AS "true";
+SELECT 'h%wkeye'::mchar NOT LIKE 'h#%%'::mchar ESCAPE '#' AS "false";
+
+SELECT 'h%awkeye'::mchar LIKE 'h#%a%k%e'::mchar ESCAPE '#' AS "true";
+SELECT 'h%awkeye'::mchar NOT LIKE 'h#%a%k%e'::mchar ESCAPE '#' AS "false";
+
+SELECT 'indio'::mchar LIKE '_ndio'::mchar ESCAPE '$' AS "true";
+SELECT 'indio'::mchar NOT LIKE '_ndio'::mchar ESCAPE '$' AS "false";
+
+SELECT 'i_dio'::mchar LIKE 'i$_d_o'::mchar ESCAPE '$' AS "true";
+SELECT 'i_dio'::mchar NOT LIKE 'i$_d_o'::mchar ESCAPE '$' AS "false";
+
+SELECT 'i_dio'::mchar LIKE 'i$_nd_o'::mchar ESCAPE '$' AS "false";
+SELECT 'i_dio'::mchar NOT LIKE 'i$_nd_o'::mchar ESCAPE '$' AS "true";
+
+SELECT 'i_dio'::mchar LIKE 'i$_d%o'::mchar ESCAPE '$' AS "true";
+SELECT 'i_dio'::mchar NOT LIKE 'i$_d%o'::mchar ESCAPE '$' AS "false";
+
+-- escape character same as pattern character
+SELECT 'maca'::mchar LIKE 'm%aca' ESCAPE '%'::mchar AS "true";
+SELECT 'maca'::mchar NOT LIKE 'm%aca' ESCAPE '%'::mchar AS "false";
+
+SELECT 'ma%a'::mchar LIKE 'm%a%%a' ESCAPE '%'::mchar AS "true";
+SELECT 'ma%a'::mchar NOT LIKE 'm%a%%a' ESCAPE '%'::mchar AS "false";
+
+SELECT 'bear'::mchar LIKE 'b_ear' ESCAPE '_'::mchar AS "true";
+SELECT 'bear'::mchar NOT LIKE 'b_ear'::mchar ESCAPE '_' AS "false";
+
+SELECT 'be_r'::mchar LIKE 'b_e__r' ESCAPE '_'::mchar AS "true";
+SELECT 'be_r'::mchar NOT LIKE 'b_e__r' ESCAPE '_'::mchar AS "false";
+
+SELECT 'be_r'::mchar LIKE '__e__r' ESCAPE '_'::mchar AS "false";
+SELECT 'be_r'::mchar NOT LIKE '__e__r'::mchar ESCAPE '_' AS "true";
+
+-- unused escape character
+SELECT 'hawkeye'::mvarchar LIKE 'h%'::mvarchar ESCAPE '#' AS "true";
+SELECT 'hawkeye'::mvarchar NOT LIKE 'h%'::mvarchar ESCAPE '#' AS "false";
+
+SELECT 'indio'::mvarchar LIKE 'ind_o'::mvarchar ESCAPE '$' AS "true";
+SELECT 'indio'::mvarchar NOT LIKE 'ind_o'::mvarchar ESCAPE '$' AS "false";
+
+-- escape character
+-- E061-05 like predicate with escape clause
+SELECT 'h%'::mvarchar LIKE 'h#%'::mvarchar ESCAPE '#' AS "true";
+SELECT 'h%'::mvarchar NOT LIKE 'h#%'::mvarchar ESCAPE '#' AS "false";
+
+SELECT 'h%wkeye'::mvarchar LIKE 'h#%'::mvarchar ESCAPE '#' AS "false";
+SELECT 'h%wkeye'::mvarchar NOT LIKE 'h#%'::mvarchar ESCAPE '#' AS "true";
+
+SELECT 'h%wkeye'::mvarchar LIKE 'h#%%'::mvarchar ESCAPE '#' AS "true";
+SELECT 'h%wkeye'::mvarchar NOT LIKE 'h#%%'::mvarchar ESCAPE '#' AS "false";
+
+SELECT 'h%awkeye'::mvarchar LIKE 'h#%a%k%e'::mvarchar ESCAPE '#' AS "true";
+SELECT 'h%awkeye'::mvarchar NOT LIKE 'h#%a%k%e'::mvarchar ESCAPE '#' AS "false";
+
+SELECT 'indio'::mvarchar LIKE '_ndio'::mvarchar ESCAPE '$' AS "true";
+SELECT 'indio'::mvarchar NOT LIKE '_ndio'::mvarchar ESCAPE '$' AS "false";
+
+SELECT 'i_dio'::mvarchar LIKE 'i$_d_o'::mvarchar ESCAPE '$' AS "true";
+SELECT 'i_dio'::mvarchar NOT LIKE 'i$_d_o'::mvarchar ESCAPE '$' AS "false";
+
+SELECT 'i_dio'::mvarchar LIKE 'i$_nd_o'::mvarchar ESCAPE '$' AS "false";
+SELECT 'i_dio'::mvarchar NOT LIKE 'i$_nd_o'::mvarchar ESCAPE '$' AS "true";
+
+SELECT 'i_dio'::mvarchar LIKE 'i$_d%o'::mvarchar ESCAPE '$' AS "true";
+SELECT 'i_dio'::mvarchar NOT LIKE 'i$_d%o'::mvarchar ESCAPE '$' AS "false";
+
+-- escape character same as pattern character
+SELECT 'maca'::mvarchar LIKE 'm%aca' ESCAPE '%'::mvarchar AS "true";
+SELECT 'maca'::mvarchar NOT LIKE 'm%aca' ESCAPE '%'::mvarchar AS "false";
+
+SELECT 'ma%a'::mvarchar LIKE 'm%a%%a' ESCAPE '%'::mvarchar AS "true";
+SELECT 'ma%a'::mvarchar NOT LIKE 'm%a%%a' ESCAPE '%'::mvarchar AS "false";
+
+SELECT 'bear'::mvarchar LIKE 'b_ear' ESCAPE '_'::mvarchar AS "true";
+SELECT 'bear'::mvarchar NOT LIKE 'b_ear'::mvarchar ESCAPE '_' AS "false";
+
+SELECT 'be_r'::mvarchar LIKE 'b_e__r' ESCAPE '_'::mvarchar AS "true";
+SELECT 'be_r'::mvarchar NOT LIKE 'b_e__r' ESCAPE '_'::mvarchar AS "false";
+
+SELECT 'be_r'::mvarchar LIKE '__e__r' ESCAPE '_'::mvarchar AS "false";
+SELECT 'be_r'::mvarchar NOT LIKE '__e__r'::mvarchar ESCAPE '_' AS "true";
+
+-- similar to
+
+SELECT 'abc'::mchar SIMILAR TO 'abc'::mchar   AS   "true";
+SELECT 'abc'::mchar SIMILAR TO 'a'::mchar      AS  "false";
+SELECT 'abc'::mchar SIMILAR TO '%(b|d)%'::mchar AS "true";
+SELECT 'abc'::mchar SIMILAR TO '(b|c)%'::mchar AS  "false";
+SELECT 'h%'::mchar SIMILAR TO 'h#%'::mchar AS "false";
+SELECT 'h%'::mchar SIMILAR TO 'h#%'::mchar ESCAPE '#' AS "true";
+
+SELECT 'abc'::mvarchar SIMILAR TO 'abc'::mvarchar   AS   "true";
+SELECT 'abc'::mvarchar SIMILAR TO 'a'::mvarchar      AS  "false";
+SELECT 'abc'::mvarchar SIMILAR TO '%(b|d)%'::mvarchar AS "true";
+SELECT 'abc'::mvarchar SIMILAR TO '(b|c)%'::mvarchar AS  "false";
+SELECT 'h%'::mvarchar SIMILAR TO 'h#%'::mvarchar AS "false";
+SELECT 'h%'::mvarchar SIMILAR TO 'h#%'::mvarchar ESCAPE '#' AS "true";
+
+-- index support
+
+SELECT * from ch where chcol like 'aB_d' order by chcol using &<;
+SELECT * from ch where chcol like 'aB%d' order by chcol using &<;
+SELECT * from ch where chcol like 'aB%' order by chcol using &<;
+SELECT * from ch where chcol like '%BC%' order by chcol using &<;
+set enable_seqscan = off;
+SELECT * from ch where chcol like 'aB_d' order by chcol using &<;
+SELECT * from ch where chcol like 'aB%d' order by chcol using &<;
+SELECT * from ch where chcol like 'aB%' order by chcol using &<;
+SELECT * from ch where chcol like '%BC%' order by chcol using &<;
+set enable_seqscan = on;
+
+
+create table testt (f1 mchar(10));
+insert into testt values ('Abc-000001');
+insert into testt values ('Abc-000002');
+insert into testt values ('0000000001');
+insert into testt values ('0000000002');
+
+select f1 from testt where f1::mvarchar like E'Abc\\-%'::mvarchar;
+select * from testt where f1::mchar like E'Abc\\-%'::mchar;
+create index testindex on testt(f1);
+set enable_seqscan=off;
+select f1 from testt where f1::mvarchar like E'Abc\\-%'::mvarchar;
+select * from testt where f1::mchar like E'Abc\\-%'::mchar;
+set enable_seqscan = on;
+drop table testt;
+
+create table testt (f1 mvarchar(10));
+insert into testt values ('Abc-000001');
+insert into testt values ('Abc-000002');
+insert into testt values ('0000000001');
+insert into testt values ('0000000002');
+
+select f1 from testt where f1::mvarchar like E'Abc\\-%'::mvarchar;
+select * from testt where f1::mchar like E'Abc\\-%'::mchar;
+select * from testt where f1::mchar like E'Abc\\-  %'::mchar;
+select * from testt where f1::mchar like E'   %'::mchar;
+create index testindex on testt(f1);
+set enable_seqscan=off;
+select f1 from testt where f1::mvarchar like E'Abc\\-%'::mvarchar;
+select * from testt where f1::mchar like E'Abc\\-%'::mchar;
+select * from testt where f1::mchar like E'Abc\\-   %'::mchar;
+select * from testt where f1::mchar like E'   %'::mchar;
+set enable_seqscan = on;
+drop table testt;
+
+
+CREATE TABLE test ( code mchar(5) NOT NULL );
+insert into test values('1111 ');
+insert into test values('111  ');
+insert into test values('11   ');
+insert into test values('1    ');
+
+SELECT * FROM test WHERE code LIKE ('%    ');
+
+
diff -ruN a/contrib/mchar/sql/mchar.sql b/contrib/mchar/sql/mchar.sql
--- a/contrib/mchar/sql/mchar.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/sql/mchar.sql	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,81 @@
+-- I/O tests
+
+select '1'::mchar;
+select '2  '::mchar;
+select '10          '::mchar;
+
+select '1'::mchar(2);
+select '2 '::mchar(2);
+select '3  '::mchar(2);
+select '10          '::mchar(2);
+
+select '                  '::mchar(10); 
+select '                  '::mchar; 
+
+-- operations & functions
+
+select length('1'::mchar);
+select length('2  '::mchar);
+select length('10          '::mchar);
+
+select length('1'::mchar(2));
+select length('2 '::mchar(2));
+select length('3  '::mchar(2));
+select length('10          '::mchar(2));
+
+select length('                  '::mchar(10)); 
+select length('                  '::mchar); 
+
+select 'asd'::mchar(10) || '>'::mchar(10);
+select length('asd'::mchar(10) || '>'::mchar(10));
+select 'asd'::mchar(2)  || '>'::mchar(10);
+select length('asd'::mchar(2) || '>'::mchar(10));
+
+-- Comparisons
+
+select 'asdf'::mchar = 'aSdf'::mchar;
+select 'asdf'::mchar = 'aSdf '::mchar;
+select 'asdf'::mchar = 'aSdf 1'::mchar(4);
+select 'asdf'::mchar = 'aSdf 1'::mchar(5);
+select 'asdf'::mchar = 'aSdf 1'::mchar(6);
+select 'asdf'::mchar(3) = 'aSdf 1'::mchar(5);
+select 'asdf'::mchar(3) = 'aSdf 1'::mchar(3);
+
+select 'asdf'::mchar < 'aSdf'::mchar;
+select 'asdf'::mchar < 'aSdf '::mchar;
+select 'asdf'::mchar < 'aSdf 1'::mchar(4);
+select 'asdf'::mchar < 'aSdf 1'::mchar(5);
+select 'asdf'::mchar < 'aSdf 1'::mchar(6);
+
+select 'asdf'::mchar <= 'aSdf'::mchar;
+select 'asdf'::mchar <= 'aSdf '::mchar;
+select 'asdf'::mchar <= 'aSdf 1'::mchar(4);
+select 'asdf'::mchar <= 'aSdf 1'::mchar(5);
+select 'asdf'::mchar <= 'aSdf 1'::mchar(6);
+
+select 'asdf'::mchar >= 'aSdf'::mchar;
+select 'asdf'::mchar >= 'aSdf '::mchar;
+select 'asdf'::mchar >= 'aSdf 1'::mchar(4);
+select 'asdf'::mchar >= 'aSdf 1'::mchar(5);
+select 'asdf'::mchar >= 'aSdf 1'::mchar(6);
+
+select 'asdf'::mchar > 'aSdf'::mchar;
+select 'asdf'::mchar > 'aSdf '::mchar;
+select 'asdf'::mchar > 'aSdf 1'::mchar(4);
+select 'asdf'::mchar > 'aSdf 1'::mchar(5);
+select 'asdf'::mchar > 'aSdf 1'::mchar(6);
+
+select max(ch) from chvch;
+select min(ch) from chvch;
+
+select substr('1234567890'::mchar, 3) = '34567890' as "34567890";
+select substr('1234567890'::mchar, 4, 3) = '456' as "456";
+
+select lower('asdfASDF'::mchar);
+select upper('asdfASDF'::mchar);
+
+select 'asd'::mchar == 'aSd'::mchar;
+select 'asd'::mchar == 'aCd'::mchar;
+select 'asd'::mchar == NULL;
+select NULL == 'aCd'::mchar;
+select NULL::mchar == NULL;
diff -ruN a/contrib/mchar/sql/mm.sql b/contrib/mchar/sql/mm.sql
--- a/contrib/mchar/sql/mm.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/sql/mm.sql	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,185 @@
+select 'asd'::mchar::mvarchar;
+select 'asd '::mchar::mvarchar;
+select 'asd'::mchar(2)::mvarchar;
+select 'asd '::mchar(2)::mvarchar;
+select 'asd'::mchar(5)::mvarchar;
+select 'asd '::mchar(5)::mvarchar;
+select 'asd'::mchar::mvarchar(2);
+select 'asd '::mchar::mvarchar(2);
+select 'asd'::mchar(2)::mvarchar(2);
+select 'asd '::mchar(2)::mvarchar(2);
+select 'asd'::mchar(5)::mvarchar(2);
+select 'asd '::mchar(5)::mvarchar(2);
+select 'asd'::mchar::mvarchar(5);
+select 'asd '::mchar::mvarchar(5);
+select 'asd'::mchar(2)::mvarchar(5);
+select 'asd '::mchar(2)::mvarchar(5);
+select 'asd'::mchar(5)::mvarchar(5);
+select 'asd '::mchar(5)::mvarchar(5);
+
+select 'asd'::mvarchar::mchar;
+select 'asd '::mvarchar::mchar;
+select 'asd'::mvarchar(2)::mchar;
+select 'asd '::mvarchar(2)::mchar;
+select 'asd'::mvarchar(5)::mchar;
+select 'asd '::mvarchar(5)::mchar;
+select 'asd'::mvarchar::mchar(2);
+select 'asd '::mvarchar::mchar(2);
+select 'asd'::mvarchar(2)::mchar(2);
+select 'asd '::mvarchar(2)::mchar(2);
+select 'asd'::mvarchar(5)::mchar(2);
+select 'asd '::mvarchar(5)::mchar(2);
+select 'asd'::mvarchar::mchar(5);
+select 'asd '::mvarchar::mchar(5);
+select 'asd'::mvarchar(2)::mchar(5);
+select 'asd '::mvarchar(2)::mchar(5);
+select 'asd'::mvarchar(5)::mchar(5);
+select 'asd '::mvarchar(5)::mchar(5);
+
+select 'asd'::mchar || '123';
+select 'asd'::mchar || '123'::mchar;
+select 'asd'::mchar || '123'::mvarchar;
+
+select 'asd '::mchar || '123';
+select 'asd '::mchar || '123'::mchar;
+select 'asd '::mchar || '123'::mvarchar;
+
+select 'asd '::mchar || '123 ';
+select 'asd '::mchar || '123 '::mchar;
+select 'asd '::mchar || '123 '::mvarchar;
+
+
+select 'asd'::mvarchar || '123';
+select 'asd'::mvarchar || '123'::mchar;
+select 'asd'::mvarchar || '123'::mvarchar;
+
+select 'asd '::mvarchar || '123';
+select 'asd '::mvarchar || '123'::mchar;
+select 'asd '::mvarchar || '123'::mvarchar;
+
+select 'asd '::mvarchar || '123 ';
+select 'asd '::mvarchar || '123 '::mchar;
+select 'asd '::mvarchar || '123 '::mvarchar;
+
+
+select 'asd'::mchar(2) || '123';
+select 'asd'::mchar(2) || '123'::mchar;
+select 'asd'::mchar(2) || '123'::mvarchar;
+
+
+select 'asd '::mchar(2) || '123';
+select 'asd '::mchar(2) || '123'::mchar;
+select 'asd '::mchar(2) || '123'::mvarchar;
+
+
+select 'asd '::mchar(2) || '123 ';
+select 'asd '::mchar(2) || '123 '::mchar;
+select 'asd '::mchar(2) || '123 '::mvarchar;
+
+select 'asd'::mvarchar(2) || '123';
+select 'asd'::mvarchar(2) || '123'::mchar;
+select 'asd'::mvarchar(2) || '123'::mvarchar;
+
+select 'asd '::mvarchar(2) || '123';
+select 'asd '::mvarchar(2) || '123'::mchar;
+select 'asd '::mvarchar(2) || '123'::mvarchar;
+
+select 'asd '::mvarchar(2) || '123 ';
+select 'asd '::mvarchar(2) || '123 '::mchar;
+select 'asd '::mvarchar(2) || '123 '::mvarchar;
+
+select 'asd'::mchar(4) || '143';
+select 'asd'::mchar(4) || '123'::mchar;
+select 'asd'::mchar(4) || '123'::mvarchar;
+
+select 'asd '::mchar(4) || '123';
+select 'asd '::mchar(4) || '123'::mchar;
+select 'asd '::mchar(4) || '123'::mvarchar;
+
+select 'asd '::mchar(4) || '123 ';
+select 'asd '::mchar(4) || '123 '::mchar;
+select 'asd '::mchar(4) || '123 '::mvarchar;
+
+select 'asd'::mvarchar(4) || '123';
+select 'asd'::mvarchar(4) || '123'::mchar;
+select 'asd'::mvarchar(4) || '123'::mvarchar;
+
+select 'asd '::mvarchar(4) || '123';
+select 'asd '::mvarchar(4) || '123'::mchar;
+select 'asd '::mvarchar(4) || '123'::mvarchar;
+
+select 'asd '::mvarchar(4) || '123 ';
+select 'asd '::mvarchar(4) || '123 '::mchar;
+select 'asd '::mvarchar(4) || '123 '::mvarchar;
+
+
+select 'asd '::mvarchar(4) || '123 '::mchar(4);
+select 'asd '::mvarchar(4) || '123 '::mvarchar(4);
+select 'asd '::mvarchar(4) || '123'::mchar(4);
+select 'asd '::mvarchar(4) || '123'::mvarchar(4);
+
+
+select 1 where 'f'::mchar='F'::mvarchar;
+select 1 where 'f'::mchar='F '::mvarchar;
+select 1 where 'f '::mchar='F'::mvarchar;
+select 1 where 'f '::mchar='F '::mvarchar;
+
+select 1 where 'f'::mchar='F'::mvarchar(2);
+select 1 where 'f'::mchar='F '::mvarchar(2);
+select 1 where 'f '::mchar='F'::mvarchar(2);
+select 1 where 'f '::mchar='F '::mvarchar(2);
+
+select 1 where 'f'::mchar(2)='F'::mvarchar;
+select 1 where 'f'::mchar(2)='F '::mvarchar;
+select 1 where 'f '::mchar(2)='F'::mvarchar;
+select 1 where 'f '::mchar(2)='F '::mvarchar;
+
+select 1 where 'f'::mchar(2)='F'::mvarchar(2);
+select 1 where 'f'::mchar(2)='F '::mvarchar(2);
+select 1 where 'f '::mchar(2)='F'::mvarchar(2);
+select 1 where 'f '::mchar(2)='F '::mvarchar(2);
+
+select 1 where 'foo'::mchar='FOO'::mvarchar;
+select 1 where 'foo'::mchar='FOO '::mvarchar;
+select 1 where 'foo '::mchar='FOO'::mvarchar;
+select 1 where 'foo '::mchar='FOO '::mvarchar;
+
+select 1 where 'foo'::mchar='FOO'::mvarchar(2);
+select 1 where 'foo'::mchar='FOO '::mvarchar(2);
+select 1 where 'foo '::mchar='FOO'::mvarchar(2);
+select 1 where 'foo '::mchar='FOO '::mvarchar(2);
+
+select 1 where 'foo'::mchar(2)='FOO'::mvarchar;
+select 1 where 'foo'::mchar(2)='FOO '::mvarchar;
+select 1 where 'foo '::mchar(2)='FOO'::mvarchar;
+select 1 where 'foo '::mchar(2)='FOO '::mvarchar;
+
+select 1 where 'foo'::mchar(2)='FOO'::mvarchar(2);
+select 1 where 'foo'::mchar(2)='FOO '::mvarchar(2);
+select 1 where 'foo '::mchar(2)='FOO'::mvarchar(2);
+select 1 where 'foo '::mchar(2)='FOO '::mvarchar(2);
+
+Select 'f'::mchar(1) Union Select 'o'::mvarchar(1);
+Select 'f'::mvarchar(1) Union Select 'o'::mchar(1);
+
+select * from chvch where ch=vch;
+
+select ch.* from ch, (select 'dEfg'::mvarchar as q) as p  where  chcol > p.q;
+create index qq on ch (chcol);
+set enable_seqscan=off;
+select ch.* from ch, (select 'dEfg'::mvarchar as q) as p  where  chcol > p.q;
+set enable_seqscan=on;
+
+
+--\copy chvch to 'results/chvch.dump' binary
+--truncate table chvch;
+--\copy chvch from 'results/chvch.dump' binary
+
+--test joins
+CREATE TABLE a (mchar2 MCHAR(2) NOT NULL);
+CREATE TABLE c (mvarchar255 mvarchar NOT NULL);
+SELECT * FROM a, c WHERE mchar2 = mvarchar255;
+SELECT * FROM a, c WHERE mvarchar255 = mchar2;
+DROP TABLE a;
+DROP TABLE c;
+
diff -ruN a/contrib/mchar/sql/mvarchar.sql b/contrib/mchar/sql/mvarchar.sql
--- a/contrib/mchar/sql/mvarchar.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/sql/mvarchar.sql	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,82 @@
+-- I/O tests
+
+select '1'::mvarchar;
+select '2  '::mvarchar;
+select '10          '::mvarchar;
+
+select '1'::mvarchar(2);
+select '2 '::mvarchar(2);
+select '3  '::mvarchar(2);
+select '10          '::mvarchar(2);
+
+select '                  '::mvarchar(10); 
+select '                  '::mvarchar; 
+
+-- operations & functions
+
+select length('1'::mvarchar);
+select length('2  '::mvarchar);
+select length('10          '::mvarchar);
+
+select length('1'::mvarchar(2));
+select length('2 '::mvarchar(2));
+select length('3  '::mvarchar(2));
+select length('10          '::mvarchar(2));
+
+select length('                  '::mvarchar(10)); 
+select length('                  '::mvarchar); 
+
+select 'asd'::mvarchar(10) || '>'::mvarchar(10);
+select length('asd'::mvarchar(10) || '>'::mvarchar(10));
+select 'asd'::mvarchar(2)  || '>'::mvarchar(10);
+select length('asd'::mvarchar(2) || '>'::mvarchar(10));
+
+-- Comparisons
+
+select 'asdf'::mvarchar = 'aSdf'::mvarchar;
+select 'asdf'::mvarchar = 'aSdf '::mvarchar;
+select 'asdf'::mvarchar = 'aSdf 1'::mvarchar(4);
+select 'asdf'::mvarchar = 'aSdf 1'::mvarchar(5);
+select 'asdf'::mvarchar = 'aSdf 1'::mvarchar(6);
+select 'asdf'::mvarchar(3) = 'aSdf 1'::mvarchar(5);
+select 'asdf'::mvarchar(3) = 'aSdf 1'::mvarchar(3);
+
+select 'asdf'::mvarchar < 'aSdf'::mvarchar;
+select 'asdf'::mvarchar < 'aSdf '::mvarchar;
+select 'asdf'::mvarchar < 'aSdf 1'::mvarchar(4);
+select 'asdf'::mvarchar < 'aSdf 1'::mvarchar(5);
+select 'asdf'::mvarchar < 'aSdf 1'::mvarchar(6);
+
+select 'asdf'::mvarchar <= 'aSdf'::mvarchar;
+select 'asdf'::mvarchar <= 'aSdf '::mvarchar;
+select 'asdf'::mvarchar <= 'aSdf 1'::mvarchar(4);
+select 'asdf'::mvarchar <= 'aSdf 1'::mvarchar(5);
+select 'asdf'::mvarchar <= 'aSdf 1'::mvarchar(6);
+
+select 'asdf'::mvarchar >= 'aSdf'::mvarchar;
+select 'asdf'::mvarchar >= 'aSdf '::mvarchar;
+select 'asdf'::mvarchar >= 'aSdf 1'::mvarchar(4);
+select 'asdf'::mvarchar >= 'aSdf 1'::mvarchar(5);
+select 'asdf'::mvarchar >= 'aSdf 1'::mvarchar(6);
+
+select 'asdf'::mvarchar > 'aSdf'::mvarchar;
+select 'asdf'::mvarchar > 'aSdf '::mvarchar;
+select 'asdf'::mvarchar > 'aSdf 1'::mvarchar(4);
+select 'asdf'::mvarchar > 'aSdf 1'::mvarchar(5);
+select 'asdf'::mvarchar > 'aSdf 1'::mvarchar(6);
+
+select max(vch) from chvch;
+select min(vch) from chvch;
+
+select substr('1234567890'::mvarchar, 3) = '34567890' as "34567890";
+select substr('1234567890'::mvarchar, 4, 3) = '456' as "456";
+
+select lower('asdfASDF'::mvarchar);
+select upper('asdfASDF'::mvarchar);
+
+select 'asd'::mvarchar == 'aSd'::mvarchar;
+select 'asd'::mvarchar == 'aCd'::mvarchar;
+select 'asd'::mvarchar == NULL;
+select NULL == 'aCd'::mvarchar;
+select NULL::mvarchar == NULL;
+
diff -ruN a/contrib/mchar/uninstall_mchar--1.0.sql b/contrib/mchar/uninstall_mchar--1.0.sql
--- a/contrib/mchar/uninstall_mchar--1.0.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/mchar/uninstall_mchar--1.0.sql	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,9 @@
+SET search_path = public;
+BEGIN;
+
+DROP FUNCTION mchar_pattern_fixed_prefix(internal, internal, internal);
+DROP FUNCTION mchar_greaterstring(internal);
+DROP TYPE MCHAR CASCADE;
+DROP TYPE MVARCHAR CASCADE;
+
+COMMIT;
diff -ruN a/contrib/online_analyze/COPYRIGHT b/contrib/online_analyze/COPYRIGHT
--- a/contrib/online_analyze/COPYRIGHT	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/online_analyze/COPYRIGHT	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,29 @@
+/*
+ * Copyright (c) 2011 Teodor Sigaev <teodor@sigaev.ru>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *        notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *        notice, this list of conditions and the following disclaimer in the
+ *        documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of the author nor the names of any co-contributors
+ *        may be used to endorse or promote products derived from this software
+ *        without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY CONTRIBUTORS ``AS IS'' AND ANY EXPRESS
+ * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL CONTRIBUTORS BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
+ * GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
+ * IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
diff -ruN a/contrib/online_analyze/Makefile b/contrib/online_analyze/Makefile
--- a/contrib/online_analyze/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/online_analyze/Makefile	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,16 @@
+MODULE_big = online_analyze
+OBJS = online_analyze.o     
+#DATA_built = online_analyze.sql
+DOCS = README.online_analyze
+#REGRESS = online_analyze
+
+ifdef USE_PGXS
+PGXS := $(shell pg_config --pgxs)
+include $(PGXS)
+else
+subdir = contrib/online_analyze
+top_builddir = ../..
+include $(top_builddir)/src/Makefile.global
+include $(top_srcdir)/contrib/contrib-global.mk
+endif
+
diff -ruN a/contrib/online_analyze/online_analyze.c b/contrib/online_analyze/online_analyze.c
--- a/contrib/online_analyze/online_analyze.c	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/online_analyze/online_analyze.c	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,1206 @@
+/*
+ * Copyright (c) 2011 Teodor Sigaev <teodor@sigaev.ru>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *		notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *		notice, this list of conditions and the following disclaimer in the
+ *		documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of the author nor the names of any co-contributors
+ *		may be used to endorse or promote products derived from this software
+ *		without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY CONTRIBUTORS ``AS IS'' AND ANY EXPRESS
+ * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL CONTRIBUTORS BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
+ * GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
+ * IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "postgres.h"
+
+#include "pgstat.h"
+#include "access/transam.h"
+#include "access/xact.h"
+#include "catalog/namespace.h"
+#include "commands/vacuum.h"
+#include "executor/executor.h"
+#include "nodes/nodes.h"
+#include "nodes/parsenodes.h"
+#include "storage/bufmgr.h"
+#include "utils/builtins.h"
+#include "utils/hsearch.h"
+#include "utils/memutils.h"
+#include "utils/lsyscache.h"
+#include "utils/guc.h"
+#if PG_VERSION_NUM >= 90200
+#include "catalog/pg_class.h"
+#include "nodes/primnodes.h"
+#include "tcop/utility.h"
+#include "utils/rel.h"
+#include "utils/relcache.h"
+#include "utils/timestamp.h"
+#if PG_VERSION_NUM >= 90500
+#include "nodes/makefuncs.h"
+#if PG_VERSION_NUM >= 100000
+#include "utils/varlena.h"
+#include "utils/regproc.h"
+#endif
+#endif
+#endif
+
+#ifdef PG_MODULE_MAGIC
+PG_MODULE_MAGIC;
+#endif
+
+static bool online_analyze_enable = true;
+static bool online_analyze_local_tracking = false;
+static bool online_analyze_verbose = true;
+static double online_analyze_scale_factor = 0.1;
+static int online_analyze_threshold = 50;
+static int online_analyze_capacity_threshold = 100000;
+static double online_analyze_min_interval = 10000;
+static int online_analyze_lower_limit = 0;
+
+static ExecutorEnd_hook_type oldExecutorEndHook = NULL;
+#if PG_VERSION_NUM >= 90200
+static ProcessUtility_hook_type	oldProcessUtilityHook = NULL;
+#endif
+
+typedef enum CmdKind
+{
+	CK_SELECT = CMD_SELECT,
+	CK_UPDATE = CMD_UPDATE,
+	CK_INSERT = CMD_INSERT,
+	CK_DELETE = CMD_DELETE,
+	CK_TRUNCATE,
+	CK_FASTTRUNCATE,
+	CK_CREATE,
+	CK_ANALYZE,
+	CK_VACUUM
+} CmdKind;
+
+
+typedef enum
+{
+	OATT_ALL		= 0x03,
+	OATT_PERSISTENT = 0x01,
+	OATT_TEMPORARY  = 0x02,
+	OATT_NONE		= 0x00
+} OnlineAnalyzeTableType;
+
+static const struct config_enum_entry online_analyze_table_type_options[] =
+{
+	{"all", OATT_ALL, false},
+	{"persistent", OATT_PERSISTENT, false},
+	{"temporary", OATT_TEMPORARY, false},
+	{"none", OATT_NONE, false},
+	{NULL, 0, false},
+};
+
+static int online_analyze_table_type = (int)OATT_ALL;
+
+typedef struct TableList {
+	int		nTables;
+	Oid		*tables;
+	char	*tableStr;
+} TableList;
+
+static TableList excludeTables = {0, NULL, NULL};
+static TableList includeTables = {0, NULL, NULL};
+
+typedef struct OnlineAnalyzeTableStat {
+	Oid				tableid;
+	bool			rereadStat;
+	PgStat_Counter	n_tuples;
+	PgStat_Counter	changes_since_analyze;
+	TimestampTz		autovac_analyze_timestamp;
+	TimestampTz		analyze_timestamp;
+} OnlineAnalyzeTableStat;
+
+static	MemoryContext	onlineAnalyzeMemoryContext = NULL;
+static	HTAB	*relstats = NULL;
+
+static void relstatsInit(void);
+
+#if PG_VERSION_NUM < 100000
+static int
+oid_cmp(const void *a, const void *b)
+{
+	if (*(Oid*)a == *(Oid*)b)
+		return 0;
+	return (*(Oid*)a > *(Oid*)b) ? 1 : -1;
+}
+#endif
+
+static const char *
+tableListAssign(const char * newval, bool doit, TableList *tbl)
+{
+	char		*rawname;
+	List		*namelist;
+	ListCell	*l;
+	Oid			*newOids = NULL;
+	int			nOids = 0,
+				i = 0;
+
+	rawname = pstrdup(newval);
+
+	if (!SplitIdentifierString(rawname, ',', &namelist))
+		goto cleanup;
+
+	if (doit)
+	{
+		nOids = list_length(namelist);
+		newOids = malloc(sizeof(Oid) * (nOids+1));
+		if (!newOids)
+			elog(ERROR,"could not allocate %d bytes",
+				 (int)(sizeof(Oid) * (nOids+1)));
+	}
+
+	foreach(l, namelist)
+	{
+		char	*curname = (char *) lfirst(l);
+#if PG_VERSION_NUM >= 90200
+		Oid		relOid = RangeVarGetRelid(makeRangeVarFromNameList(
+							stringToQualifiedNameList(curname)), NoLock, true);
+#else
+		Oid		relOid = RangeVarGetRelid(makeRangeVarFromNameList(
+							stringToQualifiedNameList(curname)), true);
+#endif
+
+		if (relOid == InvalidOid)
+		{
+#if PG_VERSION_NUM >= 90100
+			if (doit == false)
+#endif
+			elog(WARNING,"'%s' does not exist", curname);
+			continue;
+		}
+		else if ( get_rel_relkind(relOid) != RELKIND_RELATION )
+		{
+#if PG_VERSION_NUM >= 90100
+			if (doit == false)
+#endif
+				elog(WARNING,"'%s' is not an table", curname);
+			continue;
+		}
+		else if (doit)
+		{
+			newOids[i++] = relOid;
+		}
+	}
+
+	if (doit)
+	{
+		tbl->nTables = i;
+		if (tbl->tables)
+			free(tbl->tables);
+		tbl->tables = newOids;
+		if (tbl->nTables > 1)
+			qsort(tbl->tables, tbl->nTables, sizeof(tbl->tables[0]), oid_cmp);
+	}
+
+	pfree(rawname);
+	list_free(namelist);
+
+	return newval;
+
+cleanup:
+	if (newOids)
+		free(newOids);
+	pfree(rawname);
+	list_free(namelist);
+	return NULL;
+}
+
+#if PG_VERSION_NUM >= 90100
+static bool
+excludeTablesCheck(char **newval, void **extra, GucSource source)
+{
+	char *val;
+
+	val = (char*)tableListAssign(*newval, false, &excludeTables);
+
+	if (val)
+	{
+		*newval = val;
+		return true;
+	}
+
+	return false;
+}
+
+static void
+excludeTablesAssign(const char *newval, void *extra)
+{
+	tableListAssign(newval, true, &excludeTables);
+}
+
+static bool
+includeTablesCheck(char **newval, void **extra, GucSource source)
+{
+	char *val;
+
+	val = (char*)tableListAssign(*newval, false, &includeTables);
+
+	if (val)
+	{
+		*newval = val;
+		return true;
+	}
+
+	return false;
+}
+
+static void
+includeTablesAssign(const char *newval, void *extra)
+{
+	tableListAssign(newval, true, &excludeTables);
+}
+
+#else /* PG_VERSION_NUM < 90100 */
+
+static const char *
+excludeTablesAssign(const char * newval, bool doit, GucSource source)
+{
+	return tableListAssign(newval, doit, &excludeTables);
+}
+
+static const char *
+includeTablesAssign(const char * newval, bool doit, GucSource source)
+{
+	return tableListAssign(newval, doit, &includeTables);
+}
+
+#endif
+
+static const char*
+tableListShow(TableList *tbl)
+{
+	char	*val, *ptr;
+	int		i,
+			len;
+
+	len = 1 /* \0 */ + tbl->nTables * (2 * NAMEDATALEN + 2 /* ', ' */ + 1 /* . */);
+	ptr = val = palloc(len);
+	*ptr ='\0';
+	for(i=0; i<tbl->nTables; i++)
+	{
+		char	*relname = get_rel_name(tbl->tables[i]);
+		Oid		nspOid = get_rel_namespace(tbl->tables[i]);
+		char	*nspname = get_namespace_name(nspOid);
+
+		if ( relname == NULL || nspOid == InvalidOid || nspname == NULL )
+			continue;
+
+		ptr += snprintf(ptr, len - (ptr - val), "%s%s.%s",
+													(i==0) ? "" : ", ",
+													nspname, relname);
+	}
+
+	return val;
+}
+
+static const char*
+excludeTablesShow(void)
+{
+	return tableListShow(&excludeTables);
+}
+
+static const char*
+includeTablesShow(void)
+{
+	return tableListShow(&includeTables);
+}
+
+static bool
+matchOid(TableList *tbl, Oid oid)
+{
+	Oid	*StopLow = tbl->tables,
+		*StopHigh = tbl->tables + tbl->nTables,
+		*StopMiddle;
+
+	/* Loop invariant: StopLow <= val < StopHigh */
+	while (StopLow < StopHigh)
+	{
+		StopMiddle = StopLow + ((StopHigh - StopLow) >> 1);
+
+		if (*StopMiddle == oid)
+			return true;
+		else  if (*StopMiddle < oid)
+			StopLow = StopMiddle + 1;
+		else
+			StopHigh = StopMiddle;
+	}
+
+	return false;
+}
+
+#if PG_VERSION_NUM >= 90500
+static RangeVar*
+makeRangeVarFromOid(Oid relOid)
+{
+	return makeRangeVar(
+				get_namespace_name(get_rel_namespace(relOid)),
+				get_rel_name(relOid),
+				-1
+			);
+
+}
+#endif
+
+static void
+makeAnalyze(Oid relOid, CmdKind operation, int64 naffected)
+{
+	TimestampTz				now = GetCurrentTimestamp();
+	Relation				rel;
+	OnlineAnalyzeTableType	reltype;
+	bool					found = false,
+							newTable = false;
+	OnlineAnalyzeTableStat	*rstat,
+							dummyrstat;
+	PgStat_StatTabEntry		*tabentry = NULL;
+
+	if (relOid == InvalidOid)
+		return;
+
+	if (naffected == 0)
+		/* return if there is no changes */
+		return;
+	else if (naffected < 0)
+		/* number if affected rows is unknown */
+		naffected = 0;
+
+	rel = RelationIdGetRelation(relOid);
+	if (rel->rd_rel->relkind != RELKIND_RELATION)
+	{
+		RelationClose(rel);
+		return;
+	}
+
+	reltype =
+#if PG_VERSION_NUM >= 90100
+		(rel->rd_rel->relpersistence == RELPERSISTENCE_TEMP)
+#else
+		(rel->rd_istemp || rel->rd_islocaltemp)
+#endif
+			? OATT_TEMPORARY : OATT_PERSISTENT;
+
+	RelationClose(rel);
+
+	/*
+	 * includeTables overwrites excludeTables
+	 */
+	switch(online_analyze_table_type)
+	{
+		case OATT_ALL:
+			if (get_rel_relkind(relOid) != RELKIND_RELATION ||
+				(matchOid(&excludeTables, relOid) == true &&
+				matchOid(&includeTables, relOid) == false))
+				return;
+			break;
+		case OATT_NONE:
+			if (get_rel_relkind(relOid) != RELKIND_RELATION ||
+				matchOid(&includeTables, relOid) == false)
+				return;
+			break;
+		case OATT_TEMPORARY:
+		case OATT_PERSISTENT:
+		default:
+			/*
+			 * skip analyze if relation's type doesn't not match
+			 * online_analyze_table_type
+			 */
+			if ((online_analyze_table_type & reltype) == 0 ||
+				matchOid(&excludeTables, relOid) == true)
+			{
+				if (matchOid(&includeTables, relOid) == false)
+					return;
+			}
+			break;
+	}
+
+	/*
+	 * Do not store data about persistent table in local memory because we
+	 * could not track changes of them: they could be changed by another
+	 * backends. So always get a pgstat table entry.
+	 */
+	if (reltype == OATT_TEMPORARY)
+		rstat = hash_search(relstats, &relOid, HASH_ENTER, &found);
+	else
+		rstat = &dummyrstat; /* found == false for following if */
+
+	if (!found)
+	{
+		MemSet(rstat, 0, sizeof(*rstat));
+		rstat->tableid = relOid;
+		newTable = true;
+	}
+	else if (operation == CK_VACUUM)
+	{
+		/* force reread becouse vacuum could change n_tuples */
+		rstat->rereadStat = true;
+		return;
+	}
+	else if (operation == CK_ANALYZE)
+	{
+		/* only analyze */
+		rstat->changes_since_analyze = 0;
+		rstat->analyze_timestamp = now;
+		return;
+	}
+
+	Assert(rstat->tableid == relOid);
+
+	if (
+		/* do not reread data if it was a truncation */
+		operation != CK_TRUNCATE && operation != CK_FASTTRUNCATE &&
+		/* read  for persistent table and for temp teble if it allowed */
+		(reltype == OATT_PERSISTENT || online_analyze_local_tracking == false) &&
+		/* read only for new table or we know that it's needed */
+		(newTable == true || rstat->rereadStat == true)
+	   )
+	{
+		rstat->rereadStat = false;
+
+		tabentry = pgstat_fetch_stat_tabentry(relOid);
+
+		if (tabentry)
+		{
+			rstat->n_tuples = tabentry->n_dead_tuples + tabentry->n_live_tuples;
+			rstat->changes_since_analyze =
+#if PG_VERSION_NUM >= 90000
+				tabentry->changes_since_analyze;
+#else
+				tabentry->n_live_tuples + tabentry->n_dead_tuples -
+					tabentry->last_anl_tuples;
+#endif
+			rstat->autovac_analyze_timestamp =
+				tabentry->autovac_analyze_timestamp;
+			rstat->analyze_timestamp = tabentry->analyze_timestamp;
+		}
+	}
+
+	if (newTable ||
+		/* force analyze after truncate, fasttruncate already did analyze */
+		operation == CK_TRUNCATE || (
+		/* do not analyze too often, if both stamps are exceeded the go */
+		TimestampDifferenceExceeds(rstat->analyze_timestamp, now, online_analyze_min_interval) &&
+		TimestampDifferenceExceeds(rstat->autovac_analyze_timestamp, now, online_analyze_min_interval) &&
+		/* do not analyze too small tables */
+		rstat->n_tuples + rstat->changes_since_analyze + naffected > online_analyze_lower_limit &&
+		/* be in sync with relation_needs_vacanalyze */
+		((double)(rstat->changes_since_analyze + naffected)) >=
+			 online_analyze_scale_factor * ((double)rstat->n_tuples) +
+			 (double)online_analyze_threshold))
+	{
+#if PG_VERSION_NUM < 90500
+		VacuumStmt				vacstmt;
+#else
+		VacuumParams			vacstmt;
+#endif
+		TimestampTz				startStamp, endStamp;
+
+
+		memset(&startStamp, 0, sizeof(startStamp)); /* keep compiler quiet */
+
+		memset(&vacstmt, 0, sizeof(vacstmt));
+
+		vacstmt.freeze_min_age = -1;
+		vacstmt.freeze_table_age = -1; /* ??? */
+
+#if PG_VERSION_NUM < 90500
+		vacstmt.type = T_VacuumStmt;
+		vacstmt.relation = NULL;
+		vacstmt.va_cols = NIL;
+#if PG_VERSION_NUM >= 90000
+		vacstmt.options = VACOPT_ANALYZE;
+		if (online_analyze_verbose)
+			vacstmt.options |= VACOPT_VERBOSE;
+#else
+		vacstmt.vacuum = vacstmt.full = false;
+		vacstmt.analyze = true;
+		vacstmt.verbose = online_analyze_verbose;
+#endif
+#else
+		vacstmt.multixact_freeze_min_age = -1;
+		vacstmt.multixact_freeze_table_age = -1;
+		vacstmt.log_min_duration = -1;
+#endif
+
+		if (online_analyze_verbose)
+			startStamp = GetCurrentTimestamp();
+
+		analyze_rel(relOid,
+#if PG_VERSION_NUM < 90500
+			&vacstmt
+#if PG_VERSION_NUM >= 90018
+			, true
+#endif
+			, GetAccessStrategy(BAS_VACUUM)
+#if (PG_VERSION_NUM >= 90000) && (PG_VERSION_NUM < 90004)
+			, true
+#endif
+#else
+			makeRangeVarFromOid(relOid),
+			VACOPT_ANALYZE | ((online_analyze_verbose) ? VACOPT_VERBOSE : 0),
+			&vacstmt, NULL, true, GetAccessStrategy(BAS_VACUUM)
+#endif
+		);
+
+		if (online_analyze_verbose)
+		{
+			long	secs;
+			int		microsecs;
+
+			endStamp = GetCurrentTimestamp();
+			TimestampDifference(startStamp, endStamp, &secs, &microsecs);
+			elog(INFO, "analyze \"%s\" took %.02f seconds",
+				get_rel_name(relOid),
+				((double)secs) + ((double)microsecs)/1.0e6);
+		}
+
+		rstat->autovac_analyze_timestamp = now;
+		rstat->changes_since_analyze = 0;
+
+		switch(operation)
+		{
+			case CK_CREATE:
+			case CK_INSERT:
+			case CK_UPDATE:
+				rstat->n_tuples += naffected;
+			case CK_DELETE:
+				rstat->rereadStat = (reltype == OATT_PERSISTENT);
+				break;
+			case CK_TRUNCATE:
+			case CK_FASTTRUNCATE:
+				rstat->rereadStat = false;
+				rstat->n_tuples = 0;
+				break;
+			default:
+				break;
+		}
+
+		/* update last analyze timestamp in local memory of backend */
+		if (tabentry)
+		{
+			tabentry->analyze_timestamp = now;
+			tabentry->changes_since_analyze = 0;
+		}
+#if 0
+		/* force reload stat for new table */
+		if (newTable)
+			pgstat_clear_snapshot();
+#endif
+	}
+	else
+	{
+#if PG_VERSION_NUM >= 90000
+		if (tabentry)
+			tabentry->changes_since_analyze += naffected;
+#endif
+		switch(operation)
+		{
+			case CK_CREATE:
+			case CK_INSERT:
+				rstat->changes_since_analyze += naffected;
+				rstat->n_tuples += naffected;
+				break;
+			case CK_UPDATE:
+				rstat->changes_since_analyze += 2 * naffected;
+				rstat->n_tuples += naffected;
+			case CK_DELETE:
+				rstat->changes_since_analyze += naffected;
+				break;
+			case CK_TRUNCATE:
+			case CK_FASTTRUNCATE:
+				rstat->changes_since_analyze = 0;
+				rstat->n_tuples = 0;
+				break;
+			default:
+				break;
+		}
+	}
+
+	/* Reset local cache if we are over limit */
+	if (hash_get_num_entries(relstats) > online_analyze_capacity_threshold)
+		relstatsInit();
+}
+
+static Const*
+isFastTruncateCall(QueryDesc *queryDesc)
+{
+	TargetEntry	*te;
+	FuncExpr	*fe;
+	Const		*constval;
+
+	if (!(
+		  queryDesc->plannedstmt &&
+		  queryDesc->operation == CMD_SELECT &&
+		  queryDesc->plannedstmt->planTree &&
+		  queryDesc->plannedstmt->planTree->targetlist &&
+		  list_length(queryDesc->plannedstmt->planTree->targetlist) == 1
+		 ))
+		return NULL;
+
+	te = linitial(queryDesc->plannedstmt->planTree->targetlist);
+
+	if (!IsA(te, TargetEntry))
+		return NULL;
+
+	fe = (FuncExpr*)te->expr;
+
+	if (!(
+		  fe && IsA(fe, FuncExpr) &&
+		  fe->funcid >= FirstNormalObjectId &&
+		  fe->funcretset == false &&
+		  fe->funcresulttype == VOIDOID &&
+		  fe->funcvariadic == false &&
+		  list_length(fe->args) == 1
+		 ))
+		return NULL;
+
+	constval = linitial(fe->args);
+
+	if (!(
+		  IsA(constval,Const) &&
+		  constval->consttype == TEXTOID &&
+		  strcmp(get_func_name(fe->funcid), "fasttruncate") == 0
+		 ))
+		return NULL;
+
+	return constval;
+}
+
+
+extern PGDLLIMPORT void onlineAnalyzeHooker(QueryDesc *queryDesc);
+void
+onlineAnalyzeHooker(QueryDesc *queryDesc)
+{
+	int64	naffected = -1;
+	Const	*constval;
+
+	if (queryDesc->estate)
+		naffected = queryDesc->estate->es_processed;
+
+#if PG_VERSION_NUM >= 90200
+	if (online_analyze_enable &&
+		(constval = isFastTruncateCall(queryDesc)) != NULL)
+	{
+		Datum		tblnamed = constval->constvalue;
+		char		*tblname = text_to_cstring(DatumGetTextP(tblnamed));
+		RangeVar	*tblvar =
+			makeRangeVarFromNameList(stringToQualifiedNameList(tblname));
+
+		makeAnalyze(RangeVarGetRelid(tblvar,
+									 NoLock,
+									 false),
+					CK_FASTTRUNCATE, -1);
+	}
+#endif
+
+	if (online_analyze_enable && queryDesc->plannedstmt &&
+			(queryDesc->operation == CMD_INSERT ||
+			 queryDesc->operation == CMD_UPDATE ||
+			 queryDesc->operation == CMD_DELETE
+#if PG_VERSION_NUM < 90200
+			 || (queryDesc->operation == CMD_SELECT &&
+				 queryDesc->plannedstmt->intoClause)
+#endif
+			 ))
+	{
+#if PG_VERSION_NUM < 90200
+		if (queryDesc->operation == CMD_SELECT)
+		{
+			Oid	relOid = RangeVarGetRelid(queryDesc->plannedstmt->intoClause->rel, true);
+
+			makeAnalyze(relOid, queryDesc->operation, naffected);
+		}
+		else
+#endif
+		if (queryDesc->plannedstmt->resultRelations &&
+				 queryDesc->plannedstmt->rtable)
+		{
+			ListCell	*l;
+
+			foreach(l, queryDesc->plannedstmt->resultRelations)
+			{
+				int				n = lfirst_int(l);
+				RangeTblEntry	*rte = list_nth(queryDesc->plannedstmt->rtable, n-1);
+
+				if (rte->rtekind == RTE_RELATION)
+					makeAnalyze(rte->relid, (CmdKind)queryDesc->operation, naffected);
+			}
+		}
+	}
+
+	if (oldExecutorEndHook)
+		oldExecutorEndHook(queryDesc);
+	else
+		standard_ExecutorEnd(queryDesc);
+}
+
+static List		*toremove = NIL;
+
+/*
+ * removeTable called on transaction end, see call RegisterXactCallback() below
+ */
+static void
+removeTable(XactEvent event, void *arg)
+{
+	ListCell	*cell;
+
+	switch(event)
+	{
+		case XACT_EVENT_COMMIT:
+			break;
+		case XACT_EVENT_ABORT:
+			toremove = NIL;
+		default:
+			return;
+	}
+
+	foreach(cell, toremove)
+	{
+		Oid	relOid = lfirst_oid(cell);
+
+		hash_search(relstats, &relOid, HASH_REMOVE, NULL);
+	}
+
+	toremove = NIL;
+}
+
+
+#if PG_VERSION_NUM >= 90200
+static void
+onlineAnalyzeHookerUtility(
+#if PG_VERSION_NUM >= 100000
+						   PlannedStmt *pstmt,
+#else
+						   Node *parsetree,
+#endif
+						   const char *queryString,
+#if PG_VERSION_NUM >= 90300
+							ProcessUtilityContext context, ParamListInfo params,
+#if PG_VERSION_NUM >= 100000
+							QueryEnvironment *queryEnv,
+#endif
+#else
+							ParamListInfo params, bool isTopLevel,
+#endif
+							DestReceiver *dest, char *completionTag) {
+	List		*tblnames = NIL;
+	CmdKind		op = CK_INSERT;
+#if PG_VERSION_NUM >= 100000
+	Node		*parsetree = NULL;
+
+	if (pstmt->commandType == CMD_UTILITY)
+		parsetree = pstmt->utilityStmt;
+#endif
+
+	if (parsetree && online_analyze_enable)
+	{
+		if (IsA(parsetree, CreateTableAsStmt) &&
+			((CreateTableAsStmt*)parsetree)->into)
+		{
+			tblnames =
+				list_make1((RangeVar*)copyObject(((CreateTableAsStmt*)parsetree)->into->rel));
+			op = CK_CREATE;
+		}
+		else if (IsA(parsetree, TruncateStmt))
+		{
+			tblnames = list_copy(((TruncateStmt*)parsetree)->relations);
+			op = CK_TRUNCATE;
+		}
+		else if (IsA(parsetree, DropStmt) &&
+				 ((DropStmt*)parsetree)->removeType == OBJECT_TABLE)
+		{
+			ListCell	*cell;
+
+			foreach(cell, ((DropStmt*)parsetree)->objects)
+			{
+				List		*relname = (List *) lfirst(cell);
+				RangeVar	*rel = makeRangeVarFromNameList(relname);
+				Oid			relOid = RangeVarGetRelid(rel, NoLock, true);
+
+				if (OidIsValid(relOid))
+				{
+					MemoryContext	ctx;
+
+					ctx = MemoryContextSwitchTo(TopTransactionContext);
+					toremove = lappend_oid(toremove, relOid);
+					MemoryContextSwitchTo(ctx);
+				}
+			}
+		}
+		else if (IsA(parsetree, VacuumStmt))
+		{
+			VacuumStmt	*vac = (VacuumStmt*)parsetree;
+
+			tblnames = list_make1(vac->relation);
+
+			if (vac->options & (VACOPT_VACUUM | VACOPT_FULL | VACOPT_FREEZE))
+				/* optionally with analyze */
+				op = CK_VACUUM;
+			else if (vac->options & VACOPT_ANALYZE)
+				op = CK_ANALYZE;
+			else
+				tblnames = NIL;
+		}
+	}
+
+#if PG_VERSION_NUM >= 100000
+#define parsetree pstmt
+#endif
+
+	if (oldProcessUtilityHook)
+		oldProcessUtilityHook(parsetree, queryString,
+#if PG_VERSION_NUM >= 90300
+							  context, params,
+#if PG_VERSION_NUM >= 100000
+							  queryEnv,
+#endif
+#else
+							  params, isTopLevel,
+#endif
+							  dest, completionTag);
+	else
+		standard_ProcessUtility(parsetree, queryString,
+#if PG_VERSION_NUM >= 90300
+								context, params,
+#if PG_VERSION_NUM >= 100000
+								queryEnv,
+#endif
+#else
+								params, isTopLevel,
+#endif
+								dest, completionTag);
+
+#if PG_VERSION_NUM >= 100000
+#undef parsetree
+#endif
+
+	if (tblnames) {
+		ListCell	*l;
+
+		foreach(l, tblnames)
+		{
+			RangeVar	*tblname = (RangeVar*)lfirst(l);
+			Oid	tblOid = RangeVarGetRelid(tblname, NoLock, true);
+
+			makeAnalyze(tblOid, op, -1);
+		}
+	}
+}
+#endif
+
+static void
+relstatsInit(void)
+{
+	HASHCTL	hash_ctl;
+	int		flags = 0;
+
+	MemSet(&hash_ctl, 0, sizeof(hash_ctl));
+
+	hash_ctl.hash = oid_hash;
+	flags |= HASH_FUNCTION;
+
+	if (onlineAnalyzeMemoryContext)
+	{
+		Assert(relstats != NULL);
+		MemoryContextReset(onlineAnalyzeMemoryContext);
+	}
+	else
+	{
+		Assert(relstats == NULL);
+		onlineAnalyzeMemoryContext =
+			AllocSetContextCreate(CacheMemoryContext,
+								  "online_analyze storage context",
+#if PG_VERSION_NUM < 90600
+								  ALLOCSET_DEFAULT_MINSIZE,
+								  ALLOCSET_DEFAULT_INITSIZE,
+								  ALLOCSET_DEFAULT_MAXSIZE
+#else
+								  ALLOCSET_DEFAULT_SIZES
+#endif
+								 );
+	}
+
+	hash_ctl.hcxt = onlineAnalyzeMemoryContext;
+	flags |= HASH_CONTEXT;
+
+	hash_ctl.keysize = sizeof(Oid);
+
+	hash_ctl.entrysize = sizeof(OnlineAnalyzeTableStat);
+	flags |= HASH_ELEM;
+
+	relstats = hash_create("online_analyze storage", 1024, &hash_ctl, flags);
+}
+
+void _PG_init(void);
+void
+_PG_init(void)
+{
+	relstatsInit();
+
+	oldExecutorEndHook = ExecutorEnd_hook;
+
+	ExecutorEnd_hook = onlineAnalyzeHooker;
+
+#if PG_VERSION_NUM >= 90200
+	oldProcessUtilityHook = ProcessUtility_hook;
+
+	ProcessUtility_hook = onlineAnalyzeHookerUtility;
+#endif
+
+
+	DefineCustomBoolVariable(
+		"online_analyze.enable",
+		"Enable on-line analyze",
+		"Enables analyze of table directly after insert/update/delete/select into",
+		&online_analyze_enable,
+#if PG_VERSION_NUM >= 80400
+		online_analyze_enable,
+#endif
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	DefineCustomBoolVariable(
+		"online_analyze.local_tracking",
+		"Per backend tracking",
+		"Per backend tracking for temp tables (do not use system statistic)",
+		&online_analyze_local_tracking,
+#if PG_VERSION_NUM >= 80400
+		online_analyze_local_tracking,
+#endif
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	DefineCustomBoolVariable(
+		"online_analyze.verbose",
+		"Verbosity of on-line analyze",
+		"Make ANALYZE VERBOSE after table's changes",
+		&online_analyze_verbose,
+#if PG_VERSION_NUM >= 80400
+		online_analyze_verbose,
+#endif
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	DefineCustomRealVariable(
+		"online_analyze.scale_factor",
+		"fraction of table size to start on-line analyze",
+		"fraction of table size to start on-line analyze",
+		&online_analyze_scale_factor,
+#if PG_VERSION_NUM >= 80400
+		online_analyze_scale_factor,
+#endif
+		0.0,
+		1.0,
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	DefineCustomIntVariable(
+		"online_analyze.threshold",
+		"min number of row updates before on-line analyze",
+		"min number of row updates before on-line analyze",
+		&online_analyze_threshold,
+#if PG_VERSION_NUM >= 80400
+		online_analyze_threshold,
+#endif
+		0,
+		0x7fffffff,
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	DefineCustomIntVariable(
+		"online_analyze.capacity_threshold",
+		"Max local cache table capacity",
+		"Max local cache table capacity",
+		&online_analyze_capacity_threshold,
+#if PG_VERSION_NUM >= 80400
+		online_analyze_capacity_threshold,
+#endif
+		0,
+		0x7fffffff,
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	DefineCustomRealVariable(
+		"online_analyze.min_interval",
+		"minimum time interval between analyze call (in milliseconds)",
+		"minimum time interval between analyze call (in milliseconds)",
+		&online_analyze_min_interval,
+#if PG_VERSION_NUM >= 80400
+		online_analyze_min_interval,
+#endif
+		0.0,
+		1e30,
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	DefineCustomEnumVariable(
+		"online_analyze.table_type",
+		"Type(s) of table for online analyze: all(default), persistent, temporary, none",
+		NULL,
+		&online_analyze_table_type,
+#if PG_VERSION_NUM >= 80400
+		online_analyze_table_type,
+#endif
+		online_analyze_table_type_options,
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	DefineCustomStringVariable(
+		"online_analyze.exclude_tables",
+		"List of tables which will not online analyze",
+		NULL,
+		&excludeTables.tableStr,
+#if PG_VERSION_NUM >= 80400
+		"",
+#endif
+		PGC_USERSET,
+		0,
+#if PG_VERSION_NUM >= 90100
+		excludeTablesCheck,
+		excludeTablesAssign,
+#else
+		excludeTablesAssign,
+#endif
+		excludeTablesShow
+	);
+
+	DefineCustomStringVariable(
+		"online_analyze.include_tables",
+		"List of tables which will online analyze",
+		NULL,
+		&includeTables.tableStr,
+#if PG_VERSION_NUM >= 80400
+		"",
+#endif
+		PGC_USERSET,
+		0,
+#if PG_VERSION_NUM >= 90100
+		includeTablesCheck,
+		includeTablesAssign,
+#else
+		includeTablesAssign,
+#endif
+		includeTablesShow
+	);
+
+	DefineCustomIntVariable(
+		"online_analyze.lower_limit",
+		"min number of rows in table to analyze",
+		"min number of rows in table to analyze",
+		&online_analyze_lower_limit,
+#if PG_VERSION_NUM >= 80400
+		online_analyze_lower_limit,
+#endif
+		0,
+		0x7fffffff,
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	RegisterXactCallback(removeTable, NULL);
+}
+
+void _PG_fini(void);
+void
+_PG_fini(void)
+{
+	ExecutorEnd_hook = oldExecutorEndHook;
+#if PG_VERSION_NUM >= 90200
+	ProcessUtility_hook = oldProcessUtilityHook;
+#endif
+
+	if (excludeTables.tables)
+		free(excludeTables.tables);
+	if (includeTables.tables)
+		free(includeTables.tables);
+
+	excludeTables.tables = includeTables.tables = NULL;
+	excludeTables.nTables = includeTables.nTables = 0;
+}
diff -ruN a/contrib/online_analyze/README.online_analyze b/contrib/online_analyze/README.online_analyze
--- a/contrib/online_analyze/README.online_analyze	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/online_analyze/README.online_analyze	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,46 @@
+Module makes an analyze call immediately after INSERT/UPDATE/DELETE/SELECT INTO
+for affected table(s).
+
+Supported versions of PostgreSQL: 8.4.*, 9.0.*, 9.1.*, 9.2.*, 9.3.*, 9.4*, 9.5*,
+		  9.6*
+
+Usage: LOAD 'online_analyze';
+
+Custom variables (defaults values are shown):
+online_analyze.enable = on  
+	Enables on-line analyze
+
+online_analyze.local_tracking = off
+	Per backend tracking for temp tables (do not use system statistic)
+
+online_analyze.verbose = on
+	Execute ANALYZE VERBOSE
+
+online_analyze.scale_factor = 0.1
+	Fraction of table size to start on-line analyze (similar to
+	autovacuum_analyze_scale_factor)
+
+online_analyze.threshold = 50
+	Min number of row updates before on-line analyze (similar to
+	autovacuum_analyze_threshold)
+
+online_analyze.min_interval = 10000
+    Minimum time interval between analyze call per table (in milliseconds)
+
+online_analyze.lower_limit = 0
+	Min number of rows in table to analyze
+
+online_analyze.table_type = "all"
+	Type(s) of table for online analyze: all, persistent, temporary, none
+
+online_analyze.exclude_tables = ""
+	List of tables which will not online analyze
+
+online_analyze.include_tables = ""
+	List of tables which will online analyze
+	online_analyze.include_tables overwrites online_analyze.exclude_tables.
+
+online_analyze.capacity_threshold = 100000
+	Maximum number of temporary tables to store in local cache
+
+Author: Teodor Sigaev <teodor@sigaev.ru>
diff -ruN a/contrib/plantuner/COPYRIGHT b/contrib/plantuner/COPYRIGHT
--- a/contrib/plantuner/COPYRIGHT	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/plantuner/COPYRIGHT	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,29 @@
+/*
+ * Copyright (c) 2009 Teodor Sigaev <teodor@sigaev.ru>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *        notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *        notice, this list of conditions and the following disclaimer in the
+ *        documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of the author nor the names of any co-contributors
+ *        may be used to endorse or promote products derived from this software
+ *        without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY CONTRIBUTORS ``AS IS'' AND ANY EXPRESS
+ * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL CONTRIBUTORS BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
+ * GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
+ * IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
diff -ruN a/contrib/plantuner/expected/plantuner.out b/contrib/plantuner/expected/plantuner.out
--- a/contrib/plantuner/expected/plantuner.out	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/plantuner/expected/plantuner.out	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,49 @@
+LOAD 'plantuner';
+SHOW	plantuner.disable_index;
+ plantuner.disable_index 
+-------------------------
+ 
+(1 row)
+
+CREATE TABLE wow (i int, j int);
+CREATE INDEX i_idx ON wow (i);
+CREATE INDEX j_idx ON wow (j);
+SET enable_seqscan=off;
+SELECT * FROM wow;
+ i | j 
+---+---
+(0 rows)
+
+SET plantuner.disable_index="i_idx, j_idx";
+SELECT * FROM wow;
+ i | j 
+---+---
+(0 rows)
+
+SHOW plantuner.disable_index;
+  plantuner.disable_index   
+----------------------------
+ public.i_idx, public.j_idx
+(1 row)
+
+SET plantuner.disable_index="i_idx, nonexistent, public.j_idx, wow";
+WARNING:  'nonexistent' does not exist
+WARNING:  'wow' is not an index
+SHOW plantuner.disable_index;
+  plantuner.disable_index   
+----------------------------
+ public.i_idx, public.j_idx
+(1 row)
+
+SET plantuner.enable_index="i_idx";
+SHOW plantuner.enable_index;
+ plantuner.enable_index 
+------------------------
+ public.i_idx
+(1 row)
+
+SELECT * FROM wow;
+ i | j 
+---+---
+(0 rows)
+
diff -ruN a/contrib/plantuner/Makefile b/contrib/plantuner/Makefile
--- a/contrib/plantuner/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/plantuner/Makefile	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,15 @@
+MODULE_big = plantuner
+DOCS = README.plantuner
+REGRESS = plantuner
+OBJS=plantuner.o
+
+ifdef USE_PGXS
+PGXS = $(shell pg_config --pgxs)
+include $(PGXS)
+else
+subdir = contrib/plantuner
+top_builddir = ../..
+include $(top_builddir)/src/Makefile.global
+
+include $(top_srcdir)/contrib/contrib-global.mk
+endif
diff -ruN a/contrib/plantuner/plantuner.c b/contrib/plantuner/plantuner.c
--- a/contrib/plantuner/plantuner.c	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/plantuner/plantuner.c	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,380 @@
+/*
+ * Copyright (c) 2009 Teodor Sigaev <teodor@sigaev.ru>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *        notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *        notice, this list of conditions and the following disclaimer in the
+ *        documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of the author nor the names of any co-contributors
+ *        may be used to endorse or promote products derived from this software
+ *        without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY CONTRIBUTORS ``AS IS'' AND ANY EXPRESS
+ * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL CONTRIBUTORS BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
+ * GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
+ * IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
+ * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <postgres.h>
+
+#include <fmgr.h>
+#include <access/heapam.h>
+#include <catalog/namespace.h>
+#include <catalog/pg_class.h>
+#include <nodes/pg_list.h>
+#include <optimizer/plancat.h>
+#include <storage/bufmgr.h>
+#include <utils/builtins.h>
+#include <utils/varlena.h>
+#include <utils/guc.h>
+#include <utils/lsyscache.h>
+#include <utils/rel.h>
+#include <utils/regproc.h>
+
+PG_MODULE_MAGIC;
+
+static int 	nDisabledIndexes = 0;
+static Oid	*disabledIndexes = NULL;
+static char *disableIndexesOutStr = "";
+
+static int 	nEnabledIndexes = 0;
+static Oid	*enabledIndexes = NULL;
+static char *enableIndexesOutStr = "";
+
+get_relation_info_hook_type	prevHook = NULL;
+static bool	fix_empty_table = false;
+
+
+static const char *
+indexesAssign(const char * newval, bool doit, GucSource source, bool isDisable) 
+{
+	char       *rawname;
+	List       *namelist;
+	ListCell   *l;
+	Oid			*newOids = NULL;
+	int			nOids = 0,
+				i = 0;
+
+	rawname = pstrdup(newval);
+
+	if (!SplitIdentifierString(rawname, ',', &namelist))
+		goto cleanup;
+
+	if (doit) 
+	{
+		nOids = list_length(namelist);
+		newOids = malloc(sizeof(Oid) * (nOids+1));
+		if (!newOids)
+			elog(ERROR,"could not allocate %d bytes", (int)(sizeof(Oid) * (nOids+1)));
+	}
+
+	foreach(l, namelist)
+	{
+		char     	*curname = (char *) lfirst(l);
+#if PG_VERSION_NUM >= 90200
+		Oid			indexOid = RangeVarGetRelid(makeRangeVarFromNameList(stringToQualifiedNameList(curname)), 
+												NoLock, true);
+#else
+		Oid			indexOid = RangeVarGetRelid(makeRangeVarFromNameList(stringToQualifiedNameList(curname)), 
+												true);
+#endif
+
+		if (indexOid == InvalidOid)
+		{
+#if PG_VERSION_NUM >= 90100
+			if (doit == false)
+#endif
+				elog(WARNING,"'%s' does not exist", curname);
+			continue;
+		}
+		else if ( get_rel_relkind(indexOid) != RELKIND_INDEX )
+		{
+#if PG_VERSION_NUM >= 90100
+			if (doit == false)
+#endif
+				elog(WARNING,"'%s' is not an index", curname);
+			continue;
+		}
+		else if (doit)
+		{
+			newOids[i++] = indexOid;
+		}
+	}
+
+	if (doit) 
+	{
+		if (isDisable)
+		{
+			nDisabledIndexes = nOids;
+			disabledIndexes = newOids;
+		}
+		else
+		{
+			nEnabledIndexes = nOids;
+			enabledIndexes = newOids;
+		}
+	}
+
+	pfree(rawname);
+	list_free(namelist);
+
+	return newval;
+
+cleanup:
+	if (newOids)
+		free(newOids);
+	pfree(rawname);
+	list_free(namelist);
+	return NULL;
+}
+
+static const char *
+assignDisabledIndexes(const char * newval, bool doit, GucSource source)
+{
+	return indexesAssign(newval, doit, source, true);	
+}
+
+static const char *
+assignEnabledIndexes(const char * newval, bool doit, GucSource source)
+{
+	return indexesAssign(newval, doit, source, false);	
+}
+
+#if PG_VERSION_NUM >= 90100
+
+static bool
+checkDisabledIndexes(char **newval, void **extra, GucSource source)
+{
+	char *val;
+
+	val = (char*)indexesAssign(*newval, false, source, true);
+
+	if (val)
+	{
+		*newval = val;
+		return true;
+	}
+
+	return false;
+}
+
+static bool
+checkEnabledIndexes(char **newval, void **extra, GucSource source)
+{
+	char *val;
+
+	val = (char*)indexesAssign(*newval, false, source, false);
+
+	if (val)
+	{
+		*newval = val;
+		return true;
+	}
+
+	return false;
+}
+
+static void
+assignDisabledIndexesNew(const char *newval, void *extra)
+{
+	assignDisabledIndexes(newval, true, PGC_S_USER /* doesn't matter */);
+}
+
+static void
+assignEnabledIndexesNew(const char *newval, void *extra)
+{
+	assignEnabledIndexes(newval, true, PGC_S_USER /* doesn't matter */);
+}
+
+#endif
+
+static void
+indexFilter(PlannerInfo *root, Oid relationObjectId, bool inhparent, RelOptInfo *rel) {
+	int i;
+
+	for(i=0;i<nDisabledIndexes;i++)
+	{
+		ListCell   *l;
+
+		foreach(l, rel->indexlist)
+		{
+			IndexOptInfo	*info = (IndexOptInfo*)lfirst(l);
+
+			if (disabledIndexes[i] == info->indexoid)
+			{
+				int j;
+
+				for(j=0; j<nEnabledIndexes; j++)
+					if (enabledIndexes[j] == info->indexoid)
+						break;
+
+				if (j >= nEnabledIndexes)
+					rel->indexlist = list_delete_ptr(rel->indexlist, info);
+
+				break;
+			}
+		}
+	}
+}
+
+static void
+execPlantuner(PlannerInfo *root, Oid relationObjectId, bool inhparent, RelOptInfo *rel) {
+	Relation 	relation;
+
+	relation = heap_open(relationObjectId, NoLock);
+	if (relation->rd_rel->relkind == RELKIND_RELATION)
+	{
+		if (fix_empty_table && RelationGetNumberOfBlocks(relation) == 0)
+		{
+			/*
+			 * estimate_rel_size() could be too pessimistic for particular
+			 * workload
+			 */
+			rel->pages = 0.0;
+			rel->tuples = 0.0;
+		}
+
+		indexFilter(root, relationObjectId, inhparent, rel);
+	}
+	heap_close(relation, NoLock);
+
+	/*
+	 * Call next hook if it exists 
+	 */
+	if (prevHook)
+		prevHook(root, relationObjectId, inhparent, rel);
+}
+
+static const char*
+IndexFilterShow(Oid* indexes, int nIndexes) 
+{
+	char 	*val, *ptr;
+	int 	i,
+			len;
+
+	len = 1 /* \0 */ + nIndexes * (2 * NAMEDATALEN + 2 /* ', ' */ + 1 /* . */);
+	ptr = val = palloc(len);
+
+	*ptr =(char)'\0';
+	for(i=0; i<nIndexes; i++)
+	{
+		char 	*relname = get_rel_name(indexes[i]);
+		Oid 	nspOid = get_rel_namespace(indexes[i]);
+		char 	*nspname = get_namespace_name(nspOid); 
+
+		if ( relname == NULL || nspOid == InvalidOid || nspname == NULL )
+			continue;
+
+		ptr += snprintf(ptr, len - (ptr - val), "%s%s.%s",
+												(i==0) ? "" : ", ",
+												nspname,
+												relname);
+	}
+
+	return val;
+}
+
+static const char*
+disabledIndexFilterShow(void)
+{
+	return IndexFilterShow(disabledIndexes, nDisabledIndexes);
+}
+
+static const char*
+enabledIndexFilterShow(void)
+{
+	return IndexFilterShow(enabledIndexes, nEnabledIndexes);
+}
+
+void _PG_init(void);
+void
+_PG_init(void) 
+{
+    DefineCustomStringVariable(
+		"plantuner.forbid_index",
+		"List of forbidden indexes (deprecated)",
+		"Listed indexes will not be used in queries (deprecated, use plantuner.disable_index)",
+		&disableIndexesOutStr,
+		"",
+		PGC_USERSET,
+		0,
+#if PG_VERSION_NUM >= 90100
+		checkDisabledIndexes,
+		assignDisabledIndexesNew,
+#else
+		assignDisabledIndexes,
+#endif
+		disabledIndexFilterShow
+	);
+
+    DefineCustomStringVariable(
+		"plantuner.disable_index",
+		"List of disabled indexes",
+		"Listed indexes will not be used in queries",
+		&disableIndexesOutStr,
+		"",
+		PGC_USERSET,
+		0,
+#if PG_VERSION_NUM >= 90100
+		checkDisabledIndexes,
+		assignDisabledIndexesNew,
+#else
+		assignDisabledIndexes,
+#endif
+		disabledIndexFilterShow
+	);
+
+    DefineCustomStringVariable(
+		"plantuner.enable_index",
+		"List of enabled indexes (overload plantuner.disable_index)",
+		"Listed indexes which could be used in queries even they are listed in plantuner.disable_index",
+		&enableIndexesOutStr,
+		"",
+		PGC_USERSET,
+		0,
+#if PG_VERSION_NUM >= 90100
+		checkEnabledIndexes,
+		assignEnabledIndexesNew,
+#else
+		assignEnabledIndexes,
+#endif
+		enabledIndexFilterShow
+	);
+
+    DefineCustomBoolVariable(
+		"plantuner.fix_empty_table",
+		"Sets to zero estimations for empty tables",
+		"Sets to zero estimations for empty or newly created tables",
+		&fix_empty_table,
+#if PG_VERSION_NUM >= 80400
+		fix_empty_table,
+#endif
+		PGC_USERSET,
+#if PG_VERSION_NUM >= 80400
+		GUC_NOT_IN_SAMPLE,
+#if PG_VERSION_NUM >= 90100
+		NULL,
+#endif
+#endif
+		NULL,
+		NULL
+	);
+
+	if (get_relation_info_hook != execPlantuner )
+	{
+		prevHook = get_relation_info_hook;
+		get_relation_info_hook = execPlantuner;
+	}
+}
diff -ruN a/contrib/plantuner/README.plantuner b/contrib/plantuner/README.plantuner
--- a/contrib/plantuner/README.plantuner	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/plantuner/README.plantuner	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,96 @@
+Plantuner - enable planner hints
+
+   contrib/plantuner is a contribution module for PostgreSQL 8.4+, which
+   enable planner hints.
+
+   All work was done by Teodor Sigaev (teodor@sigaev.ru) and Oleg Bartunov
+   (oleg@sai.msu.su).
+
+   Sponsor: Nomao project (http://www.nomao.com)
+
+Motivation
+
+   Whether somebody think it's bad or not, but sometime it's very
+   interesting to be able to control planner (provide hints, which tells
+   optimizer to ignore its algorithm in part), which is currently
+   impossible in POstgreSQL. Oracle, for example, has over 120 hints, SQL
+   Server also provides hints.
+
+   This first version of plantuner provides a possibility to hide
+   specified indexes from PostgreSQL planner, so it will not use them.
+
+   There are many situation, when developer want to temporarily disable
+   specific index(es), without dropping them, or to instruct planner to
+   use specific index.
+
+   Next, for some workload PostgreSQL could be too pessimistic for
+   newly created tables and assumes much more rows in table than
+   it actually has. If plantuner.fix_empty_table GUC variable is set
+   to true then module will set to zero number of pages/tuples of
+   table which hasn't blocks in file.
+
+Installation
+
+     * Get latest source of plantuner from CVS Repository
+     * gmake && gmake install && gmake installcheck
+
+Syntax
+	plantuner.forbid_index (deprecated)
+	plantuner.disable_index
+		List of indexes invisible to planner
+	plantuner.enable_index
+		List of indexes visible to planner even they are hided
+		by plantuner.disable_index. 
+
+Usage
+
+   To enable the module you can either load shared library 'plantuner' in
+   psql session or specify 'shared_preload_libraries' option in
+   postgresql.conf.
+=# LOAD 'plantuner';
+=# create table test(id int);
+=# create index id_idx on test(id);
+=# create index id_idx2 on test(id);
+=# \d test
+     Table "public.test"
+ Column |  Type   | Modifiers
+--------+---------+-----------
+ id     | integer |
+Indexes:
+    "id_idx" btree (id)
+    "id_idx2" btree (id)
+=# explain select id from test where id=1;
+                              QUERY PLAN
+-----------------------------------------------------------------------
+ Bitmap Heap Scan on test  (cost=4.34..15.03 rows=12 width=4)
+   Recheck Cond: (id = 1)
+   ->  Bitmap Index Scan on id_idx2  (cost=0.00..4.34 rows=12 width=0)
+         Index Cond: (id = 1)
+(4 rows)
+=# set enable_seqscan=off;
+=# set plantuner.disable_index='id_idx2';
+=# explain select id from test where id=1;
+                              QUERY PLAN
+----------------------------------------------------------------------
+ Bitmap Heap Scan on test  (cost=4.34..15.03 rows=12 width=4)
+   Recheck Cond: (id = 1)
+   ->  Bitmap Index Scan on id_idx  (cost=0.00..4.34 rows=12 width=0)
+         Index Cond: (id = 1)
+(4 rows)
+=# set plantuner.disable_index='id_idx2,id_idx';
+=# explain select id from test where id=1;
+                               QUERY PLAN
+-------------------------------------------------------------------------
+ Seq Scan on test  (cost=10000000000.00..10000000040.00 rows=12 width=4)
+   Filter: (id = 1)
+(2 rows)
+=# set plantuner.enable_index='id_idx';
+=# explain select id from test where id=1;
+                              QUERY PLAN
+-----------------------------------------------------------------------
+ Bitmap Heap Scan on test  (cost=4.34..15.03 rows=12 width=4)
+   Recheck Cond: (id = 1)
+   ->  Bitmap Index Scan on id_idx  (cost=0.00..4.34 rows=12 width=0)
+         Index Cond: (id = 1)
+(4 rows)
+
diff -ruN a/contrib/plantuner/sql/plantuner.sql b/contrib/plantuner/sql/plantuner.sql
--- a/contrib/plantuner/sql/plantuner.sql	1970-01-01 03:00:00.000000000 +0300
+++ b/contrib/plantuner/sql/plantuner.sql	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,27 @@
+LOAD 'plantuner';
+
+SHOW	plantuner.disable_index;
+
+CREATE TABLE wow (i int, j int);
+CREATE INDEX i_idx ON wow (i);
+CREATE INDEX j_idx ON wow (j);
+
+SET enable_seqscan=off;
+
+SELECT * FROM wow;
+
+SET plantuner.disable_index="i_idx, j_idx";
+
+SELECT * FROM wow;
+
+SHOW plantuner.disable_index;
+
+SET plantuner.disable_index="i_idx, nonexistent, public.j_idx, wow";
+
+SHOW plantuner.disable_index;
+
+SET plantuner.enable_index="i_idx";
+
+SHOW plantuner.enable_index;
+
+SELECT * FROM wow;
diff -ruN a/doc/src/sgml/config-one-c.sgml b/doc/src/sgml/config-one-c.sgml
--- a/doc/src/sgml/config-one-c.sgml	1970-01-01 03:00:00.000000000 +0300
+++ b/doc/src/sgml/config-one-c.sgml	2017-12-28 14:58:03.467305206 +0300
@@ -0,0 +1,108 @@
+<!-- doc/src/sgml/config-one-c.sgml -->
+
+<appendix id="config-one-c">
+  <title>Configuring <productname>PostgreSQL</productname> for <productname>1C</productname> Solutions</title>
+   <para>You can install and use <productname>PostgreSQL</productname> with <productname>1C</productname> solutions in a client/server model. For optimal performance and stability, modify the following settings in the <filename>postgresql.conf</filename> configuration file of <productname>PostgreSQL</productname> server:</para>
+
+   <orderedlist>
+     <listitem>
+      <para>Increase the maximum number of allowed concurrent connections to the database server, up to 1000 connections. <productname>1C</productname> solutions can open a large number of connections, even if not all of them are used, so it is recommended to allow not less than 500 connections.
+      <programlisting>
+max_connections = 1000
+</programlisting>
+      </para>
+     </listitem>
+
+    <listitem>
+      <para>To ensure that temporary tables are handled correctly, modify the following parameters:
+      </para>
+      <itemizedlist>
+       <listitem>
+        <para>Increase the buffer size for temporary tables: 
+        <programlisting>
+temp_buffers = 32MB
+</programlisting>
+        </para>
+       </listitem>
+
+       <listitem>
+        <para>Increase the number of allowed locks of tables or indexes per transaction to 256: </para>
+        <programlisting>
+max_locks_per_transaction = 256
+</programlisting>
+        <para>Typically, <productname>1C</productname> solutions use a lot of temporary tables. Every backend process usually contains multiple temporary tables. When closing a connection, <productname>PostgreSQL</productname> tries to drop all temporary tables in a single transaction, so this transaction may use a lot of locks. If the number of locks exceeds the <varname>max_locks_per_transaction</varname> value, the transaction will fail, leaving multiple orphaned temporary tables.
+        </para>
+      </listitem>
+      </itemizedlist>
+    </listitem>
+
+    <listitem>
+     <para>Enable backslash escapes in all strings, and switch off the warning about using the backslash escape symbol: 
+     <programlisting>
+standard_conforming_strings = off
+escape_string_warning = off
+</programlisting>
+      </para>
+    </listitem>
+
+    <listitem>
+      <para>
+        Set the <varname>effective_cache_size</varname> parameter to at least half of <acronym>RAM</acronym>
+        available on the system. <productname>PostgreSQL</productname> query optimizer performance
+        depends on the amount of allocated <acronym>RAM</acronym>.
+      </para>
+    </listitem>
+
+    <listitem>
+     <para>Optimize query planning using <link linkend="online-analyze"><filename>online_analyze</filename></link> and <link linkend="plantuner"><filename>plantuner</filename></link> extensions, as follows:
+     </para>
+
+        <itemizedlist>
+          <listitem>
+            <para>Add <filename>online_analyze</filename> and <filename>plantuner</filename> to the <varname>shared_preload_libraries</varname> variable.
+            </para>
+                 <programlisting>
+shared_preload_libraries = 'online_analyze, plantuner'
+</programlisting>
+          </listitem>
+
+          <listitem>
+            <para>Enable automatic analysis of temporary tables when they are modified:
+            </para>
+                 <programlisting>
+online_analyze.table_type = 'temporary'
+</programlisting>
+          </listitem>
+
+          <listitem>
+            <para>Tune <productname>PostgreSQL</productname> optimizer to improve planning for recently created empty tables:
+            </para>
+                 <programlisting>
+plantuner.fix_empty_table = 'on'
+</programlisting>
+          </listitem>
+
+          <listitem>
+            <para>Suppress detailed messages from the <filename>online_analyze</filename> extension:
+            </para>
+                 <programlisting>
+online_analyze.verbose = 'off'
+</programlisting>
+          </listitem>
+
+        </itemizedlist>
+    </listitem>
+
+   </orderedlist>
+
+   <tip>
+    <para>
+      To improve performance, you can also use redundant array of independent disks (<acronym>RAID</acronym>) technology
+      based on non-volatile cache <acronym>RAID</acronym> controllers with uninterruptible power supply (<acronym>UPS</acronym>).
+      Since this technology ensures data consistency in case of hardware failure, you can speed up disk writes by
+      disabling the <varname>fsync</varname> parameter. Additionally, increasing the <acronym>RAID</acronym> controller cache
+      volume and the number of disks in the <acronym>RAID</acronym> array can improve performance even with
+      enabled <varname>fsync</varname>.
+    </para>
+   </tip>
+ </appendix>
diff -ruN a/doc/src/sgml/contrib.sgml b/doc/src/sgml/contrib.sgml
--- a/doc/src/sgml/contrib.sgml	2017-12-28 14:57:41.975567500 +0300
+++ b/doc/src/sgml/contrib.sgml	2017-12-28 14:58:03.467305206 +0300
@@ -116,7 +116,9 @@
  &dict-int;
  &dict-xsyn;
  &earthdistance;
+ &fasttrun;
  &file-fdw;
+ &fulleq;
  &fuzzystrmatch;
  &hstore;
  &intagg;
@@ -124,6 +126,8 @@
  &isn;
  &lo;
  &ltree;
+ &mchar;
+ &online-analyze;
  &pageinspect;
  &passwordcheck;
  &pgbuffercache;
@@ -135,6 +139,7 @@
  &pgstattuple;
  &pgtrgm;
  &pgvisibility;
+ &plantuner;
  &postgres-fdw;
  &seg;
  &sepgsql;
diff -ruN a/doc/src/sgml/fasttrun.sgml b/doc/src/sgml/fasttrun.sgml
--- a/doc/src/sgml/fasttrun.sgml	1970-01-01 03:00:00.000000000 +0300
+++ b/doc/src/sgml/fasttrun.sgml	2017-12-28 14:58:03.491304913 +0300
@@ -0,0 +1,49 @@
+<sect1 id="fasttrun">
+  <title>fasttrun</title>
+  <para>
+    The <literal>fasttrun</literal> module provides transaction unsafe
+    function to truncate temporary tables without growing pg_class size.
+  </para>
+  <para>
+  This module is required for 1C Enterprise support.
+  </para>
+  <para>
+  Fast truncate operation is not transactional, so its results cannot be
+  rolled back and become immediately visible in all sessions regardless
+  of isolation level.
+  </para>
+  <sect2 id="fasttrun-function">
+    <title>Function</title>
+    <para>
+      There is a function call example:
+      <programlisting>
+        select fasttruncate('TABLE_NAME');
+      </programlisting>
+    </para>
+  </sect2>
+
+  <sect2 id="fasttrun-test">
+    <title>Test example</title>
+    <para>
+      For tests you can use this example:
+      <programlisting>
+create or replace function f() returns void as $$
+begin
+  for i in 1..1000
+    loop
+      PERFORM fasttruncate('tt1');
+    end loop;
+  end;
+$$ language plpgsql;
+      </programlisting>
+    </para>
+  </sect2>
+
+  <sect2 id="fasttrun-authors">
+    <title>Authors</title>
+    <literallayout>
+      Teodor Sigaev <email>teodor@sigaev.ru</email>
+    </literallayout>
+  </sect2>
+
+</sect1>
diff -ruN a/doc/src/sgml/filelist.sgml b/doc/src/sgml/filelist.sgml
--- a/doc/src/sgml/filelist.sgml	2017-12-28 14:57:41.939567939 +0300
+++ b/doc/src/sgml/filelist.sgml	2017-12-28 14:58:03.491304913 +0300
@@ -118,7 +118,9 @@
 <!ENTITY dict-xsyn       SYSTEM "dict-xsyn.sgml">
 <!ENTITY dummy-seclabel  SYSTEM "dummy-seclabel.sgml">
 <!ENTITY earthdistance   SYSTEM "earthdistance.sgml">
+<!ENTITY fasttrun        SYSTEM "fasttrun.sgml">
 <!ENTITY file-fdw        SYSTEM "file-fdw.sgml">
+<!ENTITY fulleq          SYSTEM "fulleq.sgml">
 <!ENTITY fuzzystrmatch   SYSTEM "fuzzystrmatch.sgml">
 <!ENTITY hstore          SYSTEM "hstore.sgml">
 <!ENTITY intagg          SYSTEM "intagg.sgml">
@@ -126,7 +128,9 @@
 <!ENTITY isn             SYSTEM "isn.sgml">
 <!ENTITY lo              SYSTEM "lo.sgml">
 <!ENTITY ltree           SYSTEM "ltree.sgml">
+<!ENTITY mchar           SYSTEM "mchar.sgml">
 <!ENTITY oid2name        SYSTEM "oid2name.sgml">
+<!ENTITY online-analyze  SYSTEM "online-analyze.sgml">
 <!ENTITY pageinspect     SYSTEM "pageinspect.sgml">
 <!ENTITY passwordcheck   SYSTEM "passwordcheck.sgml">
 <!ENTITY pgbuffercache   SYSTEM "pgbuffercache.sgml">
@@ -139,6 +143,7 @@
 <!ENTITY pgstattuple     SYSTEM "pgstattuple.sgml">
 <!ENTITY pgtrgm          SYSTEM "pgtrgm.sgml">
 <!ENTITY pgvisibility    SYSTEM "pgvisibility.sgml">
+<!ENTITY plantuner       SYSTEM "plantuner.sgml">
 <!ENTITY postgres-fdw    SYSTEM "postgres-fdw.sgml">
 <!ENTITY seg             SYSTEM "seg.sgml">
 <!ENTITY contrib-spi     SYSTEM "contrib-spi.sgml">
@@ -163,6 +168,7 @@
 <!ENTITY errcodes   SYSTEM "errcodes.sgml">
 <!ENTITY features   SYSTEM "features.sgml">
 <!ENTITY keywords   SYSTEM "keywords.sgml">
+<!ENTITY config-one-c   SYSTEM "config-one-c.sgml">
 <!ENTITY sourcerepo SYSTEM "sourcerepo.sgml">
 
 <!ENTITY release    SYSTEM "release.sgml">
diff -ruN a/doc/src/sgml/fulleq.sgml b/doc/src/sgml/fulleq.sgml
--- a/doc/src/sgml/fulleq.sgml	1970-01-01 03:00:00.000000000 +0300
+++ b/doc/src/sgml/fulleq.sgml	2017-12-28 14:58:03.491304913 +0300
@@ -0,0 +1,65 @@
+<sect1 id="fulleq">
+  <title>fulleq</title>
+  <para>
+    The <literal>fulleq</literal> module provides additional equivalence
+    operator for compatibility with Microsoft SQL Server.
+  </para>
+   <para>
+   This module is required for 1C Enterprise support.
+   </para>
+   <sect2 id="fulleq-overview">
+    <title>Overview</title>
+    <para>
+      The <productname>PostgreSQL</productname> equivalence operator is
+      defined to return NULL when both operands are NULLs. However, the Microsoft
+      SQL Servers family traditionally defines other semantic for equivalence
+      operator, where operator returns TRUE in the case of both nulled operands.
+      This module provides such operator with MSSQL semantic.
+    </para>
+  </sect2>
+
+  <sect2 id="fulleq-operator">
+    <title>Operator fulleq</title>
+    <para>
+      The <literal>==</literal> operator is defined for the following data
+      types:
+      <itemizedlist>
+        <listitem><para>bool</para></listitem>
+        <listitem><para>bytea</para></listitem>
+        <listitem><para>char</para></listitem>
+        <listitem><para>name</para></listitem>
+        <listitem><para>int2</para></listitem>
+        <listitem><para>int4</para></listitem>
+        <listitem><para>int8</para></listitem>
+        <listitem><para>int2vector</para></listitem>
+        <listitem><para>text</para></listitem>
+        <listitem><para>oid</para></listitem>
+        <listitem><para>xid</para></listitem>
+        <listitem><para>cid</para></listitem>
+        <listitem><para>oidvector</para></listitem>
+        <listitem><para>float4</para></listitem>
+        <listitem><para>float8</para></listitem>
+        <listitem><para>abstime</para></listitem>
+        <listitem><para>reltime</para></listitem>
+        <listitem><para>macaddr</para></listitem>
+        <listitem><para>inet</para></listitem>
+        <listitem><para>cidr</para></listitem>
+        <listitem><para>varchar</para></listitem>
+        <listitem><para>date</para></listitem>
+        <listitem><para>time</para></listitem>
+        <listitem><para>timestamp</para></listitem>
+        <listitem><para>timestamptz</para></listitem>
+        <listitem><para>interval</para></listitem>
+        <listitem><para>timetz</para></listitem>
+      </itemizedlist>
+    </para>
+  </sect2>
+
+  <sect2 id="fulleq-authors">
+    <title>Authors</title>
+    <literallayout>
+      Teodor Sigaev <email>teodor@sigaev.ru</email>
+    </literallayout>
+  </sect2>
+
+</sect1>
diff -ruN a/doc/src/sgml/mchar.sgml b/doc/src/sgml/mchar.sgml
--- a/doc/src/sgml/mchar.sgml	1970-01-01 03:00:00.000000000 +0300
+++ b/doc/src/sgml/mchar.sgml	2017-12-28 14:58:03.491304913 +0300
@@ -0,0 +1,107 @@
+<sect1 id="mchar">
+  <title>mchar</title>
+  <para>
+    The <literal>mchar</literal> module provides additional data types
+    for compatibility with Microsoft SQL Server (MSSQL).
+  </para>
+
+  <sect2 id="mchar-overview">
+    <title>Overview</title>
+    <para>
+      This module has been designed to improve <application>1C Enterprise</application>
+      support, most popular Russian CRM and ERP system.
+    </para>
+    <para>
+    It implements types MCHAR and MVARCHAR, which are bug-to-bug
+    compatible with MSSQL CHAR and VARCHAR respectively. Additionally, 
+    these types use libicu for comparison and case conversion, so their
+    behavior is identical across different operating systems.
+    </para>
+    <para>
+    <productname>PostgreSQL</productname> also includes <xref linkend="citext"> extension which
+    provides types similar to MCHAR. But this extension doesn't emulate
+    MS-SQL behavior concerning end-of-value whitespace.
+    </para>
+    <para>
+    Differences from <productname>PostgreSQL</productname> standard CHAR and VARCHAR are:
+    </para>
+    <itemizedlist>
+    <listitem>
+    <para>
+    Case insensitive comparison
+    </para>
+    </listitem>
+    <listitem>
+    <para>
+    Handling of the whitespace at the end of string
+    </para>
+    </listitem>
+    <listitem>
+    <para>
+    These types are always stored as two-byte unicode value regardless
+    of database encoding.
+    </para>
+    </listitem>
+    </itemizedlist>
+  </sect2>
+
+  <sect2 id="mchar-types">
+    <title>Additional types</title>
+    <itemizedlist>
+      <listitem>
+        <para><type>mchar</type> &mdash; analog of the MSSQL char type</para>
+      </listitem>
+      <listitem>
+        <para><type>mvarchar</type> &mdash; analog of the MSSQL varchar type</para>
+      </listitem>
+    </itemizedlist>
+  </sect2>
+
+  <sect2 id="mchar-features">
+    <title>MCHAR and MVARCHAR features</title>
+    <itemizedlist>
+      <listitem>
+        <para>Defines <function>length(str)</function> function</para>
+      </listitem>
+      <listitem>
+        <para>Defines <function>substr(str, pos[, length])</function> function</para>
+      </listitem>
+      <listitem>
+        <para>Defines <literal>||</literal> operator, which would be applied to concatenate any (mchar and mvarchar) arguments</para>
+      </listitem>
+      <listitem>
+        <para>Defines set of operators: <literal>&lt;</>, <literal>&lt;=</> <literal>=</>, <literal>&gt;=</>, <literal>&gt;</> for case-insensitive comparison (LibICU)</para>
+      </listitem>
+      <listitem>
+        <para>Defines set of operators: <literal>&amp;&lt;</>, <literal>&amp;&lt;=</>, <literal>&amp;=</>, <literal>&amp;&gt;=</>, <literal>&amp;&gt;</> to case-sensitive comparison (LibICU)</para>
+      </listitem>
+      <listitem>
+        <para>Implicit cast between <type>mchar</type> and <type>mvarchar</type> types</para>
+      </listitem>
+      <listitem>
+        <para>B-tree and Hash-index support</para>
+      </listitem>
+      <listitem>
+        <para>The <literal>LIKE [ESCAPE]</literal> operator support</para>
+      </listitem>
+      <listitem>
+        <para>The <literal>SIMILAR TO [ESCAPE]</literal> operator support</para>
+      </listitem>
+      <listitem>
+        <para>The <emphasis>~</emphasis> operator (POSIX regexp) support</para>
+      </listitem>
+      <listitem>
+        <para>Index support for the <emphasis>LIKE</emphasis> operator</para>
+      </listitem>
+    </itemizedlist>
+  </sect2>
+
+  <sect2 id="mchar-authors">
+    <title>Authors</title>
+    <literallayout>
+      Oleg Bartunov <email>oleg@sai.msu.ru</email>
+      Teodor Sigaev <email>teodor@sigaev.ru</email>
+    </literallayout>
+  </sect2>
+
+</sect1>
diff -ruN a/doc/src/sgml/online-analyze.sgml b/doc/src/sgml/online-analyze.sgml
--- a/doc/src/sgml/online-analyze.sgml	1970-01-01 03:00:00.000000000 +0300
+++ b/doc/src/sgml/online-analyze.sgml	2017-12-28 14:58:03.491304913 +0300
@@ -0,0 +1,104 @@
+<sect1 id="online-analyze">
+  <title>online-analyze</title>
+  <para>
+    The <filename>online_analyze</filename> module provides a set of
+    features that immediately update statistics after <command>INSERT</command>,
+    <command>UPDATE</command>, <command>DELETE</command>, or <command>SELECT INTO</command>
+    operations for the affected tables.
+  </para>
+
+  <sect2 id="online-analyze-loading">
+    <title>Module Loading</title>
+    <para>
+      To use <filename>online_analyze</filename> module, load the shared library:
+
+      <programlisting>
+LOAD 'online_analyze';
+</programlisting>
+    </para>
+  </sect2>
+
+  <sect2 id="online-analyze-configuration">
+    <title>Module Configuration</title>
+
+    <para>
+      You can configure <filename>online_analyze</filename> using
+      the following custom variables (default values are shown):
+
+      <itemizedlist>
+        <listitem>
+          <para>online_analyze.enable = on</para>
+          <para>Enables <filename>online_analyze</filename>.</para>
+        </listitem>
+        <listitem>
+          <para>online_analyze.verbose = on</para>
+          <para>Executes <command>ANALYZE VERBOSE</command>.</para>
+        </listitem>
+        <listitem>
+          <para>online_analyze.scale_factor = 0.1</para>
+          <para>Fraction of table size to start online analysis
+          (similar to <xref linkend="guc-autovacuum-analyze-scale-factor">).</para>
+        </listitem>
+
+        <listitem>
+          <para>online_analyze.threshold = 50</para>
+          <para>Minimum number of row updates before starting online analysis
+          (similar to <xref linkend="guc-autovacuum-analyze-threshold">).</para>
+        </listitem>
+
+        <listitem>
+          <para>online_analyze.min_interval = 10000</para>
+          <para>Minimum time interval between <command>ANALYZE</command>
+          calls per table, in milliseconds.</para>
+        </listitem>
+
+        <listitem>
+          <para>online_analyze.table_type = "all"</para>
+          <para>Type(s) of tables for online analysis. Possible values are:
+          <literal>all</literal>, <literal>persistent</literal>,
+          <literal>temporary</literal>, <literal>none</literal>.</para>
+        </listitem>
+
+        <listitem>
+          <para>online_analyze.exclude_tables = ""</para>
+          <para>List of tables to exclude from online analysis.</para>
+        </listitem>
+
+        <listitem>
+          <para>online_analyze.include_tables = ""</para>
+          <para>List of tables to include in online analysis
+          (<varname>online_analyze.include_tables</varname> overrides
+          <varname>online_analyze.exclude_tables</varname>).</para>
+        </listitem>
+
+        <listitem>
+          <para>online_analyze.local_tracking = off</para>
+          <para>Enables per-backend tracking for temporary tables by
+          <filename>online_analyze</filename>. When this variable is set
+          to <literal>off</literal>, <filename>online_analyze</filename>
+          uses the default system statistics for temporary tables.</para>
+        </listitem>
+
+        <listitem>
+          <para>online_analyze.lower_limit = 0</para>
+          <para>Minimum number of rows in a table required to trigger
+          <filename>online_analyze</filename>.</para>
+        </listitem>
+
+        <listitem>
+          <para>online_analyze.capacity_threshold = 100000</para>
+          <para>Maximum number of temporary tables to store
+          in local cache.</para>
+        </listitem>
+      </itemizedlist>
+    </para>
+  </sect2>
+
+  <sect2 id="online-analyze-authors">
+    <title>Authors</title>
+    <literallayout>
+      Teodor Sigaev <email>teodor@sigaev.ru</email>
+    </literallayout>
+  </sect2>
+
+</sect1>
diff -ruN a/doc/src/sgml/plantuner.sgml b/doc/src/sgml/plantuner.sgml
--- a/doc/src/sgml/plantuner.sgml	1970-01-01 03:00:00.000000000 +0300
+++ b/doc/src/sgml/plantuner.sgml	2017-12-28 14:58:03.491304913 +0300
@@ -0,0 +1,106 @@
+<sect1 id="plantuner">
+  <title>plantuner</title>
+  <para>
+    The <literal>plantuner</literal> module provides hits for planner,
+    which can disable or enable indexes for query execution.
+  </para>
+
+  <sect2 id="plantuner-motivation">
+    <title>Motivation</title>
+    <para>
+      Whether somebody think it's bad or not, but sometime it's very
+      interesting to be able to control planner (provide hints, which tell
+      optimizer to ignore its algorithm in part), which is currently
+      impossible in <productname>PostgreSQL</productname>.
+      Oracle, for example, has over 120 hints,
+      and Microsoft SQL Server also supports hints.
+    </para>
+    <para>
+      This first version of plantuner provides a possibility to hide
+      specified indexes from <productname>PostgreSQL</productname> planner, so it will not use them.
+    </para>
+    <para>
+      There are many situations when developer want to temporarily disable
+      specific index(es), without dropping them, or to instruct planner to
+      use specific index.
+    </para>
+    <para>
+      Next, for some workload <productname>PostgreSQL</productname> could be too pessimistic for
+      newly created tables and assumes much more rows in table than
+      it actually has. If plantuner.fix_empty_table GUC variable is set
+      to true then module will set to zero the number of pages/tuples of
+      table which hasn't blocks in a file.
+    </para>
+  </sect2>
+
+  <sect2 id="plantuner-syntax">
+    <title>Syntax</title>
+    <para>plantuner.disable_index &mdash; List of indexes invisible to planner</para>
+    <para>plantuner.enable_index &mdash; List of indexes visible to planner even they are hidden by plantuner.disable_index.</para>
+  </sect2>
+
+  <sect2 id="plantuner-usage-example">
+    <title>Example</title>
+    <para>
+      To enable the module you can either load shared library 'plantuner' in
+      psql session or specify 'shared_preload_libraries' option in
+      postgresql.conf.
+      <programlisting>
+=# LOAD 'plantuner';
+=# create table test(id int);
+=# create index id_idx on test(id);
+=# create index id_idx2 on test(id);
+=# \d test
+     Table "public.test"
+ Column |  Type   | Modifiers
+--------+---------+-----------
+ id     | integer |
+Indexes:
+    "id_idx" btree (id)
+    "id_idx2" btree (id)
+=# explain select id from test where id=1;
+                              QUERY PLAN
+-----------------------------------------------------------------------
+ Bitmap Heap Scan on test  (cost=4.34..15.03 rows=12 width=4)
+   Recheck Cond: (id = 1)
+   ->  Bitmap Index Scan on id_idx2  (cost=0.00..4.34 rows=12 width=0)
+         Index Cond: (id = 1)
+(4 rows)
+=# set enable_seqscan=off;
+=# set plantuner.disable_index='id_idx2';
+=# explain select id from test where id=1;
+                              QUERY PLAN
+----------------------------------------------------------------------
+ Bitmap Heap Scan on test  (cost=4.34..15.03 rows=12 width=4)
+   Recheck Cond: (id = 1)
+   ->  Bitmap Index Scan on id_idx  (cost=0.00..4.34 rows=12 width=0)
+         Index Cond: (id = 1)
+(4 rows)
+=# set plantuner.disable_index='id_idx2,id_idx';
+=# explain select id from test where id=1;
+                               QUERY PLAN
+-------------------------------------------------------------------------
+ Seq Scan on test  (cost=10000000000.00..10000000040.00 rows=12 width=4)
+   Filter: (id = 1)
+(2 rows)
+=# set plantuner.enable_index='id_idx';
+=# explain select id from test where id=1;
+                              QUERY PLAN
+-----------------------------------------------------------------------
+ Bitmap Heap Scan on test  (cost=4.34..15.03 rows=12 width=4)
+   Recheck Cond: (id = 1)
+   ->  Bitmap Index Scan on id_idx  (cost=0.00..4.34 rows=12 width=0)
+         Index Cond: (id = 1)
+(4 rows)
+      </programlisting>
+    </para>
+  </sect2>
+
+  <sect2 id="plantuner-authors">
+    <title>Authors</title>
+    <para>All work was done by Teodor Sigaev (teodor@sigaev.ru) and Oleg Bartunov (oleg@sai.msu.su).</para>
+    <para>The work sponsored by Nomao project (http://www.nomao.com).</para>
+  </sect2>
+
+</sect1>
+
diff -ruN a/doc/src/sgml/postgres.sgml b/doc/src/sgml/postgres.sgml
--- a/doc/src/sgml/postgres.sgml	2017-12-28 14:57:41.971567549 +0300
+++ b/doc/src/sgml/postgres.sgml	2017-12-28 14:58:03.491304913 +0300
@@ -270,6 +270,7 @@
   &release;
   &contrib;
   &external-projects;
+  &config-one-c;
   &sourcerepo;
   &docguide;
   &acronyms;
diff -ruN a/src/backend/commands/collationcmds.c b/src/backend/commands/collationcmds.c
--- a/src/backend/commands/collationcmds.c	2017-12-28 14:57:41.907568330 +0300
+++ b/src/backend/commands/collationcmds.c	2017-12-28 14:58:03.491304913 +0300
@@ -446,11 +446,13 @@
 
 	status = U_ZERO_ERROR;
 	uloc_toLanguageTag(localename, buf, sizeof(buf), TRUE, &status);
-	if (U_FAILURE(status))
-		ereport(ERROR,
+	if (U_FAILURE(status)) 
+	{
+		ereport(WARNING,
 				(errmsg("could not convert locale name \"%s\" to language tag: %s",
 						localename, u_errorName(status))));
-
+		return NULL;
+	}
 	return pstrdup(buf);
 }
 
diff -ruN a/src/backend/nodes/outfuncs.c b/src/backend/nodes/outfuncs.c
--- a/src/backend/nodes/outfuncs.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/nodes/outfuncs.c	2017-12-28 14:58:03.491304913 +0300
@@ -1857,6 +1857,7 @@
 
 	WRITE_NODE_FIELD(partitioned_rels);
 	WRITE_NODE_FIELD(subpaths);
+	WRITE_BOOL_FIELD(pull_tlist);
 }
 
 static void
diff -ruN a/src/backend/optimizer/path/allpaths.c b/src/backend/optimizer/path/allpaths.c
--- a/src/backend/optimizer/path/allpaths.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/path/allpaths.c	2017-12-28 14:58:03.491304913 +0300
@@ -705,6 +705,9 @@
 	/* Consider index scans */
 	create_index_paths(root, rel);
 
+	/* Consider index scans with rewrited quals */
+	keybased_rewrite_index_paths(root, rel);
+
 	/* Consider TID scans */
 	create_tidscan_paths(root, rel);
 }
@@ -1430,7 +1433,8 @@
 	 */
 	if (subpaths_valid)
 		add_path(rel, (Path *) create_append_path(rel, subpaths, NULL, 0,
-												  partitioned_rels));
+												  partitioned_rels,
+												  false, NIL));
 
 	/*
 	 * Consider an append of partial unordered, unparameterized partial paths.
@@ -1457,7 +1461,8 @@
 
 		/* Generate a partial append path. */
 		appendpath = create_append_path(rel, partial_subpaths, NULL,
-										parallel_workers, partitioned_rels);
+										parallel_workers, partitioned_rels,
+										false, NIL);
 		add_partial_path(rel, (Path *) appendpath);
 	}
 
@@ -1511,7 +1516,8 @@
 		if (subpaths_valid)
 			add_path(rel, (Path *)
 					 create_append_path(rel, subpaths, required_outer, 0,
-										partitioned_rels));
+										partitioned_rels,
+										false, NIL));
 	}
 }
 
@@ -1747,7 +1753,8 @@
 	rel->pathlist = NIL;
 	rel->partial_pathlist = NIL;
 
-	add_path(rel, (Path *) create_append_path(rel, NIL, NULL, 0, NIL));
+	add_path(rel, (Path *) create_append_path(rel, NIL, NULL, 0, NIL,
+											  false, NIL));
 
 	/*
 	 * We set the cheapest path immediately, to ensure that IS_DUMMY_REL()
diff -ruN a/src/backend/optimizer/path/appendorpath.c b/src/backend/optimizer/path/appendorpath.c
--- a/src/backend/optimizer/path/appendorpath.c	1970-01-01 03:00:00.000000000 +0300
+++ b/src/backend/optimizer/path/appendorpath.c	2017-12-28 14:58:03.491304913 +0300
@@ -0,0 +1,968 @@
+/*
+ * support Append plan for ORed clauses
+ * Teodor Sigaev <teodor@sigaev.ru>
+ */
+#include "postgres.h"
+
+#include "access/skey.h"
+#include "catalog/pg_am.h"
+#include "optimizer/cost.h"
+#include "optimizer/clauses.h"
+#include "optimizer/paths.h"
+#include "optimizer/pathnode.h"
+#include "optimizer/planmain.h"
+#include "optimizer/predtest.h"
+#include "optimizer/restrictinfo.h"
+#include "utils/lsyscache.h"
+
+typedef struct CKey {
+	RestrictInfo	*rinfo;		/* original rinfo */
+	int				n;			/* IndexPath's number in bitmapquals */
+	OpExpr			*normalizedexpr; /* expression with Var on left */
+	Var				*var;
+	Node			*value;
+	Oid				opfamily;
+	int				strategy;
+	uint8			strategyMask;
+} CKey;
+#define	BTMASK(x)	( 1<<(x) )
+
+static	List* find_common_quals( BitmapOrPath *path );
+static	RestrictInfo* unionOperation(CKey	*key);
+static	BitmapOrPath* cleanup_nested_quals( PlannerInfo *root, RelOptInfo *rel, BitmapOrPath *path );
+static  List* sortIndexScans( List* ipaths );
+static	List* reverseScanDirIdxPaths(List *indexPaths);
+static	IndexPath* reverseScanDirIdxPath(IndexPath *ipath);
+
+#define IS_LESS(a)	( (a) == BTLessStrategyNumber || (a)== BTLessEqualStrategyNumber )
+#define IS_GREATER(a)	( (a) == BTGreaterStrategyNumber || (a) == BTGreaterEqualStrategyNumber )
+#define	IS_ONE_DIRECTION(a,b)	(		\
+	( IS_LESS(a) && IS_LESS(b) )		\
+	||									\
+	( IS_GREATER(a) && IS_GREATER(b) )	\
+)
+
+typedef struct ExExpr {
+	OpExpr		*expr;
+	Oid			opfamily;
+	Oid			lefttype;
+	Oid			righttype;
+	int			strategy;
+	int			attno;
+} ExExpr;
+
+
+typedef struct IndexPathEx {
+	IndexPath	*path;
+	List		*preparedquals; /* list of ExExpr */
+} IndexPathEx;
+
+
+/*----------
+ * keybased_rewrite_or_index_quals
+ *	  Examine join OR-of-AND quals to see if any useful common restriction
+ *	  clauses can be extracted.  If so, try to use for creating new index paths.
+ *
+ * For example consider
+ *		WHERE ( a.x=5 and a.y>10 ) OR a.x>5
+ *	and there is an index on a.x or (a.x, a.y). So, plan
+ *	will be seqscan or BitmapOr(IndexPath,IndexPath)
+ *  So, we can add some restriction:
+ *		WHERE (( a.x=5 and a.y>10 ) OR a.x>5) AND a.x>=5
+ *	and plan may be so
+ *		Index Scan (a.x>=5)
+ *		Filter( (( a.x=5 and a.y>10 ) OR a.x>5) )
+ *
+ * We don't want to add new clauses to baserestrictinfo, just
+ * use it as index quals.
+ *
+ * Next thing which it possible to test is use append of
+ * searches instead of OR.
+ * For example consider
+ *	WHERE ( a.x=5 and a.y>10 ) OR a.x>6
+ * and there is an index on (a.x) (a.x, a.y)
+ * So, we can suggest follow plan:
+ *	Append
+ *	Filter ( a.x=5 and a.y>10 ) OR (a.x>6)
+ *		Index Scan (a.x=5)	--in case of index on (a.x)
+ *		Index Scan (a.x>6)
+ * For that we should proof that index quals isn't overlapped,
+ * also, some index quals may be containedi in other, so it can be eliminated
+ */
+
+void
+keybased_rewrite_index_paths(PlannerInfo *root, RelOptInfo *rel)
+{
+	BitmapOrPath *bestpath = NULL;
+	ListCell   *i;
+	List		*commonquals;
+	AppendPath  *appendidxpath;
+	List		*indexPaths;
+	IndexOptInfo *index;
+
+	foreach(i, rel->baserestrictinfo)
+	{
+		RestrictInfo *rinfo = (RestrictInfo *) lfirst(i);
+
+		if (restriction_is_or_clause(rinfo) &&
+			!rinfo->outerjoin_delayed)
+		{
+			/*
+			 * Use the generate_bitmap_or_paths() machinery to estimate the
+			 * value of each OR clause.  We can use regular restriction
+			 * clauses along with the OR clause contents to generate
+			 * indexquals.	We pass outer_rel = NULL so that sub-clauses
+			 * that are actually joins will be ignored.
+			 */
+			List	   *orpaths;
+			ListCell   *k;
+
+			orpaths = generate_bitmap_or_paths(root, rel,
+											   list_make1(rinfo),
+											   rel->baserestrictinfo);
+
+			/* Locate the cheapest OR path */
+			foreach(k, orpaths)
+			{
+				BitmapOrPath *path = (BitmapOrPath *) lfirst(k);
+
+				Assert(IsA(path, BitmapOrPath));
+				if (bestpath == NULL ||
+					path->path.total_cost < bestpath->path.total_cost)
+				{
+					bestpath = path;
+				}
+			}
+		}
+	}
+
+	/* Fail if no suitable clauses found */
+	if (bestpath == NULL)
+		return;
+
+	commonquals = find_common_quals(bestpath);
+	/* Found quals with the same args, but with, may be, different
+		operations */
+	if ( commonquals != NULL ) {
+		List		*addon=NIL;
+
+		foreach(i, commonquals) {
+			CKey	*key = (CKey*)lfirst(i);
+			RestrictInfo	*rinfo;
+
+			/*
+			 * get 'union' of operation for key
+			 */
+			rinfo = unionOperation(key);
+			if ( rinfo )
+				addon = lappend(addon, rinfo);
+		}
+
+		/*
+		 * Ok, we found common quals and union it, so we will try to
+		 * create new possible index paths
+		 */
+		if ( addon ) {
+			List	*origbaserestrictinfo = list_copy(rel->baserestrictinfo);
+
+			rel->baserestrictinfo = list_concat(rel->baserestrictinfo, addon);
+
+			create_index_paths(root, rel);
+
+			rel->baserestrictinfo = origbaserestrictinfo;
+		}
+	}
+
+	/*
+	 * Check if indexquals isn't overlapped and all index scan
+	 * are on the same index.
+	 */
+	if ( (bestpath = cleanup_nested_quals( root, rel, bestpath )) == NULL )
+		return;
+
+	if (IsA(bestpath, IndexPath)) {
+		IndexPath	*ipath = (IndexPath*)bestpath;
+
+		Assert(list_length(ipath->indexquals) == list_length(ipath->indexqualcols));
+		/*
+		 * It's possible to do only one index scan :)
+		 */
+		index = ipath->indexinfo;
+
+		if ( root->query_pathkeys != NIL && index->sortopfamily && OidIsValid(index->sortopfamily[0]) )
+		{
+			List	*pathkeys;
+
+			pathkeys = build_index_pathkeys(root, index,
+													ForwardScanDirection);
+			pathkeys = truncate_useless_pathkeys(root, rel,
+													pathkeys);
+
+			ipath->path.pathkeys = pathkeys;
+			add_path(rel, (Path *) ipath);
+
+			/*
+			 * add path ordered in backward direction if our pathkeys
+			 * is still unusable...
+			 */
+			if ( pathkeys == NULL || pathkeys_useful_for_ordering(root, pathkeys) == 0 ) 
+			{
+				pathkeys = build_index_pathkeys(root, index,
+													BackwardScanDirection);
+				pathkeys = truncate_useless_pathkeys(root, rel,
+														pathkeys);
+
+				ipath = reverseScanDirIdxPath( ipath );
+
+				ipath->path.pathkeys = pathkeys;
+				add_path(rel, (Path *) ipath);
+			}
+		} else
+			add_path(rel, (Path *) ipath);
+		return;
+	}
+
+	/* recount costs */
+	foreach(i, bestpath->bitmapquals ) {
+		IndexPath	*ipath = (IndexPath*)lfirst(i);
+
+		Assert( IsA(ipath, IndexPath) );
+		Assert(list_length(ipath->indexquals) == list_length(ipath->indexqualcols));
+		ipath->path.rows = rel->tuples * clauselist_selectivity(root,
+															ipath->indexquals,
+															rel->relid,
+															JOIN_INNER,
+															NULL);
+		ipath->path.rows = clamp_row_est(ipath->path.rows);
+		cost_index(ipath, root, 1, false);
+	}
+
+	/*
+	 * Check if append index can suggest ordering of result
+	 *
+	 * Also, we should say to AppendPath about targetlist:
+	 * target list will be taked from indexscan
+	 */
+	index = ((IndexPath*)linitial(bestpath->bitmapquals))->indexinfo;
+	if ( root->query_pathkeys != NIL && index->sortopfamily && OidIsValid(index->sortopfamily[0]) && 
+				(indexPaths = sortIndexScans( bestpath->bitmapquals )) !=NULL ) {
+		List	*pathkeys;
+
+		pathkeys = build_index_pathkeys(root, index,
+										ForwardScanDirection);
+		pathkeys = truncate_useless_pathkeys(root, rel,
+											 pathkeys);
+
+		appendidxpath = create_append_path(rel, indexPaths, NULL, 0, NIL,
+										   true, pathkeys);
+		add_path(rel, (Path *) appendidxpath);
+
+		/*
+		 * add path ordered in backward direction if our pathkeys
+		 * is still unusable...
+		 */
+		if ( pathkeys == NULL || pathkeys_useful_for_ordering(root, pathkeys) == 0 ) {
+
+			pathkeys = build_index_pathkeys(root, index,
+										BackwardScanDirection);
+			pathkeys = truncate_useless_pathkeys(root, rel,
+											 pathkeys);
+
+			indexPaths = reverseScanDirIdxPaths(indexPaths);
+			appendidxpath = create_append_path(rel, indexPaths, NULL, 0, NIL,
+											   true, pathkeys);
+			add_path(rel, (Path *) appendidxpath);
+		}
+	} else {
+		appendidxpath = create_append_path(rel, bestpath->bitmapquals, NULL,
+										   0, NIL, true, NIL);
+		add_path(rel, (Path *) appendidxpath);
+	}
+}
+
+/*
+ * transformToCkey - transform RestrictionInfo
+ * to CKey struct. Fucntion checks possibility and correctness of
+ * RestrictionInfo to use it as common key, normalizes 
+ * expression and "caches" some information. Note,
+ * original RestrictInfo isn't touched
+ */
+
+static CKey*
+transformToCkey( IndexOptInfo *index, RestrictInfo* rinfo, int indexcol) {
+	CKey	*key;
+	OpExpr  *expr = (OpExpr*)rinfo->clause;
+
+	if ( rinfo->outerjoin_delayed )
+		return NULL;
+
+	if ( !IsA(expr, OpExpr) )
+		return NULL;
+
+	if ( contain_mutable_functions((Node*)expr) )
+		return NULL;
+
+	if ( list_length( expr->args ) != 2 )
+		return NULL;
+
+	key = (CKey*)palloc(sizeof(CKey));
+	key->rinfo = rinfo;
+
+	key->normalizedexpr = (OpExpr*)copyObject( expr ); 
+	if (!bms_equal(rinfo->left_relids, index->rel->relids))
+		CommuteOpExpr(key->normalizedexpr);
+
+	/*
+	 * fix_indexqual_operand returns copy of object
+	 */
+	key->var = (Var*)fix_indexqual_operand(linitial(key->normalizedexpr->args), index, indexcol);
+	Assert( IsA(key->var, Var) );
+
+	key->opfamily = index->opfamily[ key->var->varattno - 1 ];
+
+	/* restore varattno, because it may be different in different index */
+	key->var->varattno = key->var->varoattno;
+
+	key->value = (Node*)lsecond(key->normalizedexpr->args);
+
+	key->strategy = get_op_opfamily_strategy( key->normalizedexpr->opno, key->opfamily);
+	Assert( key->strategy != InvalidStrategy );
+
+	key->strategyMask = BTMASK(key->strategy);
+
+	return key;
+}
+
+/*
+ * get_index_quals - get list of quals in
+ * CKeys form
+ */
+
+static List*
+get_index_quals(IndexPath *path, int cnt) {
+	ListCell	*i, *c;
+	List	*quals = NIL;
+
+	Assert(list_length(path->indexquals) == list_length(path->indexqualcols));
+	forboth(i, path->indexquals, c, path->indexqualcols) {
+		CKey	*k = transformToCkey( path->indexinfo, (RestrictInfo*)lfirst(i), lfirst_int(c) );
+		if ( k ) {
+			k->n = cnt;
+			quals = lappend(quals, k);
+		}
+	}
+	return quals;
+}
+
+/*
+ * extract all quals from bitmapquals->indexquals for
+ */
+static List*
+find_all_quals( BitmapOrPath *path, int *counter ) {
+	ListCell   *i,*j;
+	List	*allquals = NIL;
+
+	*counter = 0;
+
+	foreach(i, path->bitmapquals )
+	{
+		Path *subpath = (Path *) lfirst(i);
+
+		if ( IsA(subpath, BitmapAndPath) ) {
+			foreach(j, ((BitmapAndPath*)subpath)->bitmapquals) {
+				Path *subsubpath = (Path *) lfirst(i);
+
+				if ( IsA(subsubpath, IndexPath) ) {
+					if ( ((IndexPath*)subsubpath)->indexinfo->relam != BTREE_AM_OID )
+						return NIL;
+					allquals = list_concat(allquals, get_index_quals( (IndexPath*)subsubpath, *counter ));
+				} else
+					return NIL;
+			}
+		} else if ( IsA(subpath, IndexPath) ) {
+			if ( ((IndexPath*)subpath)->indexinfo->relam != BTREE_AM_OID )
+				return NIL;
+			allquals = list_concat(allquals, get_index_quals( (IndexPath*)subpath, *counter ));
+		} else
+			return NIL;
+
+		(*counter)++;
+	}
+
+	return allquals;
+}
+
+/*
+ * Compares aruments of operation
+ */
+static bool
+iseqCKeyArgs( CKey	*a, CKey *b ) {
+	if ( a->opfamily != b->opfamily )
+		return false;
+
+	if ( !equal( a->value, b->value ) )
+		return false;
+
+	if ( !equal( a->var, b->var ) )
+		return false;
+
+	return true;
+}
+
+/*
+ * Count entries of CKey with the same arguments
+ */
+static int
+count_entry( List *allquals, CKey *tocmp ) {
+	ListCell	*i;
+	int			curcnt=0;
+
+	foreach(i, allquals) {
+		CKey   *key = lfirst(i);
+
+		if ( key->n == curcnt ) {
+			continue;
+		} else if ( key->n == curcnt+1 ) {
+			if ( iseqCKeyArgs( key, tocmp ) ) {
+				tocmp->strategyMask |= key->strategyMask;
+				curcnt++;
+			}
+		} else
+			return -1;
+	}
+
+	return curcnt+1;
+}
+
+/*
+ * Finds all CKey with the same arguments
+ */
+static List*
+find_common_quals( BitmapOrPath *path ) {
+	List *allquals;
+	List *commonquals = NIL;
+	ListCell	*i;
+	int counter;
+
+	if ( (allquals = find_all_quals( path, &counter ))==NIL )
+		return NIL;
+
+	foreach(i, allquals) {
+		CKey	*key = lfirst(i);
+
+		if ( key->n != 0 )
+			break;
+
+		if ( counter == count_entry(allquals, key) )
+			commonquals = lappend( commonquals, key );
+	}
+
+	return commonquals;
+}
+
+/*
+ * unionOperation - make RestrictInfo with combined operation
+ */
+
+static RestrictInfo*
+unionOperation(CKey	*key) {
+	RestrictInfo	*rinfo;
+	Oid		lefttype, righttype;
+	int		strategy;
+
+	switch( key->strategyMask ) {
+		case	BTMASK(BTLessStrategyNumber):
+		case	BTMASK(BTLessEqualStrategyNumber):
+		case	BTMASK(BTEqualStrategyNumber):
+		case	BTMASK(BTGreaterEqualStrategyNumber):
+		case	BTMASK(BTGreaterStrategyNumber):
+				/* trivial case */
+				break;
+		case	BTMASK(BTLessStrategyNumber) | BTMASK(BTLessEqualStrategyNumber):
+		case	BTMASK(BTLessStrategyNumber) | BTMASK(BTLessEqualStrategyNumber) | BTMASK(BTEqualStrategyNumber):
+		case	BTMASK(BTLessStrategyNumber) | BTMASK(BTEqualStrategyNumber):
+		case	BTMASK(BTLessEqualStrategyNumber) | BTMASK(BTEqualStrategyNumber):
+				/* any subset of <, <=, = can be unioned with <= */
+				key->strategy = BTLessEqualStrategyNumber;
+				break;
+		case	BTMASK(BTGreaterEqualStrategyNumber) | BTMASK(BTGreaterStrategyNumber):
+		case	BTMASK(BTEqualStrategyNumber) | BTMASK(BTGreaterEqualStrategyNumber) | BTMASK(BTGreaterStrategyNumber):
+		case	BTMASK(BTEqualStrategyNumber) | BTMASK(BTGreaterStrategyNumber):
+		case	BTMASK(BTEqualStrategyNumber) | BTMASK(BTGreaterEqualStrategyNumber):
+				/* any subset of >, >=, = can be unioned with >= */
+				key->strategy = BTGreaterEqualStrategyNumber;
+				break;
+		default:
+			/*
+			 * Can't make common restrict qual
+			 */
+			return NULL;
+	}
+
+	get_op_opfamily_properties(key->normalizedexpr->opno, key->opfamily, false,
+							  &strategy, &lefttype, &righttype);
+
+	if ( strategy != key->strategy ) {
+		/*
+		 * We should check because it's possible to have "strange"
+		 * opfamilies - without some strategies...
+		 */
+		key->normalizedexpr->opno = get_opfamily_member(key->opfamily, lefttype, righttype, key->strategy);
+
+		if ( key->normalizedexpr->opno == InvalidOid )
+			return NULL;
+
+		key->normalizedexpr->opfuncid = get_opcode( key->normalizedexpr->opno );
+		Assert ( key->normalizedexpr->opfuncid != InvalidOid );
+	}
+
+	rinfo =	make_simple_restrictinfo((Expr*)key->normalizedexpr);
+
+	return rinfo;
+}
+
+/*
+ * Remove unneeded RestrioctionInfo nodes as it
+ * needed by predicate_*_by()
+ */
+static void 
+make_predicate(List *indexquals, List *indexqualcols, List **preds, List **predcols) {
+	ListCell	*i, *c;
+
+	*preds = NIL;
+	*predcols = NIL;
+
+	forboth(i, indexquals, c, indexqualcols) 
+	{
+		RestrictInfo *rinfo = lfirst(i);
+		OpExpr  *expr = (OpExpr*)rinfo->clause;
+
+		if ( rinfo->outerjoin_delayed )
+			continue;
+
+		if ( !IsA(expr, OpExpr) )
+			continue;
+
+		if ( list_length( expr->args ) != 2 )
+			continue;
+
+		*preds = lappend(*preds, rinfo);
+		*predcols = lappend(*predcols, lfirst(c));
+	}
+}
+
+#define CELL_GET_QUALS(x)	( ((IndexPath*)lfirst(x))->indexquals )
+#define CELL_GET_CLAUSES(x)	( ((IndexPath*)lfirst(x))->indexclauses )
+
+static List*
+listRInfo2OpExpr(List *listRInfo) {
+	ListCell	*i;
+	List		*listOpExpr=NULL;
+
+	foreach(i, listRInfo)
+	{
+		RestrictInfo *rinfo = lfirst(i);
+		OpExpr  *expr = (OpExpr*)rinfo->clause;
+
+		listOpExpr = lappend(listOpExpr, expr);
+	}
+
+	return listOpExpr;
+}
+
+/*
+ * returns list of all nested quals
+ */
+static List*
+contained_quals(List *nested, List* quals, ListCell *check) {
+	ListCell	*i;
+	List		*checkpred;
+
+	if ( list_member_ptr( nested, lfirst(check) ) )
+		return nested;
+
+	if (equal(CELL_GET_QUALS(check), CELL_GET_CLAUSES(check)) == false)
+		return nested;
+
+	checkpred = listRInfo2OpExpr(CELL_GET_QUALS(check));
+
+	if ( contain_mutable_functions((Node*)checkpred) )
+		return nested;
+
+	foreach(i, quals )
+	{
+		if ( check == i )
+			continue;
+
+		if ( list_member_ptr( nested, lfirst(i) ) )
+			continue;
+
+		if ( equal(CELL_GET_QUALS(i), CELL_GET_CLAUSES(i)) &&
+				predicate_implied_by( checkpred, CELL_GET_QUALS(i), false ) )
+			nested = lappend( nested, lfirst(i) );
+	}
+	return nested;
+}
+
+/*
+ * Checks that one row can be in several quals.
+ * It's guaranteed by predicate_refuted_by()
+ */
+static bool
+is_intersect(ListCell *check) {
+	ListCell	*i;
+	List		*checkpred=NULL;
+
+	checkpred=listRInfo2OpExpr(CELL_GET_QUALS(check));
+	Assert( checkpred != NULL );
+
+	for_each_cell(i, check) {
+		if ( i==check )
+			continue;
+
+		if ( predicate_refuted_by( checkpred, CELL_GET_QUALS(i), false ) == false )
+			return true;
+	}
+
+	return false;
+}
+
+/*
+ * Removes nested quals and gurantees that quals are not intersected,
+ * ie one row can't satisfy to several quals. It's open a possibility of
+ * Append node using instead of BitmapOr
+ */
+static	BitmapOrPath*
+cleanup_nested_quals( PlannerInfo *root, RelOptInfo *rel, BitmapOrPath *path ) {
+	ListCell   *i;
+	IndexOptInfo	*index=NULL;
+	List		*nested = NULL;
+
+	/*
+	 * check all path to use only one index
+	 */
+	foreach(i, path->bitmapquals )
+	{
+
+		if ( IsA(lfirst(i), IndexPath) ) {
+			List *preds, *predcols;
+			IndexPath *subpath = (IndexPath *) lfirst(i);
+
+			if ( subpath->indexinfo->relam != BTREE_AM_OID )
+				return NULL;
+
+			if ( index == NULL )
+				index = subpath->indexinfo;
+			else if ( index->indexoid != subpath->indexinfo->indexoid )
+				return NULL;
+
+			/*
+			 * work only with optimizable quals
+			 */
+			Assert(list_length(subpath->indexquals) == list_length(subpath->indexqualcols));
+			make_predicate(subpath->indexquals, subpath->indexqualcols, &preds, &predcols); 
+			if (preds == NIL)
+				return NULL;
+			subpath->indexquals = preds;
+			subpath->indexqualcols = predcols;
+			Assert(list_length(subpath->indexquals) == list_length(subpath->indexqualcols));
+		} else
+			return NULL;
+	}
+
+	/*
+	 * eliminate nested quals
+	 */
+	foreach(i, path->bitmapquals ) {
+		nested = contained_quals(nested, path->bitmapquals, i);
+	}
+
+	if ( nested != NIL ) {
+		path->bitmapquals = list_difference_ptr( path->bitmapquals, nested );
+
+		Assert( list_length( path->bitmapquals )>0 );
+
+		/*
+		 * All quals becomes only one after eliminating nested quals
+		 */
+		if (list_length( path->bitmapquals ) == 1)
+			return (BitmapOrPath*)linitial(path->bitmapquals);
+	}
+
+	/*
+	 * Checks for intersection
+	 */
+	foreach(i, path->bitmapquals ) {
+		if ( is_intersect( i ) )
+			return NULL;
+	}
+
+	return path;
+}
+
+/*
+ * Checks if whole result of one simple operation is contained
+ * in another
+ */
+static int
+simpleCmpExpr( ExExpr *a, ExExpr *b ) {
+	if ( predicate_implied_by((List*)a->expr, (List*)b->expr, false) )
+		/*
+		 * a:( Var < 15 ) > b:( Var <= 10 )
+		 */
+		return 1;
+	else if ( predicate_implied_by((List*)b->expr, (List*)a->expr, false) )
+		/*
+		 * a:( Var <= 10 ) < b:( Var < 15 )
+		 */
+		return -1;
+	else
+		return 0;
+}
+
+/*
+ * Trys to define where is equation - on left or right side
+ *		a(< 10)	 b(=11)	- on right
+ *		a(> 10)  b(=9)	- on left
+ *		a(= 10)	 b(=11)	- on right
+ *		a(= 10)  b(=9)	- on left
+ * Any other - result is 0;
+ */
+static int
+cmpEqExpr( ExExpr *a, ExExpr *b ) {
+	Oid oldop = b->expr->opno;
+	int res=0;
+
+	b->expr->opno = get_opfamily_member(b->opfamily, b->lefttype, b->righttype, BTLessStrategyNumber);
+	if ( b->expr->opno != InvalidOid ) {
+		 b->expr->opfuncid = get_opcode( b->expr->opno );
+		res = simpleCmpExpr(a,b);
+	}
+
+	if ( res == 0 ) {
+		b->expr->opno = get_opfamily_member(b->opfamily, b->lefttype, b->righttype, BTGreaterStrategyNumber);
+		if ( b->expr->opno != InvalidOid ) {
+			b->expr->opfuncid = get_opcode( b->expr->opno );
+			res = -simpleCmpExpr(a,b);
+		}
+	}
+
+	b->expr->opno = oldop;
+	b->expr->opfuncid = get_opcode( b->expr->opno );
+
+	return res;
+}
+
+/*
+ * Is result of a contained in result of b or on the contrary?
+ */
+static int
+cmpNegCmp( ExExpr *a, ExExpr *b ) {
+	Oid oldop = b->expr->opno;
+	int	res = 0;
+
+	b->expr->opno = get_negator( b->expr->opno );
+	if ( b->expr->opno != InvalidOid ) {
+		b->expr->opfuncid = get_opcode( b->expr->opno );
+		res = simpleCmpExpr(a,b);
+	}
+
+	b->expr->opno = oldop;
+	b->expr->opfuncid = get_opcode( b->expr->opno );
+
+	return ( IS_LESS(a->strategy) ) ? res : -res;
+}
+
+/*
+ * Returns 1 if whole result of a is on left comparing with result of b
+ * Returns -1 if whole result of a is on right comparing with result of b
+ * Return 0 if it's impossible to define or results is overlapped
+ * Expressions should use the same attribute of index and should be
+ * a simple: just one operation with index.
+ */
+static int
+cmpExpr( ExExpr *a, ExExpr *b ) {
+	int res;
+
+	/*
+	 * If a and b are overlapped, we can't decide which one is
+	 * lefter or righter
+	 */
+	if ( IS_ONE_DIRECTION(a->strategy, b->strategy) || predicate_refuted_by((List*)a->expr, (List*)b->expr, false) == false )
+		return 0;
+
+	/*
+	 * In this place it's impossible to have a row which satisfies
+	 * a and b expressions, so we will try to find relatiove position of that results
+	 */
+	if ( b->strategy == BTEqualStrategyNumber ) {
+		return -cmpEqExpr(a, b); /* Covers cases with any operations in a */
+	} else if ( a->strategy == BTEqualStrategyNumber ) {
+		return cmpEqExpr(b, a);
+	} else if ( (res = cmpNegCmp(a, b)) == 0 ) { /* so, a(<10) b(>20) */
+		res = -cmpNegCmp(b, a);
+	}
+
+	return res;
+}
+
+/*
+ * Try to define positions of result which satisfy indexquals a and b per
+ * one index's attribute.
+ */
+static int
+cmpColumnQuals( List *a, List *b, int attno ) {
+	int res = 0;
+	ListCell *ai, *bi;
+
+	foreach(ai, a) {
+		ExExpr	*ae = (ExExpr*)lfirst(ai);
+
+		if ( attno != ae->attno )
+			continue;
+
+		foreach(bi, b) {
+			ExExpr	*be = (ExExpr*)lfirst(bi);
+
+			if ( attno != be->attno )
+				continue;
+
+			if ((res=cmpExpr(ae, be))!=0)
+				return res;
+		}
+	}
+
+	return 0;
+}
+
+static IndexOptInfo	*sortingIndex = NULL;
+static bool volatile	unableToDefine = false;
+
+/*
+ * Compare result of two indexquals.
+ * Warinig: it use PG_RE_THROW(), so any call should be wrapped with
+ * PG_TRY().  Try/catch construction is used here for minimize unneeded
+ * actions when sorting is impossible
+ */
+static int
+cmpIndexPathEx(const void *a, const void *b) {
+	IndexPathEx	*aipe = (IndexPathEx*)a;
+	IndexPathEx	*bipe = (IndexPathEx*)b;
+	int attno, res = 0;
+
+	for(attno=1; res==0 && attno<=sortingIndex->ncolumns; attno++)
+		res=cmpColumnQuals(aipe->preparedquals, bipe->preparedquals, attno);
+
+	if ( res==0 ) {
+		unableToDefine = true;
+		PG_RE_THROW(); /* it should be PG_THROW(), but it's the same */
+	}
+
+	return res;
+}
+
+/*
+ * Initialize lists of operation in useful form
+ */
+static List*
+prepareQuals(IndexOptInfo *index, List *indexquals, List *indexqualcols) {
+	ListCell	*i, *c;
+	List		*res=NULL;
+	ExExpr		*ex;
+
+	Assert(list_length(indexquals) == list_length(indexqualcols));
+	forboth(i, indexquals, c, indexqualcols)
+	{
+		RestrictInfo *rinfo = lfirst(i);
+		OpExpr  *expr = (OpExpr*)rinfo->clause;
+
+		if ( rinfo->outerjoin_delayed )
+			return NULL;
+
+		if ( !IsA(expr, OpExpr) )
+			return NULL;
+
+		if ( list_length( expr->args ) != 2 )
+			return NULL;
+
+		if ( contain_mutable_functions((Node*)expr) )
+			return NULL;
+
+		ex = (ExExpr*)palloc(sizeof(ExExpr));
+		ex->expr = (OpExpr*)copyObject( expr );
+		if (!bms_equal(rinfo->left_relids, index->rel->relids))
+			CommuteOpExpr(ex->expr);
+		linitial(ex->expr->args) = fix_indexqual_operand(linitial(ex->expr->args), index, lfirst_int(c));
+		ex->attno = ((Var*)linitial(ex->expr->args))->varattno;
+		ex->opfamily = index->opfamily[ ex->attno - 1 ];
+		get_op_opfamily_properties( ex->expr->opno, ex->opfamily, false,
+			&ex->strategy, &ex->lefttype, &ex->righttype);
+
+		res = lappend(res, ex);
+	}
+
+	return res;
+}
+
+/*
+ * sortIndexScans - sorts index scans to get sorted results.
+ * Function supposed that index is the same for all
+ * index scans
+ */
+static List*
+sortIndexScans( List* ipaths ) {
+	ListCell	*i;
+	int			j=0;
+	IndexPathEx	*ipe = (IndexPathEx*)palloc( sizeof(IndexPathEx)*list_length(ipaths) );
+	List		*orderedPaths = NIL;
+	IndexOptInfo *index = ((IndexPath*)linitial(ipaths))->indexinfo;
+
+	foreach(i, ipaths) {
+		ipe[j].path = (IndexPath*)lfirst(i);
+		ipe[j].preparedquals = prepareQuals( index, ipe[j].path->indexquals, ipe[j].path->indexqualcols );
+
+		if (ipe[j].preparedquals == NULL)
+			return NULL;
+		j++;
+	}
+
+	sortingIndex = index;
+	unableToDefine = false;
+	PG_TRY(); {
+		qsort(ipe, list_length(ipaths), sizeof(IndexPathEx), cmpIndexPathEx);
+	} PG_CATCH(); {
+		if ( unableToDefine == false )
+			PG_RE_THROW(); /* not our problem */
+	} PG_END_TRY();
+
+	if ( unableToDefine == true )
+		return NULL;
+
+	for(j=0;j<list_length(ipaths);j++)
+		orderedPaths = lappend(orderedPaths, ipe[j].path);
+
+	return  orderedPaths;
+}
+
+static  IndexPath*
+reverseScanDirIdxPath(IndexPath *ipath) {
+	IndexPath   *n = makeNode(IndexPath);
+
+	*n = *ipath;
+
+	n->indexscandir = BackwardScanDirection;
+
+	return n;
+}
+
+static List*
+reverseScanDirIdxPaths(List *indexPaths) {
+	List		*idxpath = NIL;
+	ListCell	*i;
+
+	foreach(i, indexPaths) {
+		idxpath = lcons(reverseScanDirIdxPath( (IndexPath*)lfirst(i) ), idxpath);
+	}
+
+	return idxpath;
+}
diff -ruN a/src/backend/optimizer/path/indxpath.c b/src/backend/optimizer/path/indxpath.c
--- a/src/backend/optimizer/path/indxpath.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/path/indxpath.c	2017-12-28 14:58:03.491304913 +0300
@@ -39,6 +39,14 @@
 #include "utils/pg_locale.h"
 #include "utils/selfuncs.h"
 
+/*
+ * index support for LIKE mchar
+ */
+#include "fmgr.h"
+#include "access/htup_details.h"
+#include "utils/catcache.h"
+#include "utils/syscache.h"
+#include "parser/parse_type.h"
 
 #define IsBooleanOpfamily(opfamily) \
 	((opfamily) == BOOL_BTREE_FAM_OID || (opfamily) == BOOL_HASH_FAM_OID)
@@ -116,8 +124,6 @@
 				  bool *skip_lower_saop);
 static List *build_paths_for_OR(PlannerInfo *root, RelOptInfo *rel,
 				   List *clauses, List *other_clauses);
-static List *generate_bitmap_or_paths(PlannerInfo *root, RelOptInfo *rel,
-						 List *clauses, List *other_clauses);
 static Path *choose_bitmap_and(PlannerInfo *root, RelOptInfo *rel,
 				  List *paths);
 static int	path_usage_comparator(const void *a, const void *b);
@@ -1261,7 +1267,7 @@
  * for the purpose of generating indexquals, but are not to be searched for
  * ORs.  (See build_paths_for_OR() for motivation.)
  */
-static List *
+List *
 generate_bitmap_or_paths(PlannerInfo *root, RelOptInfo *rel,
 						 List *clauses, List *other_clauses)
 {
@@ -3242,6 +3248,208 @@
 }
 
 /****************************************************************************
+ *			----  ROUTINES FOR "SPECIAL" INDEXABLE OPERATORS  FOR 
+ *                 SPECIAL USER_DEFINED TYPES ----
+ *									-- teodor
+ ****************************************************************************/
+
+static Oid mmPFPOid = InvalidOid; 
+static Oid mmGTOid = InvalidOid; 
+static Oid mcharOid = InvalidOid; 
+static Oid mvarcharOid = InvalidOid;
+
+static bool
+fillMCharOIDS() {
+	CatCList    *catlist;
+	HeapTuple   tup;
+	char        *funcname = "mchar_pattern_fixed_prefix";
+	int			n_members;
+
+	catlist = SearchSysCacheList(PROCNAMEARGSNSP, 1,
+									CStringGetDatum(funcname),
+									0, 0, 0);
+	n_members = catlist->n_members;
+
+	if ( n_members != 1 ) {
+		ReleaseSysCacheList(catlist);
+		if ( n_members > 1 ) 
+			elog(ERROR,"There are %d candidates for '%s' function'", n_members, funcname);
+		return false;
+	}
+
+	tup = &catlist->members[0]->tuple;
+
+	if ( HeapTupleGetOid(tup) != mmPFPOid ) {
+		TypeName	*typename;
+		Type		typtup;
+		char        *quals_funcname = "mchar_greaterstring";
+		Oid			tmp_mmPFPOid = HeapTupleGetOid(tup);
+
+		ReleaseSysCacheList(catlist);
+
+		typename = makeTypeName("mchar");
+		typtup = LookupTypeName(NULL, typename, NULL, true);
+		if ( typtup ) {
+			mcharOid = typeTypeId(typtup);
+			ReleaseSysCache(typtup);
+		}
+
+		typename = makeTypeName("mvarchar");
+		typtup = LookupTypeName(NULL, typename, NULL, true);
+		if ( typtup ) {
+			mvarcharOid = typeTypeId(typtup);
+			ReleaseSysCache(typtup);
+		}
+
+
+		if ( mcharOid == InvalidOid || mvarcharOid == InvalidOid ) {
+			elog(LOG,"Can't find mchar/mvarvarchar types: mchar=%d mvarchar=%d", 
+					mcharOid, mvarcharOid);
+			return false;
+		}
+
+		catlist = SearchSysCacheList(PROCNAMEARGSNSP, 1,
+										CStringGetDatum(quals_funcname),
+										0, 0, 0);
+		n_members = catlist->n_members;
+
+		if ( n_members != 1 ) {
+			ReleaseSysCacheList(catlist);
+			if ( n_members > 1 ) 
+				elog(ERROR,"There are %d candidates for '%s' function'", n_members, quals_funcname);
+			return false;
+		}
+
+		tup = &catlist->members[0]->tuple;
+		mmGTOid  = HeapTupleGetOid(tup); 
+		mmPFPOid = tmp_mmPFPOid;
+	}
+
+	ReleaseSysCacheList(catlist);
+
+	return true;
+}
+
+static Pattern_Prefix_Status
+mchar_pattern_fixed_prefix(Oid opOid, Oid opfamilyOid, Const *patt, Pattern_Type ptype,
+                     Const **prefix, Oid *leftTypeOid) {
+	HeapTuple	tup;
+    Form_pg_operator oprForm;
+	bool	isMCharLike = true;
+	 
+	if ( !fillMCharOIDS() )
+		return Pattern_Prefix_None;
+
+	tup = SearchSysCache(OPEROID, opOid, 0, 0, 0);
+	oprForm	= (Form_pg_operator) GETSTRUCT(tup);
+
+	if ( strncmp(oprForm->oprname.data, "~~", 2) != 0 ) 
+		isMCharLike	= false;
+
+	if ( oprForm->oprright != mvarcharOid )
+		isMCharLike = false;
+
+	if ( !( oprForm->oprleft == mcharOid || oprForm->oprleft == mvarcharOid ) )
+		isMCharLike = false;
+
+	if ( patt->consttype != mvarcharOid )
+		isMCharLike = false;
+
+	if (leftTypeOid) 
+		*leftTypeOid = oprForm->oprleft;
+
+	ReleaseSysCache(tup);
+
+	if ( !isMCharLike )
+		return Pattern_Prefix_None;
+
+	if ( opfamilyOid != InvalidOid ) {
+		Form_pg_opfamily claForm;
+
+		tup = SearchSysCache(OPFAMILYOID, opfamilyOid, 0, 0, 0);
+		claForm = (Form_pg_opfamily) GETSTRUCT(tup);
+
+		if ( claForm->opfmethod != BTREE_AM_OID )
+			isMCharLike = false;
+
+		if ( mcharOid && strncmp(claForm->opfname.data, "icase_ops", 9 /* strlen(icase_ops) */ ) != 0 )
+			isMCharLike = false;
+
+		ReleaseSysCache(tup);
+	}
+
+	if ( !isMCharLike )
+		return Pattern_Prefix_None;
+
+	return (Pattern_Prefix_Status)DatumGetInt32( OidFunctionCall3(
+		mmPFPOid,
+		PointerGetDatum( patt ),
+		Int32GetDatum( ptype ),
+		PointerGetDatum( prefix )
+	) );
+}
+
+static Oid
+get_opclass_member_mchar(Oid opclass, Oid leftTypeOid, int strategy) {
+	Oid	oproid;
+
+	oproid = get_opfamily_member(opclass, leftTypeOid, mvarcharOid, strategy);
+
+	if ( oproid == InvalidOid )
+		elog(ERROR, "no operator for opclass %u for strategy %u for left type %u", opclass, strategy, leftTypeOid);
+
+	return oproid;
+}
+
+static List *
+mchar_prefix_quals(Node *leftop, Oid leftTypeOid, Oid opclass,
+             Const *prefix_const, Pattern_Prefix_Status pstatus) {
+	Oid		oproid;
+	Expr	*expr;
+	List	*result;
+	Const	*greaterstr;
+
+	Assert(pstatus != Pattern_Prefix_None);
+	if ( pstatus == Pattern_Prefix_Exact ) {
+		oproid = get_opclass_member_mchar(opclass, leftTypeOid, BTEqualStrategyNumber);
+
+		expr = make_opclause(oproid, BOOLOID, false,
+								(Expr *) leftop, (Expr *) prefix_const,
+								InvalidOid, InvalidOid);
+		result = list_make1(make_simple_restrictinfo(expr));
+		return result;
+	}
+	
+	/* We can always say "x >= prefix". */
+	oproid = get_opclass_member_mchar(opclass, leftTypeOid, BTGreaterEqualStrategyNumber);
+
+	expr = make_opclause(oproid, BOOLOID, false,
+							(Expr *) leftop, (Expr *) prefix_const,
+							InvalidOid, InvalidOid);
+	result = list_make1(make_simple_restrictinfo(expr));
+
+	/* If we can create a string larger than the prefix, we can say
+	 * "x < greaterstr". */
+
+	greaterstr = (Const*)DatumGetPointer( OidFunctionCall1(
+		mmGTOid,
+		PointerGetDatum( prefix_const )
+	) );
+
+	if (greaterstr) {
+		oproid = get_opclass_member_mchar(opclass, leftTypeOid, BTLessStrategyNumber);
+
+		expr = make_opclause(oproid, BOOLOID, false,
+								(Expr *) leftop, (Expr *) greaterstr,
+								InvalidOid, InvalidOid);
+		result = lappend(result, make_simple_restrictinfo(expr));
+	}
+
+	return result;
+}
+
+
+/****************************************************************************
  *			----  ROUTINES FOR "SPECIAL" INDEXABLE OPERATORS  ----
  ****************************************************************************/
 
@@ -3433,9 +3641,16 @@
 		pfree(prefix);
 	}
 
-	/* done if the expression doesn't look indexable */
-	if (!isIndexable)
+	if ( !isIndexable ) {
+		/* done if the expression doesn't look indexable,
+			but we should previously check it for mchar/mvarchar types */
+		if ( mchar_pattern_fixed_prefix(expr_op, InvalidOid,
+								patt, Pattern_Type_Like,
+								&prefix, NULL) != Pattern_Prefix_None ) {
+			return true;
+		}
 		return false;
+	}
 
 	/*
 	 * Must also check that index's opfamily supports the operators we will
@@ -3686,6 +3901,14 @@
 	Const	   *patt = (Const *) rightop;
 	Const	   *prefix = NULL;
 	Pattern_Prefix_Status pstatus;
+	Oid			leftTypeOid;
+
+	pstatus = mchar_pattern_fixed_prefix(expr_op, opfamily,
+											patt, Pattern_Type_Like,
+											&prefix, &leftTypeOid);
+
+	if ( pstatus != Pattern_Prefix_None )
+		return mchar_prefix_quals(leftop, leftTypeOid, opfamily, prefix, pstatus);
 
 	/*
 	 * LIKE and regex operators are not members of any btree index opfamily,
diff -ruN a/src/backend/optimizer/path/joinrels.c b/src/backend/optimizer/path/joinrels.c
--- a/src/backend/optimizer/path/joinrels.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/path/joinrels.c	2017-12-28 14:58:03.491304913 +0300
@@ -1217,7 +1217,8 @@
 	rel->partial_pathlist = NIL;
 
 	/* Set up the dummy path */
-	add_path(rel, (Path *) create_append_path(rel, NIL, NULL, 0, NIL));
+	add_path(rel, (Path *) create_append_path(rel, NIL, NULL, 0, NIL,
+											  false, NIL));
 
 	/* Set or update cheapest_total_path and related fields */
 	set_cheapest(rel);
diff -ruN a/src/backend/optimizer/path/Makefile b/src/backend/optimizer/path/Makefile
--- a/src/backend/optimizer/path/Makefile	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/path/Makefile	2017-12-28 14:58:03.491304913 +0300
@@ -12,7 +12,7 @@
 top_builddir = ../../../..
 include $(top_builddir)/src/Makefile.global
 
-OBJS = allpaths.o clausesel.o costsize.o equivclass.o indxpath.o \
-       joinpath.o joinrels.o pathkeys.o tidpath.o
+OBJS = allpaths.o appendorpath.o clausesel.o costsize.o equivclass.o \
+       indxpath.o joinpath.o joinrels.o pathkeys.o tidpath.o
 
 include $(top_srcdir)/src/backend/common.mk
diff -ruN a/src/backend/optimizer/path/pathkeys.c b/src/backend/optimizer/path/pathkeys.c
--- a/src/backend/optimizer/path/pathkeys.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/path/pathkeys.c	2017-12-28 14:58:03.491304913 +0300
@@ -1492,7 +1492,7 @@
  * no good to order by just the first key(s) of the requested ordering.
  * So the result is always either 0 or list_length(root->query_pathkeys).
  */
-static int
+int
 pathkeys_useful_for_ordering(PlannerInfo *root, List *pathkeys)
 {
 	if (root->query_pathkeys == NIL)
diff -ruN a/src/backend/optimizer/plan/createplan.c b/src/backend/optimizer/plan/createplan.c
--- a/src/backend/optimizer/plan/createplan.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/plan/createplan.c	2017-12-28 14:58:03.495304864 +0300
@@ -157,7 +157,6 @@
 								 List *subplan_params);
 static List *fix_indexqual_references(PlannerInfo *root, IndexPath *index_path);
 static List *fix_indexorderby_references(PlannerInfo *root, IndexPath *index_path);
-static Node *fix_indexqual_operand(Node *node, IndexOptInfo *index, int indexcol);
 static List *get_switched_clauses(List *clauses, Relids outerrelids);
 static List *order_qual_clauses(PlannerInfo *root, List *clauses);
 static void copy_generic_path_info(Plan *dest, Path *src);
@@ -1002,7 +1001,7 @@
 create_append_plan(PlannerInfo *root, AppendPath *best_path)
 {
 	Append	   *plan;
-	List	   *tlist = build_path_tlist(root, &best_path->path);
+	List	   *tlist;
 	List	   *subplans = NIL;
 	ListCell   *subpaths;
 
@@ -1020,6 +1019,7 @@
 		/* Generate a Result plan with constant-FALSE gating qual */
 		Plan	   *plan;
 
+		tlist = build_path_tlist(root, &best_path->path);
 		plan = (Plan *) make_result(tlist,
 									(Node *) list_make1(makeBoolConst(false,
 																	  false)),
@@ -1049,6 +1049,11 @@
 	 * parent-rel Vars it'll be asked to emit.
 	 */
 
+	if ( best_path->pull_tlist )
+		tlist = copyObject( ((Plan*)linitial(subplans))->targetlist );
+	else
+		tlist = build_path_tlist(root, &best_path->path);
+
 	plan = make_append(subplans, tlist, best_path->partitioned_rels);
 
 	copy_generic_path_info(&plan->plan, (Path *) best_path);
@@ -4610,7 +4615,7 @@
  * Most of the code here is just for sanity cross-checking that the given
  * expression actually matches the index column it's claimed to.
  */
-static Node *
+Node *
 fix_indexqual_operand(Node *node, IndexOptInfo *index, int indexcol)
 {
 	Var		   *result;
diff -ruN a/src/backend/optimizer/plan/planner.c b/src/backend/optimizer/plan/planner.c
--- a/src/backend/optimizer/plan/planner.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/plan/planner.c	2017-12-28 14:58:03.495304864 +0300
@@ -3619,6 +3619,8 @@
 								   paths,
 								   NULL,
 								   0,
+								   NIL,
+								   false,
 								   NIL);
 			path->pathtarget = target;
 		}
diff -ruN a/src/backend/optimizer/plan/planner.c.orig b/src/backend/optimizer/plan/planner.c.orig
--- a/src/backend/optimizer/plan/planner.c.orig	1970-01-01 03:00:00.000000000 +0300
+++ b/src/backend/optimizer/plan/planner.c.orig	2017-12-28 14:58:03.495304864 +0300
@@ -0,0 +1,6114 @@
+/*-------------------------------------------------------------------------
+ *
+ * planner.c
+ *	  The query optimizer external interface.
+ *
+ * Portions Copyright (c) 1996-2017, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/optimizer/plan/planner.c
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#include "postgres.h"
+
+#include <limits.h>
+#include <math.h>
+
+#include "access/htup_details.h"
+#include "access/parallel.h"
+#include "access/sysattr.h"
+#include "access/xact.h"
+#include "catalog/pg_constraint_fn.h"
+#include "catalog/pg_proc.h"
+#include "catalog/pg_type.h"
+#include "executor/executor.h"
+#include "executor/nodeAgg.h"
+#include "foreign/fdwapi.h"
+#include "miscadmin.h"
+#include "lib/bipartite_match.h"
+#include "lib/knapsack.h"
+#include "nodes/makefuncs.h"
+#include "nodes/nodeFuncs.h"
+#ifdef OPTIMIZER_DEBUG
+#include "nodes/print.h"
+#endif
+#include "optimizer/clauses.h"
+#include "optimizer/cost.h"
+#include "optimizer/pathnode.h"
+#include "optimizer/paths.h"
+#include "optimizer/plancat.h"
+#include "optimizer/planmain.h"
+#include "optimizer/planner.h"
+#include "optimizer/prep.h"
+#include "optimizer/subselect.h"
+#include "optimizer/tlist.h"
+#include "optimizer/var.h"
+#include "parser/analyze.h"
+#include "parser/parsetree.h"
+#include "parser/parse_agg.h"
+#include "rewrite/rewriteManip.h"
+#include "storage/dsm_impl.h"
+#include "utils/rel.h"
+#include "utils/selfuncs.h"
+#include "utils/lsyscache.h"
+#include "utils/syscache.h"
+
+
+/* GUC parameters */
+double		cursor_tuple_fraction = DEFAULT_CURSOR_TUPLE_FRACTION;
+int			force_parallel_mode = FORCE_PARALLEL_OFF;
+
+/* Hook for plugins to get control in planner() */
+planner_hook_type planner_hook = NULL;
+
+/* Hook for plugins to get control when grouping_planner() plans upper rels */
+create_upper_paths_hook_type create_upper_paths_hook = NULL;
+
+
+/* Expression kind codes for preprocess_expression */
+#define EXPRKIND_QUAL				0
+#define EXPRKIND_TARGET				1
+#define EXPRKIND_RTFUNC				2
+#define EXPRKIND_RTFUNC_LATERAL		3
+#define EXPRKIND_VALUES				4
+#define EXPRKIND_VALUES_LATERAL		5
+#define EXPRKIND_LIMIT				6
+#define EXPRKIND_APPINFO			7
+#define EXPRKIND_PHV				8
+#define EXPRKIND_TABLESAMPLE		9
+#define EXPRKIND_ARBITER_ELEM		10
+#define EXPRKIND_TABLEFUNC			11
+#define EXPRKIND_TABLEFUNC_LATERAL	12
+
+/* Passthrough data for standard_qp_callback */
+typedef struct
+{
+	List	   *tlist;			/* preprocessed query targetlist */
+	List	   *activeWindows;	/* active windows, if any */
+	List	   *groupClause;	/* overrides parse->groupClause */
+} standard_qp_extra;
+
+/*
+ * Data specific to grouping sets
+ */
+
+typedef struct
+{
+	List	   *rollups;
+	List	   *hash_sets_idx;
+	double		dNumHashGroups;
+	bool		any_hashable;
+	Bitmapset  *unsortable_refs;
+	Bitmapset  *unhashable_refs;
+	List	   *unsortable_sets;
+	int		   *tleref_to_colnum_map;
+} grouping_sets_data;
+
+/* Local functions */
+static Node *preprocess_expression(PlannerInfo *root, Node *expr, int kind);
+static void preprocess_qual_conditions(PlannerInfo *root, Node *jtnode);
+static void inheritance_planner(PlannerInfo *root);
+static void grouping_planner(PlannerInfo *root, bool inheritance_update,
+				 double tuple_fraction);
+static grouping_sets_data *preprocess_grouping_sets(PlannerInfo *root);
+static List *remap_to_groupclause_idx(List *groupClause, List *gsets,
+						 int *tleref_to_colnum_map);
+static void preprocess_rowmarks(PlannerInfo *root);
+static double preprocess_limit(PlannerInfo *root,
+				 double tuple_fraction,
+				 int64 *offset_est, int64 *count_est);
+static bool limit_needed(Query *parse);
+static void remove_useless_groupby_columns(PlannerInfo *root);
+static List *preprocess_groupclause(PlannerInfo *root, List *force);
+static List *extract_rollup_sets(List *groupingSets);
+static List *reorder_grouping_sets(List *groupingSets, List *sortclause);
+static void standard_qp_callback(PlannerInfo *root, void *extra);
+static double get_number_of_groups(PlannerInfo *root,
+					 double path_rows,
+					 grouping_sets_data *gd);
+static Size estimate_hashagg_tablesize(Path *path,
+						   const AggClauseCosts *agg_costs,
+						   double dNumGroups);
+static RelOptInfo *create_grouping_paths(PlannerInfo *root,
+					  RelOptInfo *input_rel,
+					  PathTarget *target,
+					  const AggClauseCosts *agg_costs,
+					  grouping_sets_data *gd);
+static void consider_groupingsets_paths(PlannerInfo *root,
+							RelOptInfo *grouped_rel,
+							Path *path,
+							bool is_sorted,
+							bool can_hash,
+							PathTarget *target,
+							grouping_sets_data *gd,
+							const AggClauseCosts *agg_costs,
+							double dNumGroups);
+static RelOptInfo *create_window_paths(PlannerInfo *root,
+					RelOptInfo *input_rel,
+					PathTarget *input_target,
+					PathTarget *output_target,
+					List *tlist,
+					WindowFuncLists *wflists,
+					List *activeWindows);
+static void create_one_window_path(PlannerInfo *root,
+					   RelOptInfo *window_rel,
+					   Path *path,
+					   PathTarget *input_target,
+					   PathTarget *output_target,
+					   List *tlist,
+					   WindowFuncLists *wflists,
+					   List *activeWindows);
+static RelOptInfo *create_distinct_paths(PlannerInfo *root,
+					  RelOptInfo *input_rel);
+static RelOptInfo *create_ordered_paths(PlannerInfo *root,
+					 RelOptInfo *input_rel,
+					 PathTarget *target,
+					 double limit_tuples);
+static PathTarget *make_group_input_target(PlannerInfo *root,
+						PathTarget *final_target);
+static PathTarget *make_partial_grouping_target(PlannerInfo *root,
+							 PathTarget *grouping_target);
+static List *postprocess_setop_tlist(List *new_tlist, List *orig_tlist);
+static List *select_active_windows(PlannerInfo *root, WindowFuncLists *wflists);
+static PathTarget *make_window_input_target(PlannerInfo *root,
+						 PathTarget *final_target,
+						 List *activeWindows);
+static List *make_pathkeys_for_window(PlannerInfo *root, WindowClause *wc,
+						 List *tlist);
+static PathTarget *make_sort_input_target(PlannerInfo *root,
+					   PathTarget *final_target,
+					   bool *have_postponed_srfs);
+static void adjust_paths_for_srfs(PlannerInfo *root, RelOptInfo *rel,
+					  List *targets, List *targets_contain_srfs);
+
+
+/*****************************************************************************
+ *
+ *	   Query optimizer entry point
+ *
+ * To support loadable plugins that monitor or modify planner behavior,
+ * we provide a hook variable that lets a plugin get control before and
+ * after the standard planning process.  The plugin would normally call
+ * standard_planner().
+ *
+ * Note to plugin authors: standard_planner() scribbles on its Query input,
+ * so you'd better copy that data structure if you want to plan more than once.
+ *
+ *****************************************************************************/
+PlannedStmt *
+planner(Query *parse, int cursorOptions, ParamListInfo boundParams)
+{
+	PlannedStmt *result;
+
+	if (planner_hook)
+		result = (*planner_hook) (parse, cursorOptions, boundParams);
+	else
+		result = standard_planner(parse, cursorOptions, boundParams);
+	return result;
+}
+
+PlannedStmt *
+standard_planner(Query *parse, int cursorOptions, ParamListInfo boundParams)
+{
+	PlannedStmt *result;
+	PlannerGlobal *glob;
+	double		tuple_fraction;
+	PlannerInfo *root;
+	RelOptInfo *final_rel;
+	Path	   *best_path;
+	Plan	   *top_plan;
+	ListCell   *lp,
+			   *lr;
+
+	/*
+	 * Set up global state for this planner invocation.  This data is needed
+	 * across all levels of sub-Query that might exist in the given command,
+	 * so we keep it in a separate struct that's linked to by each per-Query
+	 * PlannerInfo.
+	 */
+	glob = makeNode(PlannerGlobal);
+
+	glob->boundParams = boundParams;
+	glob->subplans = NIL;
+	glob->subroots = NIL;
+	glob->rewindPlanIDs = NULL;
+	glob->finalrtable = NIL;
+	glob->finalrowmarks = NIL;
+	glob->resultRelations = NIL;
+	glob->nonleafResultRelations = NIL;
+	glob->rootResultRelations = NIL;
+	glob->relationOids = NIL;
+	glob->invalItems = NIL;
+	glob->nParamExec = 0;
+	glob->lastPHId = 0;
+	glob->lastRowMarkId = 0;
+	glob->lastPlanNodeId = 0;
+	glob->transientPlan = false;
+	glob->dependsOnRole = false;
+
+	/*
+	 * Assess whether it's feasible to use parallel mode for this query. We
+	 * can't do this in a standalone backend, or if the command will try to
+	 * modify any data, or if this is a cursor operation, or if GUCs are set
+	 * to values that don't permit parallelism, or if parallel-unsafe
+	 * functions are present in the query tree.
+	 *
+	 * For now, we don't try to use parallel mode if we're running inside a
+	 * parallel worker.  We might eventually be able to relax this
+	 * restriction, but for now it seems best not to have parallel workers
+	 * trying to create their own parallel workers.
+	 *
+	 * We can't use parallelism in serializable mode because the predicate
+	 * locking code is not parallel-aware.  It's not catastrophic if someone
+	 * tries to run a parallel plan in serializable mode; it just won't get
+	 * any workers and will run serially.  But it seems like a good heuristic
+	 * to assume that the same serialization level will be in effect at plan
+	 * time and execution time, so don't generate a parallel plan if we're in
+	 * serializable mode.
+	 */
+	if ((cursorOptions & CURSOR_OPT_PARALLEL_OK) != 0 &&
+		IsUnderPostmaster &&
+		dynamic_shared_memory_type != DSM_IMPL_NONE &&
+		parse->commandType == CMD_SELECT &&
+		!parse->hasModifyingCTE &&
+		max_parallel_workers_per_gather > 0 &&
+		!IsParallelWorker() &&
+		!IsolationIsSerializable())
+	{
+		/* all the cheap tests pass, so scan the query tree */
+		glob->maxParallelHazard = max_parallel_hazard(parse);
+		glob->parallelModeOK = (glob->maxParallelHazard != PROPARALLEL_UNSAFE);
+	}
+	else
+	{
+		/* skip the query tree scan, just assume it's unsafe */
+		glob->maxParallelHazard = PROPARALLEL_UNSAFE;
+		glob->parallelModeOK = false;
+	}
+
+	/*
+	 * glob->parallelModeNeeded should tell us whether it's necessary to
+	 * impose the parallel mode restrictions, but we don't actually want to
+	 * impose them unless we choose a parallel plan, so it is normally set
+	 * only if a parallel plan is chosen (see create_gather_plan).  That way,
+	 * people who mislabel their functions but don't use parallelism anyway
+	 * aren't harmed.  But when force_parallel_mode is set, we enable the
+	 * restrictions whenever possible for testing purposes.
+	 */
+	glob->parallelModeNeeded = glob->parallelModeOK &&
+		(force_parallel_mode != FORCE_PARALLEL_OFF);
+
+	/* Determine what fraction of the plan is likely to be scanned */
+	if (cursorOptions & CURSOR_OPT_FAST_PLAN)
+	{
+		/*
+		 * We have no real idea how many tuples the user will ultimately FETCH
+		 * from a cursor, but it is often the case that he doesn't want 'em
+		 * all, or would prefer a fast-start plan anyway so that he can
+		 * process some of the tuples sooner.  Use a GUC parameter to decide
+		 * what fraction to optimize for.
+		 */
+		tuple_fraction = cursor_tuple_fraction;
+
+		/*
+		 * We document cursor_tuple_fraction as simply being a fraction, which
+		 * means the edge cases 0 and 1 have to be treated specially here.  We
+		 * convert 1 to 0 ("all the tuples") and 0 to a very small fraction.
+		 */
+		if (tuple_fraction >= 1.0)
+			tuple_fraction = 0.0;
+		else if (tuple_fraction <= 0.0)
+			tuple_fraction = 1e-10;
+	}
+	else
+	{
+		/* Default assumption is we need all the tuples */
+		tuple_fraction = 0.0;
+	}
+
+	/* primary planning entry point (may recurse for subqueries) */
+	root = subquery_planner(glob, parse, NULL,
+							false, tuple_fraction);
+
+	/* Select best Path and turn it into a Plan */
+	final_rel = fetch_upper_rel(root, UPPERREL_FINAL, NULL);
+	best_path = get_cheapest_fractional_path(final_rel, tuple_fraction);
+
+	top_plan = create_plan(root, best_path);
+
+	/*
+	 * If creating a plan for a scrollable cursor, make sure it can run
+	 * backwards on demand.  Add a Material node at the top at need.
+	 */
+	if (cursorOptions & CURSOR_OPT_SCROLL)
+	{
+		if (!ExecSupportsBackwardScan(top_plan))
+			top_plan = materialize_finished_plan(top_plan);
+	}
+
+	/*
+	 * Optionally add a Gather node for testing purposes, provided this is
+	 * actually a safe thing to do.
+	 */
+	if (force_parallel_mode != FORCE_PARALLEL_OFF && top_plan->parallel_safe)
+	{
+		Gather	   *gather = makeNode(Gather);
+
+		gather->plan.targetlist = top_plan->targetlist;
+		gather->plan.qual = NIL;
+		gather->plan.lefttree = top_plan;
+		gather->plan.righttree = NULL;
+		gather->num_workers = 1;
+		gather->single_copy = true;
+		gather->invisible = (force_parallel_mode == FORCE_PARALLEL_REGRESS);
+
+		/*
+		 * Since this Gather has no parallel-aware descendants to signal to,
+		 * we don't need a rescan Param.
+		 */
+		gather->rescan_param = -1;
+
+		/*
+		 * Ideally we'd use cost_gather here, but setting up dummy path data
+		 * to satisfy it doesn't seem much cleaner than knowing what it does.
+		 */
+		gather->plan.startup_cost = top_plan->startup_cost +
+			parallel_setup_cost;
+		gather->plan.total_cost = top_plan->total_cost +
+			parallel_setup_cost + parallel_tuple_cost * top_plan->plan_rows;
+		gather->plan.plan_rows = top_plan->plan_rows;
+		gather->plan.plan_width = top_plan->plan_width;
+		gather->plan.parallel_aware = false;
+		gather->plan.parallel_safe = false;
+
+		/* use parallel mode for parallel plans. */
+		root->glob->parallelModeNeeded = true;
+
+		top_plan = &gather->plan;
+	}
+
+	/*
+	 * If any Params were generated, run through the plan tree and compute
+	 * each plan node's extParam/allParam sets.  Ideally we'd merge this into
+	 * set_plan_references' tree traversal, but for now it has to be separate
+	 * because we need to visit subplans before not after main plan.
+	 */
+	if (glob->nParamExec > 0)
+	{
+		Assert(list_length(glob->subplans) == list_length(glob->subroots));
+		forboth(lp, glob->subplans, lr, glob->subroots)
+		{
+			Plan	   *subplan = (Plan *) lfirst(lp);
+			PlannerInfo *subroot = (PlannerInfo *) lfirst(lr);
+
+			SS_finalize_plan(subroot, subplan);
+		}
+		SS_finalize_plan(root, top_plan);
+	}
+
+	/* final cleanup of the plan */
+	Assert(glob->finalrtable == NIL);
+	Assert(glob->finalrowmarks == NIL);
+	Assert(glob->resultRelations == NIL);
+	Assert(glob->nonleafResultRelations == NIL);
+	Assert(glob->rootResultRelations == NIL);
+	top_plan = set_plan_references(root, top_plan);
+	/* ... and the subplans (both regular subplans and initplans) */
+	Assert(list_length(glob->subplans) == list_length(glob->subroots));
+	forboth(lp, glob->subplans, lr, glob->subroots)
+	{
+		Plan	   *subplan = (Plan *) lfirst(lp);
+		PlannerInfo *subroot = (PlannerInfo *) lfirst(lr);
+
+		lfirst(lp) = set_plan_references(subroot, subplan);
+	}
+
+	/* build the PlannedStmt result */
+	result = makeNode(PlannedStmt);
+
+	result->commandType = parse->commandType;
+	result->queryId = parse->queryId;
+	result->hasReturning = (parse->returningList != NIL);
+	result->hasModifyingCTE = parse->hasModifyingCTE;
+	result->canSetTag = parse->canSetTag;
+	result->transientPlan = glob->transientPlan;
+	result->dependsOnRole = glob->dependsOnRole;
+	result->parallelModeNeeded = glob->parallelModeNeeded;
+	result->planTree = top_plan;
+	result->rtable = glob->finalrtable;
+	result->resultRelations = glob->resultRelations;
+	result->nonleafResultRelations = glob->nonleafResultRelations;
+	result->rootResultRelations = glob->rootResultRelations;
+	result->subplans = glob->subplans;
+	result->rewindPlanIDs = glob->rewindPlanIDs;
+	result->rowMarks = glob->finalrowmarks;
+	result->relationOids = glob->relationOids;
+	result->invalItems = glob->invalItems;
+	result->nParamExec = glob->nParamExec;
+	/* utilityStmt should be null, but we might as well copy it */
+	result->utilityStmt = parse->utilityStmt;
+	result->stmt_location = parse->stmt_location;
+	result->stmt_len = parse->stmt_len;
+
+	return result;
+}
+
+
+/*--------------------
+ * subquery_planner
+ *	  Invokes the planner on a subquery.  We recurse to here for each
+ *	  sub-SELECT found in the query tree.
+ *
+ * glob is the global state for the current planner run.
+ * parse is the querytree produced by the parser & rewriter.
+ * parent_root is the immediate parent Query's info (NULL at the top level).
+ * hasRecursion is true if this is a recursive WITH query.
+ * tuple_fraction is the fraction of tuples we expect will be retrieved.
+ * tuple_fraction is interpreted as explained for grouping_planner, below.
+ *
+ * Basically, this routine does the stuff that should only be done once
+ * per Query object.  It then calls grouping_planner.  At one time,
+ * grouping_planner could be invoked recursively on the same Query object;
+ * that's not currently true, but we keep the separation between the two
+ * routines anyway, in case we need it again someday.
+ *
+ * subquery_planner will be called recursively to handle sub-Query nodes
+ * found within the query's expressions and rangetable.
+ *
+ * Returns the PlannerInfo struct ("root") that contains all data generated
+ * while planning the subquery.  In particular, the Path(s) attached to
+ * the (UPPERREL_FINAL, NULL) upperrel represent our conclusions about the
+ * cheapest way(s) to implement the query.  The top level will select the
+ * best Path and pass it through createplan.c to produce a finished Plan.
+ *--------------------
+ */
+PlannerInfo *
+subquery_planner(PlannerGlobal *glob, Query *parse,
+				 PlannerInfo *parent_root,
+				 bool hasRecursion, double tuple_fraction)
+{
+	PlannerInfo *root;
+	List	   *newWithCheckOptions;
+	List	   *newHaving;
+	bool		hasOuterJoins;
+	RelOptInfo *final_rel;
+	ListCell   *l;
+
+	/* Create a PlannerInfo data structure for this subquery */
+	root = makeNode(PlannerInfo);
+	root->parse = parse;
+	root->glob = glob;
+	root->query_level = parent_root ? parent_root->query_level + 1 : 1;
+	root->parent_root = parent_root;
+	root->plan_params = NIL;
+	root->outer_params = NULL;
+	root->planner_cxt = CurrentMemoryContext;
+	root->init_plans = NIL;
+	root->cte_plan_ids = NIL;
+	root->multiexpr_params = NIL;
+	root->eq_classes = NIL;
+	root->append_rel_list = NIL;
+	root->pcinfo_list = NIL;
+	root->rowMarks = NIL;
+	memset(root->upper_rels, 0, sizeof(root->upper_rels));
+	memset(root->upper_targets, 0, sizeof(root->upper_targets));
+	root->processed_tlist = NIL;
+	root->grouping_map = NULL;
+	root->minmax_aggs = NIL;
+	root->qual_security_level = 0;
+	root->hasInheritedTarget = false;
+	root->hasRecursion = hasRecursion;
+	if (hasRecursion)
+		root->wt_param_id = SS_assign_special_param(root);
+	else
+		root->wt_param_id = -1;
+	root->non_recursive_path = NULL;
+
+	/*
+	 * If there is a WITH list, process each WITH query and build an initplan
+	 * SubPlan structure for it.
+	 */
+	if (parse->cteList)
+		SS_process_ctes(root);
+
+	/*
+	 * Look for ANY and EXISTS SubLinks in WHERE and JOIN/ON clauses, and try
+	 * to transform them into joins.  Note that this step does not descend
+	 * into subqueries; if we pull up any subqueries below, their SubLinks are
+	 * processed just before pulling them up.
+	 */
+	if (parse->hasSubLinks)
+		pull_up_sublinks(root);
+
+	/*
+	 * Scan the rangetable for set-returning functions, and inline them if
+	 * possible (producing subqueries that might get pulled up next).
+	 * Recursion issues here are handled in the same way as for SubLinks.
+	 */
+	inline_set_returning_functions(root);
+
+	/*
+	 * Check to see if any subqueries in the jointree can be merged into this
+	 * query.
+	 */
+	pull_up_subqueries(root);
+
+	/*
+	 * If this is a simple UNION ALL query, flatten it into an appendrel. We
+	 * do this now because it requires applying pull_up_subqueries to the leaf
+	 * queries of the UNION ALL, which weren't touched above because they
+	 * weren't referenced by the jointree (they will be after we do this).
+	 */
+	if (parse->setOperations)
+		flatten_simple_union_all(root);
+
+	/*
+	 * Detect whether any rangetable entries are RTE_JOIN kind; if not, we can
+	 * avoid the expense of doing flatten_join_alias_vars().  Also check for
+	 * outer joins --- if none, we can skip reduce_outer_joins().  And check
+	 * for LATERAL RTEs, too.  This must be done after we have done
+	 * pull_up_subqueries(), of course.
+	 */
+	root->hasJoinRTEs = false;
+	root->hasLateralRTEs = false;
+	hasOuterJoins = false;
+	foreach(l, parse->rtable)
+	{
+		RangeTblEntry *rte = (RangeTblEntry *) lfirst(l);
+
+		if (rte->rtekind == RTE_JOIN)
+		{
+			root->hasJoinRTEs = true;
+			if (IS_OUTER_JOIN(rte->jointype))
+				hasOuterJoins = true;
+		}
+		if (rte->lateral)
+			root->hasLateralRTEs = true;
+	}
+
+	/*
+	 * Preprocess RowMark information.  We need to do this after subquery
+	 * pullup (so that all non-inherited RTEs are present) and before
+	 * inheritance expansion (so that the info is available for
+	 * expand_inherited_tables to examine and modify).
+	 */
+	preprocess_rowmarks(root);
+
+	/*
+	 * Expand any rangetable entries that are inheritance sets into "append
+	 * relations".  This can add entries to the rangetable, but they must be
+	 * plain base relations not joins, so it's OK (and marginally more
+	 * efficient) to do it after checking for join RTEs.  We must do it after
+	 * pulling up subqueries, else we'd fail to handle inherited tables in
+	 * subqueries.
+	 */
+	expand_inherited_tables(root);
+
+	/*
+	 * Set hasHavingQual to remember if HAVING clause is present.  Needed
+	 * because preprocess_expression will reduce a constant-true condition to
+	 * an empty qual list ... but "HAVING TRUE" is not a semantic no-op.
+	 */
+	root->hasHavingQual = (parse->havingQual != NULL);
+
+	/* Clear this flag; might get set in distribute_qual_to_rels */
+	root->hasPseudoConstantQuals = false;
+
+	/*
+	 * Do expression preprocessing on targetlist and quals, as well as other
+	 * random expressions in the querytree.  Note that we do not need to
+	 * handle sort/group expressions explicitly, because they are actually
+	 * part of the targetlist.
+	 */
+	parse->targetList = (List *)
+		preprocess_expression(root, (Node *) parse->targetList,
+							  EXPRKIND_TARGET);
+
+	/* Constant-folding might have removed all set-returning functions */
+	if (parse->hasTargetSRFs)
+		parse->hasTargetSRFs = expression_returns_set((Node *) parse->targetList);
+
+	newWithCheckOptions = NIL;
+	foreach(l, parse->withCheckOptions)
+	{
+		WithCheckOption *wco = (WithCheckOption *) lfirst(l);
+
+		wco->qual = preprocess_expression(root, wco->qual,
+										  EXPRKIND_QUAL);
+		if (wco->qual != NULL)
+			newWithCheckOptions = lappend(newWithCheckOptions, wco);
+	}
+	parse->withCheckOptions = newWithCheckOptions;
+
+	parse->returningList = (List *)
+		preprocess_expression(root, (Node *) parse->returningList,
+							  EXPRKIND_TARGET);
+
+	preprocess_qual_conditions(root, (Node *) parse->jointree);
+
+	parse->havingQual = preprocess_expression(root, parse->havingQual,
+											  EXPRKIND_QUAL);
+
+	foreach(l, parse->windowClause)
+	{
+		WindowClause *wc = (WindowClause *) lfirst(l);
+
+		/* partitionClause/orderClause are sort/group expressions */
+		wc->startOffset = preprocess_expression(root, wc->startOffset,
+												EXPRKIND_LIMIT);
+		wc->endOffset = preprocess_expression(root, wc->endOffset,
+											  EXPRKIND_LIMIT);
+	}
+
+	parse->limitOffset = preprocess_expression(root, parse->limitOffset,
+											   EXPRKIND_LIMIT);
+	parse->limitCount = preprocess_expression(root, parse->limitCount,
+											  EXPRKIND_LIMIT);
+
+	if (parse->onConflict)
+	{
+		parse->onConflict->arbiterElems = (List *)
+			preprocess_expression(root,
+								  (Node *) parse->onConflict->arbiterElems,
+								  EXPRKIND_ARBITER_ELEM);
+		parse->onConflict->arbiterWhere =
+			preprocess_expression(root,
+								  parse->onConflict->arbiterWhere,
+								  EXPRKIND_QUAL);
+		parse->onConflict->onConflictSet = (List *)
+			preprocess_expression(root,
+								  (Node *) parse->onConflict->onConflictSet,
+								  EXPRKIND_TARGET);
+		parse->onConflict->onConflictWhere =
+			preprocess_expression(root,
+								  parse->onConflict->onConflictWhere,
+								  EXPRKIND_QUAL);
+		/* exclRelTlist contains only Vars, so no preprocessing needed */
+	}
+
+	root->append_rel_list = (List *)
+		preprocess_expression(root, (Node *) root->append_rel_list,
+							  EXPRKIND_APPINFO);
+
+	/* Also need to preprocess expressions within RTEs */
+	foreach(l, parse->rtable)
+	{
+		RangeTblEntry *rte = (RangeTblEntry *) lfirst(l);
+		int			kind;
+		ListCell   *lcsq;
+
+		if (rte->rtekind == RTE_RELATION)
+		{
+			if (rte->tablesample)
+				rte->tablesample = (TableSampleClause *)
+					preprocess_expression(root,
+										  (Node *) rte->tablesample,
+										  EXPRKIND_TABLESAMPLE);
+		}
+		else if (rte->rtekind == RTE_SUBQUERY)
+		{
+			/*
+			 * We don't want to do all preprocessing yet on the subquery's
+			 * expressions, since that will happen when we plan it.  But if it
+			 * contains any join aliases of our level, those have to get
+			 * expanded now, because planning of the subquery won't do it.
+			 * That's only possible if the subquery is LATERAL.
+			 */
+			if (rte->lateral && root->hasJoinRTEs)
+				rte->subquery = (Query *)
+					flatten_join_alias_vars(root, (Node *) rte->subquery);
+		}
+		else if (rte->rtekind == RTE_FUNCTION)
+		{
+			/* Preprocess the function expression(s) fully */
+			kind = rte->lateral ? EXPRKIND_RTFUNC_LATERAL : EXPRKIND_RTFUNC;
+			rte->functions = (List *)
+				preprocess_expression(root, (Node *) rte->functions, kind);
+		}
+		else if (rte->rtekind == RTE_TABLEFUNC)
+		{
+			/* Preprocess the function expression(s) fully */
+			kind = rte->lateral ? EXPRKIND_TABLEFUNC_LATERAL : EXPRKIND_TABLEFUNC;
+			rte->tablefunc = (TableFunc *)
+				preprocess_expression(root, (Node *) rte->tablefunc, kind);
+		}
+		else if (rte->rtekind == RTE_VALUES)
+		{
+			/* Preprocess the values lists fully */
+			kind = rte->lateral ? EXPRKIND_VALUES_LATERAL : EXPRKIND_VALUES;
+			rte->values_lists = (List *)
+				preprocess_expression(root, (Node *) rte->values_lists, kind);
+		}
+
+		/*
+		 * Process each element of the securityQuals list as if it were a
+		 * separate qual expression (as indeed it is).  We need to do it this
+		 * way to get proper canonicalization of AND/OR structure.  Note that
+		 * this converts each element into an implicit-AND sublist.
+		 */
+		foreach(lcsq, rte->securityQuals)
+		{
+			lfirst(lcsq) = preprocess_expression(root,
+												 (Node *) lfirst(lcsq),
+												 EXPRKIND_QUAL);
+		}
+	}
+
+	/*
+	 * Now that we are done preprocessing expressions, and in particular done
+	 * flattening join alias variables, get rid of the joinaliasvars lists.
+	 * They no longer match what expressions in the rest of the tree look
+	 * like, because we have not preprocessed expressions in those lists (and
+	 * do not want to; for example, expanding a SubLink there would result in
+	 * a useless unreferenced subplan).  Leaving them in place simply creates
+	 * a hazard for later scans of the tree.  We could try to prevent that by
+	 * using QTW_IGNORE_JOINALIASES in every tree scan done after this point,
+	 * but that doesn't sound very reliable.
+	 */
+	if (root->hasJoinRTEs)
+	{
+		foreach(l, parse->rtable)
+		{
+			RangeTblEntry *rte = lfirst_node(RangeTblEntry, l);
+
+			rte->joinaliasvars = NIL;
+		}
+	}
+
+	/*
+	 * In some cases we may want to transfer a HAVING clause into WHERE. We
+	 * cannot do so if the HAVING clause contains aggregates (obviously) or
+	 * volatile functions (since a HAVING clause is supposed to be executed
+	 * only once per group).  We also can't do this if there are any nonempty
+	 * grouping sets; moving such a clause into WHERE would potentially change
+	 * the results, if any referenced column isn't present in all the grouping
+	 * sets.  (If there are only empty grouping sets, then the HAVING clause
+	 * must be degenerate as discussed below.)
+	 *
+	 * Also, it may be that the clause is so expensive to execute that we're
+	 * better off doing it only once per group, despite the loss of
+	 * selectivity.  This is hard to estimate short of doing the entire
+	 * planning process twice, so we use a heuristic: clauses containing
+	 * subplans are left in HAVING.  Otherwise, we move or copy the HAVING
+	 * clause into WHERE, in hopes of eliminating tuples before aggregation
+	 * instead of after.
+	 *
+	 * If the query has explicit grouping then we can simply move such a
+	 * clause into WHERE; any group that fails the clause will not be in the
+	 * output because none of its tuples will reach the grouping or
+	 * aggregation stage.  Otherwise we must have a degenerate (variable-free)
+	 * HAVING clause, which we put in WHERE so that query_planner() can use it
+	 * in a gating Result node, but also keep in HAVING to ensure that we
+	 * don't emit a bogus aggregated row. (This could be done better, but it
+	 * seems not worth optimizing.)
+	 *
+	 * Note that both havingQual and parse->jointree->quals are in
+	 * implicitly-ANDed-list form at this point, even though they are declared
+	 * as Node *.
+	 */
+	newHaving = NIL;
+	foreach(l, (List *) parse->havingQual)
+	{
+		Node	   *havingclause = (Node *) lfirst(l);
+
+		if ((parse->groupClause && parse->groupingSets) ||
+			contain_agg_clause(havingclause) ||
+			contain_volatile_functions(havingclause) ||
+			contain_subplans(havingclause))
+		{
+			/* keep it in HAVING */
+			newHaving = lappend(newHaving, havingclause);
+		}
+		else if (parse->groupClause && !parse->groupingSets)
+		{
+			/* move it to WHERE */
+			parse->jointree->quals = (Node *)
+				lappend((List *) parse->jointree->quals, havingclause);
+		}
+		else
+		{
+			/* put a copy in WHERE, keep it in HAVING */
+			parse->jointree->quals = (Node *)
+				lappend((List *) parse->jointree->quals,
+						copyObject(havingclause));
+			newHaving = lappend(newHaving, havingclause);
+		}
+	}
+	parse->havingQual = (Node *) newHaving;
+
+	/* Remove any redundant GROUP BY columns */
+	remove_useless_groupby_columns(root);
+
+	/*
+	 * If we have any outer joins, try to reduce them to plain inner joins.
+	 * This step is most easily done after we've done expression
+	 * preprocessing.
+	 */
+	if (hasOuterJoins)
+		reduce_outer_joins(root);
+
+	/*
+	 * Do the main planning.  If we have an inherited target relation, that
+	 * needs special processing, else go straight to grouping_planner.
+	 */
+	if (parse->resultRelation &&
+		rt_fetch(parse->resultRelation, parse->rtable)->inh)
+		inheritance_planner(root);
+	else
+		grouping_planner(root, false, tuple_fraction);
+
+	/*
+	 * Capture the set of outer-level param IDs we have access to, for use in
+	 * extParam/allParam calculations later.
+	 */
+	SS_identify_outer_params(root);
+
+	/*
+	 * If any initPlans were created in this query level, adjust the surviving
+	 * Paths' costs and parallel-safety flags to account for them.  The
+	 * initPlans won't actually get attached to the plan tree till
+	 * create_plan() runs, but we must include their effects now.
+	 */
+	final_rel = fetch_upper_rel(root, UPPERREL_FINAL, NULL);
+	SS_charge_for_initplans(root, final_rel);
+
+	/*
+	 * Make sure we've identified the cheapest Path for the final rel.  (By
+	 * doing this here not in grouping_planner, we include initPlan costs in
+	 * the decision, though it's unlikely that will change anything.)
+	 */
+	set_cheapest(final_rel);
+
+	return root;
+}
+
+/*
+ * preprocess_expression
+ *		Do subquery_planner's preprocessing work for an expression,
+ *		which can be a targetlist, a WHERE clause (including JOIN/ON
+ *		conditions), a HAVING clause, or a few other things.
+ */
+static Node *
+preprocess_expression(PlannerInfo *root, Node *expr, int kind)
+{
+	/*
+	 * Fall out quickly if expression is empty.  This occurs often enough to
+	 * be worth checking.  Note that null->null is the correct conversion for
+	 * implicit-AND result format, too.
+	 */
+	if (expr == NULL)
+		return NULL;
+
+	/*
+	 * If the query has any join RTEs, replace join alias variables with
+	 * base-relation variables.  We must do this first, since any expressions
+	 * we may extract from the joinaliasvars lists have not been preprocessed.
+	 * For example, if we did this after sublink processing, sublinks expanded
+	 * out from join aliases would not get processed.  But we can skip this in
+	 * non-lateral RTE functions, VALUES lists, and TABLESAMPLE clauses, since
+	 * they can't contain any Vars of the current query level.
+	 */
+	if (root->hasJoinRTEs &&
+		!(kind == EXPRKIND_RTFUNC ||
+		  kind == EXPRKIND_VALUES ||
+		  kind == EXPRKIND_TABLESAMPLE ||
+		  kind == EXPRKIND_TABLEFUNC))
+		expr = flatten_join_alias_vars(root, expr);
+
+	/*
+	 * Simplify constant expressions.
+	 *
+	 * Note: an essential effect of this is to convert named-argument function
+	 * calls to positional notation and insert the current actual values of
+	 * any default arguments for functions.  To ensure that happens, we *must*
+	 * process all expressions here.  Previous PG versions sometimes skipped
+	 * const-simplification if it didn't seem worth the trouble, but we can't
+	 * do that anymore.
+	 *
+	 * Note: this also flattens nested AND and OR expressions into N-argument
+	 * form.  All processing of a qual expression after this point must be
+	 * careful to maintain AND/OR flatness --- that is, do not generate a tree
+	 * with AND directly under AND, nor OR directly under OR.
+	 */
+	expr = eval_const_expressions(root, expr);
+
+	/*
+	 * If it's a qual or havingQual, canonicalize it.
+	 */
+	if (kind == EXPRKIND_QUAL)
+	{
+		expr = (Node *) canonicalize_qual((Expr *) expr);
+
+#ifdef OPTIMIZER_DEBUG
+		printf("After canonicalize_qual()\n");
+		pprint(expr);
+#endif
+	}
+
+	/* Expand SubLinks to SubPlans */
+	if (root->parse->hasSubLinks)
+		expr = SS_process_sublinks(root, expr, (kind == EXPRKIND_QUAL));
+
+	/*
+	 * XXX do not insert anything here unless you have grokked the comments in
+	 * SS_replace_correlation_vars ...
+	 */
+
+	/* Replace uplevel vars with Param nodes (this IS possible in VALUES) */
+	if (root->query_level > 1)
+		expr = SS_replace_correlation_vars(root, expr);
+
+	/*
+	 * If it's a qual or havingQual, convert it to implicit-AND format. (We
+	 * don't want to do this before eval_const_expressions, since the latter
+	 * would be unable to simplify a top-level AND correctly. Also,
+	 * SS_process_sublinks expects explicit-AND format.)
+	 */
+	if (kind == EXPRKIND_QUAL)
+		expr = (Node *) make_ands_implicit((Expr *) expr);
+
+	return expr;
+}
+
+/*
+ * preprocess_qual_conditions
+ *		Recursively scan the query's jointree and do subquery_planner's
+ *		preprocessing work on each qual condition found therein.
+ */
+static void
+preprocess_qual_conditions(PlannerInfo *root, Node *jtnode)
+{
+	if (jtnode == NULL)
+		return;
+	if (IsA(jtnode, RangeTblRef))
+	{
+		/* nothing to do here */
+	}
+	else if (IsA(jtnode, FromExpr))
+	{
+		FromExpr   *f = (FromExpr *) jtnode;
+		ListCell   *l;
+
+		foreach(l, f->fromlist)
+			preprocess_qual_conditions(root, lfirst(l));
+
+		f->quals = preprocess_expression(root, f->quals, EXPRKIND_QUAL);
+	}
+	else if (IsA(jtnode, JoinExpr))
+	{
+		JoinExpr   *j = (JoinExpr *) jtnode;
+
+		preprocess_qual_conditions(root, j->larg);
+		preprocess_qual_conditions(root, j->rarg);
+
+		j->quals = preprocess_expression(root, j->quals, EXPRKIND_QUAL);
+	}
+	else
+		elog(ERROR, "unrecognized node type: %d",
+			 (int) nodeTag(jtnode));
+}
+
+/*
+ * preprocess_phv_expression
+ *	  Do preprocessing on a PlaceHolderVar expression that's been pulled up.
+ *
+ * If a LATERAL subquery references an output of another subquery, and that
+ * output must be wrapped in a PlaceHolderVar because of an intermediate outer
+ * join, then we'll push the PlaceHolderVar expression down into the subquery
+ * and later pull it back up during find_lateral_references, which runs after
+ * subquery_planner has preprocessed all the expressions that were in the
+ * current query level to start with.  So we need to preprocess it then.
+ */
+Expr *
+preprocess_phv_expression(PlannerInfo *root, Expr *expr)
+{
+	return (Expr *) preprocess_expression(root, (Node *) expr, EXPRKIND_PHV);
+}
+
+/*
+ * inheritance_planner
+ *	  Generate Paths in the case where the result relation is an
+ *	  inheritance set.
+ *
+ * We have to handle this case differently from cases where a source relation
+ * is an inheritance set. Source inheritance is expanded at the bottom of the
+ * plan tree (see allpaths.c), but target inheritance has to be expanded at
+ * the top.  The reason is that for UPDATE, each target relation needs a
+ * different targetlist matching its own column set.  Fortunately,
+ * the UPDATE/DELETE target can never be the nullable side of an outer join,
+ * so it's OK to generate the plan this way.
+ *
+ * Returns nothing; the useful output is in the Paths we attach to
+ * the (UPPERREL_FINAL, NULL) upperrel stored in *root.
+ *
+ * Note that we have not done set_cheapest() on the final rel; it's convenient
+ * to leave this to the caller.
+ */
+static void
+inheritance_planner(PlannerInfo *root)
+{
+	Query	   *parse = root->parse;
+	int			parentRTindex = parse->resultRelation;
+	Bitmapset  *subqueryRTindexes;
+	Bitmapset  *modifiableARIindexes;
+	int			nominalRelation = -1;
+	List	   *final_rtable = NIL;
+	int			save_rel_array_size = 0;
+	RelOptInfo **save_rel_array = NULL;
+	List	   *subpaths = NIL;
+	List	   *subroots = NIL;
+	List	   *resultRelations = NIL;
+	List	   *withCheckOptionLists = NIL;
+	List	   *returningLists = NIL;
+	List	   *rowMarks;
+	RelOptInfo *final_rel;
+	ListCell   *lc;
+	Index		rti;
+	RangeTblEntry *parent_rte;
+	List	   *partitioned_rels = NIL;
+
+	Assert(parse->commandType != CMD_INSERT);
+
+	/*
+	 * We generate a modified instance of the original Query for each target
+	 * relation, plan that, and put all the plans into a list that will be
+	 * controlled by a single ModifyTable node.  All the instances share the
+	 * same rangetable, but each instance must have its own set of subquery
+	 * RTEs within the finished rangetable because (1) they are likely to get
+	 * scribbled on during planning, and (2) it's not inconceivable that
+	 * subqueries could get planned differently in different cases.  We need
+	 * not create duplicate copies of other RTE kinds, in particular not the
+	 * target relations, because they don't have either of those issues.  Not
+	 * having to duplicate the target relations is important because doing so
+	 * (1) would result in a rangetable of length O(N^2) for N targets, with
+	 * at least O(N^3) work expended here; and (2) would greatly complicate
+	 * management of the rowMarks list.
+	 *
+	 * To begin with, generate a bitmapset of the relids of the subquery RTEs.
+	 */
+	subqueryRTindexes = NULL;
+	rti = 1;
+	foreach(lc, parse->rtable)
+	{
+		RangeTblEntry *rte = (RangeTblEntry *) lfirst(lc);
+
+		if (rte->rtekind == RTE_SUBQUERY)
+			subqueryRTindexes = bms_add_member(subqueryRTindexes, rti);
+		rti++;
+	}
+
+	/*
+	 * Next, we want to identify which AppendRelInfo items contain references
+	 * to any of the aforesaid subquery RTEs.  These items will need to be
+	 * copied and modified to adjust their subquery references; whereas the
+	 * other ones need not be touched.  It's worth being tense over this
+	 * because we can usually avoid processing most of the AppendRelInfo
+	 * items, thereby saving O(N^2) space and time when the target is a large
+	 * inheritance tree.  We can identify AppendRelInfo items by their
+	 * child_relid, since that should be unique within the list.
+	 */
+	modifiableARIindexes = NULL;
+	if (subqueryRTindexes != NULL)
+	{
+		foreach(lc, root->append_rel_list)
+		{
+			AppendRelInfo *appinfo = (AppendRelInfo *) lfirst(lc);
+
+			if (bms_is_member(appinfo->parent_relid, subqueryRTindexes) ||
+				bms_is_member(appinfo->child_relid, subqueryRTindexes) ||
+				bms_overlap(pull_varnos((Node *) appinfo->translated_vars),
+							subqueryRTindexes))
+				modifiableARIindexes = bms_add_member(modifiableARIindexes,
+													  appinfo->child_relid);
+		}
+	}
+
+	/*
+	 * If the parent RTE is a partitioned table, we should use that as the
+	 * nominal relation, because the RTEs added for partitioned tables
+	 * (including the root parent) as child members of the inheritance set do
+	 * not appear anywhere else in the plan.  The situation is exactly the
+	 * opposite in the case of non-partitioned inheritance parent as described
+	 * below.
+	 */
+	parent_rte = rt_fetch(parentRTindex, root->parse->rtable);
+	if (parent_rte->relkind == RELKIND_PARTITIONED_TABLE)
+		nominalRelation = parentRTindex;
+
+	/*
+	 * And now we can get on with generating a plan for each child table.
+	 */
+	foreach(lc, root->append_rel_list)
+	{
+		AppendRelInfo *appinfo = (AppendRelInfo *) lfirst(lc);
+		PlannerInfo *subroot;
+		RangeTblEntry *child_rte;
+		RelOptInfo *sub_final_rel;
+		Path	   *subpath;
+
+		/* append_rel_list contains all append rels; ignore others */
+		if (appinfo->parent_relid != parentRTindex)
+			continue;
+
+		/*
+		 * We need a working copy of the PlannerInfo so that we can control
+		 * propagation of information back to the main copy.
+		 */
+		subroot = makeNode(PlannerInfo);
+		memcpy(subroot, root, sizeof(PlannerInfo));
+
+		/*
+		 * Generate modified query with this rel as target.  We first apply
+		 * adjust_appendrel_attrs, which copies the Query and changes
+		 * references to the parent RTE to refer to the current child RTE,
+		 * then fool around with subquery RTEs.
+		 */
+		subroot->parse = (Query *)
+			adjust_appendrel_attrs(root,
+								   (Node *) parse,
+								   appinfo);
+
+		/*
+		 * If there are securityQuals attached to the parent, move them to the
+		 * child rel (they've already been transformed properly for that).
+		 */
+		parent_rte = rt_fetch(parentRTindex, subroot->parse->rtable);
+		child_rte = rt_fetch(appinfo->child_relid, subroot->parse->rtable);
+		child_rte->securityQuals = parent_rte->securityQuals;
+		parent_rte->securityQuals = NIL;
+
+		/*
+		 * The rowMarks list might contain references to subquery RTEs, so
+		 * make a copy that we can apply ChangeVarNodes to.  (Fortunately, the
+		 * executor doesn't need to see the modified copies --- we can just
+		 * pass it the original rowMarks list.)
+		 */
+		subroot->rowMarks = copyObject(root->rowMarks);
+
+		/*
+		 * The append_rel_list likewise might contain references to subquery
+		 * RTEs (if any subqueries were flattenable UNION ALLs).  So prepare
+		 * to apply ChangeVarNodes to that, too.  As explained above, we only
+		 * want to copy items that actually contain such references; the rest
+		 * can just get linked into the subroot's append_rel_list.
+		 *
+		 * If we know there are no such references, we can just use the outer
+		 * append_rel_list unmodified.
+		 */
+		if (modifiableARIindexes != NULL)
+		{
+			ListCell   *lc2;
+
+			subroot->append_rel_list = NIL;
+			foreach(lc2, root->append_rel_list)
+			{
+				AppendRelInfo *appinfo2 = (AppendRelInfo *) lfirst(lc2);
+
+				if (bms_is_member(appinfo2->child_relid, modifiableARIindexes))
+					appinfo2 = copyObject(appinfo2);
+
+				subroot->append_rel_list = lappend(subroot->append_rel_list,
+												   appinfo2);
+			}
+		}
+
+		/*
+		 * Add placeholders to the child Query's rangetable list to fill the
+		 * RT indexes already reserved for subqueries in previous children.
+		 * These won't be referenced, so there's no need to make them very
+		 * valid-looking.
+		 */
+		while (list_length(subroot->parse->rtable) < list_length(final_rtable))
+			subroot->parse->rtable = lappend(subroot->parse->rtable,
+											 makeNode(RangeTblEntry));
+
+		/*
+		 * If this isn't the first child Query, generate duplicates of all
+		 * subquery RTEs, and adjust Var numbering to reference the
+		 * duplicates. To simplify the loop logic, we scan the original rtable
+		 * not the copy just made by adjust_appendrel_attrs; that should be OK
+		 * since subquery RTEs couldn't contain any references to the target
+		 * rel.
+		 */
+		if (final_rtable != NIL && subqueryRTindexes != NULL)
+		{
+			ListCell   *lr;
+
+			rti = 1;
+			foreach(lr, parse->rtable)
+			{
+				RangeTblEntry *rte = (RangeTblEntry *) lfirst(lr);
+
+				if (bms_is_member(rti, subqueryRTindexes))
+				{
+					Index		newrti;
+
+					/*
+					 * The RTE can't contain any references to its own RT
+					 * index, except in its securityQuals, so we can save a
+					 * few cycles by applying ChangeVarNodes to the rest of
+					 * the rangetable before we append the RTE to it.
+					 */
+					newrti = list_length(subroot->parse->rtable) + 1;
+					ChangeVarNodes((Node *) subroot->parse, rti, newrti, 0);
+					ChangeVarNodes((Node *) subroot->rowMarks, rti, newrti, 0);
+					/* Skip processing unchanging parts of append_rel_list */
+					if (modifiableARIindexes != NULL)
+					{
+						ListCell   *lc2;
+
+						foreach(lc2, subroot->append_rel_list)
+						{
+							AppendRelInfo *appinfo2 = (AppendRelInfo *) lfirst(lc2);
+
+							if (bms_is_member(appinfo2->child_relid,
+											  modifiableARIindexes))
+								ChangeVarNodes((Node *) appinfo2, rti, newrti, 0);
+						}
+					}
+					rte = copyObject(rte);
+					ChangeVarNodes((Node *) rte->securityQuals, rti, newrti, 0);
+					subroot->parse->rtable = lappend(subroot->parse->rtable,
+													 rte);
+				}
+				rti++;
+			}
+		}
+
+		/* There shouldn't be any OJ info to translate, as yet */
+		Assert(subroot->join_info_list == NIL);
+		/* and we haven't created PlaceHolderInfos, either */
+		Assert(subroot->placeholder_list == NIL);
+		/* hack to mark target relation as an inheritance partition */
+		subroot->hasInheritedTarget = true;
+
+		/* Generate Path(s) for accessing this result relation */
+		grouping_planner(subroot, true, 0.0 /* retrieve all tuples */ );
+
+		/*
+		 * Set the nomimal target relation of the ModifyTable node if not
+		 * already done.  We use the inheritance parent RTE as the nominal
+		 * target relation if it's a partitioned table (see just above this
+		 * loop).  In the non-partitioned parent case, we'll use the first
+		 * child relation (even if it's excluded) as the nominal target
+		 * relation.  Because of the way expand_inherited_rtentry works, the
+		 * latter should be the RTE representing the parent table in its role
+		 * as a simple member of the inheritance set.
+		 *
+		 * It would be logically cleaner to *always* use the inheritance
+		 * parent RTE as the nominal relation; but that RTE is not otherwise
+		 * referenced in the plan in the non-partitioned inheritance case.
+		 * Instead the duplicate child RTE created by expand_inherited_rtentry
+		 * is used elsewhere in the plan, so using the original parent RTE
+		 * would give rise to confusing use of multiple aliases in EXPLAIN
+		 * output for what the user will think is the "same" table.  OTOH,
+		 * it's not a problem in the partitioned inheritance case, because the
+		 * duplicate child RTE added for the parent does not appear anywhere
+		 * else in the plan tree.
+		 */
+		if (nominalRelation < 0)
+			nominalRelation = appinfo->child_relid;
+
+		/*
+		 * Select cheapest path in case there's more than one.  We always run
+		 * modification queries to conclusion, so we care only for the
+		 * cheapest-total path.
+		 */
+		sub_final_rel = fetch_upper_rel(subroot, UPPERREL_FINAL, NULL);
+		set_cheapest(sub_final_rel);
+		subpath = sub_final_rel->cheapest_total_path;
+
+		/*
+		 * If this child rel was excluded by constraint exclusion, exclude it
+		 * from the result plan.
+		 */
+		if (IS_DUMMY_PATH(subpath))
+			continue;
+
+		/*
+		 * If this is the first non-excluded child, its post-planning rtable
+		 * becomes the initial contents of final_rtable; otherwise, append
+		 * just its modified subquery RTEs to final_rtable.
+		 */
+		if (final_rtable == NIL)
+			final_rtable = subroot->parse->rtable;
+		else
+			final_rtable = list_concat(final_rtable,
+									   list_copy_tail(subroot->parse->rtable,
+													  list_length(final_rtable)));
+
+		/*
+		 * We need to collect all the RelOptInfos from all child plans into
+		 * the main PlannerInfo, since setrefs.c will need them.  We use the
+		 * last child's simple_rel_array (previous ones are too short), so we
+		 * have to propagate forward the RelOptInfos that were already built
+		 * in previous children.
+		 */
+		Assert(subroot->simple_rel_array_size >= save_rel_array_size);
+		for (rti = 1; rti < save_rel_array_size; rti++)
+		{
+			RelOptInfo *brel = save_rel_array[rti];
+
+			if (brel)
+				subroot->simple_rel_array[rti] = brel;
+		}
+		save_rel_array_size = subroot->simple_rel_array_size;
+		save_rel_array = subroot->simple_rel_array;
+
+		/* Make sure any initplans from this rel get into the outer list */
+		root->init_plans = subroot->init_plans;
+
+		/* Build list of sub-paths */
+		subpaths = lappend(subpaths, subpath);
+
+		/* Build list of modified subroots, too */
+		subroots = lappend(subroots, subroot);
+
+		/* Build list of target-relation RT indexes */
+		resultRelations = lappend_int(resultRelations, appinfo->child_relid);
+
+		/* Build lists of per-relation WCO and RETURNING targetlists */
+		if (parse->withCheckOptions)
+			withCheckOptionLists = lappend(withCheckOptionLists,
+										   subroot->parse->withCheckOptions);
+		if (parse->returningList)
+			returningLists = lappend(returningLists,
+									 subroot->parse->returningList);
+
+		Assert(!parse->onConflict);
+	}
+
+	if (parent_rte->relkind == RELKIND_PARTITIONED_TABLE)
+	{
+		partitioned_rels = get_partitioned_child_rels(root, parentRTindex);
+		/* The root partitioned table is included as a child rel */
+		Assert(list_length(partitioned_rels) >= 1);
+	}
+
+	/* Result path must go into outer query's FINAL upperrel */
+	final_rel = fetch_upper_rel(root, UPPERREL_FINAL, NULL);
+
+	/*
+	 * We don't currently worry about setting final_rel's consider_parallel
+	 * flag in this case, nor about allowing FDWs or create_upper_paths_hook
+	 * to get control here.
+	 */
+
+	/*
+	 * If we managed to exclude every child rel, return a dummy plan; it
+	 * doesn't even need a ModifyTable node.
+	 */
+	if (subpaths == NIL)
+	{
+		set_dummy_rel_pathlist(final_rel);
+		return;
+	}
+
+	/*
+	 * Put back the final adjusted rtable into the master copy of the Query.
+	 * (We mustn't do this if we found no non-excluded children.)
+	 */
+	parse->rtable = final_rtable;
+	root->simple_rel_array_size = save_rel_array_size;
+	root->simple_rel_array = save_rel_array;
+	/* Must reconstruct master's simple_rte_array, too */
+	root->simple_rte_array = (RangeTblEntry **)
+		palloc0((list_length(final_rtable) + 1) * sizeof(RangeTblEntry *));
+	rti = 1;
+	foreach(lc, final_rtable)
+	{
+		RangeTblEntry *rte = (RangeTblEntry *) lfirst(lc);
+
+		root->simple_rte_array[rti++] = rte;
+	}
+
+	/*
+	 * If there was a FOR [KEY] UPDATE/SHARE clause, the LockRows node will
+	 * have dealt with fetching non-locked marked rows, else we need to have
+	 * ModifyTable do that.
+	 */
+	if (parse->rowMarks)
+		rowMarks = NIL;
+	else
+		rowMarks = root->rowMarks;
+
+	/* Create Path representing a ModifyTable to do the UPDATE/DELETE work */
+	add_path(final_rel, (Path *)
+			 create_modifytable_path(root, final_rel,
+									 parse->commandType,
+									 parse->canSetTag,
+									 nominalRelation,
+									 partitioned_rels,
+									 resultRelations,
+									 subpaths,
+									 subroots,
+									 withCheckOptionLists,
+									 returningLists,
+									 rowMarks,
+									 NULL,
+									 SS_assign_special_param(root)));
+}
+
+/*--------------------
+ * grouping_planner
+ *	  Perform planning steps related to grouping, aggregation, etc.
+ *
+ * This function adds all required top-level processing to the scan/join
+ * Path(s) produced by query_planner.
+ *
+ * If inheritance_update is true, we're being called from inheritance_planner
+ * and should not include a ModifyTable step in the resulting Path(s).
+ * (inheritance_planner will create a single ModifyTable node covering all the
+ * target tables.)
+ *
+ * tuple_fraction is the fraction of tuples we expect will be retrieved.
+ * tuple_fraction is interpreted as follows:
+ *	  0: expect all tuples to be retrieved (normal case)
+ *	  0 < tuple_fraction < 1: expect the given fraction of tuples available
+ *		from the plan to be retrieved
+ *	  tuple_fraction >= 1: tuple_fraction is the absolute number of tuples
+ *		expected to be retrieved (ie, a LIMIT specification)
+ *
+ * Returns nothing; the useful output is in the Paths we attach to the
+ * (UPPERREL_FINAL, NULL) upperrel in *root.  In addition,
+ * root->processed_tlist contains the final processed targetlist.
+ *
+ * Note that we have not done set_cheapest() on the final rel; it's convenient
+ * to leave this to the caller.
+ *--------------------
+ */
+static void
+grouping_planner(PlannerInfo *root, bool inheritance_update,
+				 double tuple_fraction)
+{
+	Query	   *parse = root->parse;
+	List	   *tlist = parse->targetList;
+	int64		offset_est = 0;
+	int64		count_est = 0;
+	double		limit_tuples = -1.0;
+	bool		have_postponed_srfs = false;
+	PathTarget *final_target;
+	List	   *final_targets;
+	List	   *final_targets_contain_srfs;
+	RelOptInfo *current_rel;
+	RelOptInfo *final_rel;
+	ListCell   *lc;
+
+	/* Tweak caller-supplied tuple_fraction if have LIMIT/OFFSET */
+	if (parse->limitCount || parse->limitOffset)
+	{
+		tuple_fraction = preprocess_limit(root, tuple_fraction,
+										  &offset_est, &count_est);
+
+		/*
+		 * If we have a known LIMIT, and don't have an unknown OFFSET, we can
+		 * estimate the effects of using a bounded sort.
+		 */
+		if (count_est > 0 && offset_est >= 0)
+			limit_tuples = (double) count_est + (double) offset_est;
+	}
+
+	/* Make tuple_fraction accessible to lower-level routines */
+	root->tuple_fraction = tuple_fraction;
+
+	if (parse->setOperations)
+	{
+		/*
+		 * If there's a top-level ORDER BY, assume we have to fetch all the
+		 * tuples.  This might be too simplistic given all the hackery below
+		 * to possibly avoid the sort; but the odds of accurate estimates here
+		 * are pretty low anyway.  XXX try to get rid of this in favor of
+		 * letting plan_set_operations generate both fast-start and
+		 * cheapest-total paths.
+		 */
+		if (parse->sortClause)
+			root->tuple_fraction = 0.0;
+
+		/*
+		 * Construct Paths for set operations.  The results will not need any
+		 * work except perhaps a top-level sort and/or LIMIT.  Note that any
+		 * special work for recursive unions is the responsibility of
+		 * plan_set_operations.
+		 */
+		current_rel = plan_set_operations(root);
+
+		/*
+		 * We should not need to call preprocess_targetlist, since we must be
+		 * in a SELECT query node.  Instead, use the targetlist returned by
+		 * plan_set_operations (since this tells whether it returned any
+		 * resjunk columns!), and transfer any sort key information from the
+		 * original tlist.
+		 */
+		Assert(parse->commandType == CMD_SELECT);
+
+		tlist = root->processed_tlist;	/* from plan_set_operations */
+
+		/* for safety, copy processed_tlist instead of modifying in-place */
+		tlist = postprocess_setop_tlist(copyObject(tlist), parse->targetList);
+
+		/* Save aside the final decorated tlist */
+		root->processed_tlist = tlist;
+
+		/* Also extract the PathTarget form of the setop result tlist */
+		final_target = current_rel->cheapest_total_path->pathtarget;
+
+		/* The setop result tlist couldn't contain any SRFs */
+		Assert(!parse->hasTargetSRFs);
+		final_targets = final_targets_contain_srfs = NIL;
+
+		/*
+		 * Can't handle FOR [KEY] UPDATE/SHARE here (parser should have
+		 * checked already, but let's make sure).
+		 */
+		if (parse->rowMarks)
+			ereport(ERROR,
+					(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
+			/*------
+			  translator: %s is a SQL row locking clause such as FOR UPDATE */
+					 errmsg("%s is not allowed with UNION/INTERSECT/EXCEPT",
+							LCS_asString(((RowMarkClause *)
+										  linitial(parse->rowMarks))->strength))));
+
+		/*
+		 * Calculate pathkeys that represent result ordering requirements
+		 */
+		Assert(parse->distinctClause == NIL);
+		root->sort_pathkeys = make_pathkeys_for_sortclauses(root,
+															parse->sortClause,
+															tlist);
+	}
+	else
+	{
+		/* No set operations, do regular planning */
+		PathTarget *sort_input_target;
+		List	   *sort_input_targets;
+		List	   *sort_input_targets_contain_srfs;
+		PathTarget *grouping_target;
+		List	   *grouping_targets;
+		List	   *grouping_targets_contain_srfs;
+		PathTarget *scanjoin_target;
+		List	   *scanjoin_targets;
+		List	   *scanjoin_targets_contain_srfs;
+		bool		have_grouping;
+		AggClauseCosts agg_costs;
+		WindowFuncLists *wflists = NULL;
+		List	   *activeWindows = NIL;
+		grouping_sets_data *gset_data = NULL;
+		standard_qp_extra qp_extra;
+
+		/* A recursive query should always have setOperations */
+		Assert(!root->hasRecursion);
+
+		/* Preprocess grouping sets and GROUP BY clause, if any */
+		if (parse->groupingSets)
+		{
+			gset_data = preprocess_grouping_sets(root);
+		}
+		else
+		{
+			/* Preprocess regular GROUP BY clause, if any */
+			if (parse->groupClause)
+				parse->groupClause = preprocess_groupclause(root, NIL);
+		}
+
+		/* Preprocess targetlist */
+		tlist = preprocess_targetlist(root, tlist);
+
+		if (parse->onConflict)
+			parse->onConflict->onConflictSet =
+				preprocess_onconflict_targetlist(parse->onConflict->onConflictSet,
+												 parse->resultRelation,
+												 parse->rtable);
+
+		/*
+		 * We are now done hacking up the query's targetlist.  Most of the
+		 * remaining planning work will be done with the PathTarget
+		 * representation of tlists, but save aside the full representation so
+		 * that we can transfer its decoration (resnames etc) to the topmost
+		 * tlist of the finished Plan.
+		 */
+		root->processed_tlist = tlist;
+
+		/*
+		 * Collect statistics about aggregates for estimating costs, and mark
+		 * all the aggregates with resolved aggtranstypes.  We must do this
+		 * before slicing and dicing the tlist into various pathtargets, else
+		 * some copies of the Aggref nodes might escape being marked with the
+		 * correct transtypes.
+		 *
+		 * Note: currently, we do not detect duplicate aggregates here.  This
+		 * may result in somewhat-overestimated cost, which is fine for our
+		 * purposes since all Paths will get charged the same.  But at some
+		 * point we might wish to do that detection in the planner, rather
+		 * than during executor startup.
+		 */
+		MemSet(&agg_costs, 0, sizeof(AggClauseCosts));
+		if (parse->hasAggs)
+		{
+			get_agg_clause_costs(root, (Node *) tlist, AGGSPLIT_SIMPLE,
+								 &agg_costs);
+			get_agg_clause_costs(root, parse->havingQual, AGGSPLIT_SIMPLE,
+								 &agg_costs);
+		}
+
+		/*
+		 * Locate any window functions in the tlist.  (We don't need to look
+		 * anywhere else, since expressions used in ORDER BY will be in there
+		 * too.)  Note that they could all have been eliminated by constant
+		 * folding, in which case we don't need to do any more work.
+		 */
+		if (parse->hasWindowFuncs)
+		{
+			wflists = find_window_functions((Node *) tlist,
+											list_length(parse->windowClause));
+			if (wflists->numWindowFuncs > 0)
+				activeWindows = select_active_windows(root, wflists);
+			else
+				parse->hasWindowFuncs = false;
+		}
+
+		/*
+		 * Preprocess MIN/MAX aggregates, if any.  Note: be careful about
+		 * adding logic between here and the query_planner() call.  Anything
+		 * that is needed in MIN/MAX-optimizable cases will have to be
+		 * duplicated in planagg.c.
+		 */
+		if (parse->hasAggs)
+			preprocess_minmax_aggregates(root, tlist);
+
+		/*
+		 * Figure out whether there's a hard limit on the number of rows that
+		 * query_planner's result subplan needs to return.  Even if we know a
+		 * hard limit overall, it doesn't apply if the query has any
+		 * grouping/aggregation operations, or SRFs in the tlist.
+		 */
+		if (parse->groupClause ||
+			parse->groupingSets ||
+			parse->distinctClause ||
+			parse->hasAggs ||
+			parse->hasWindowFuncs ||
+			parse->hasTargetSRFs ||
+			root->hasHavingQual)
+			root->limit_tuples = -1.0;
+		else
+			root->limit_tuples = limit_tuples;
+
+		/* Set up data needed by standard_qp_callback */
+		qp_extra.tlist = tlist;
+		qp_extra.activeWindows = activeWindows;
+		qp_extra.groupClause = (gset_data
+								? (gset_data->rollups ? ((RollupData *) linitial(gset_data->rollups))->groupClause : NIL)
+								: parse->groupClause);
+
+		/*
+		 * Generate the best unsorted and presorted paths for the scan/join
+		 * portion of this Query, ie the processing represented by the
+		 * FROM/WHERE clauses.  (Note there may not be any presorted paths.)
+		 * We also generate (in standard_qp_callback) pathkey representations
+		 * of the query's sort clause, distinct clause, etc.
+		 */
+		current_rel = query_planner(root, tlist,
+									standard_qp_callback, &qp_extra);
+
+		/*
+		 * Convert the query's result tlist into PathTarget format.
+		 *
+		 * Note: it's desirable to not do this till after query_planner(),
+		 * because the target width estimates can use per-Var width numbers
+		 * that were obtained within query_planner().
+		 */
+		final_target = create_pathtarget(root, tlist);
+
+		/*
+		 * If ORDER BY was given, consider whether we should use a post-sort
+		 * projection, and compute the adjusted target for preceding steps if
+		 * so.
+		 */
+		if (parse->sortClause)
+			sort_input_target = make_sort_input_target(root,
+													   final_target,
+													   &have_postponed_srfs);
+		else
+			sort_input_target = final_target;
+
+		/*
+		 * If we have window functions to deal with, the output from any
+		 * grouping step needs to be what the window functions want;
+		 * otherwise, it should be sort_input_target.
+		 */
+		if (activeWindows)
+			grouping_target = make_window_input_target(root,
+													   final_target,
+													   activeWindows);
+		else
+			grouping_target = sort_input_target;
+
+		/*
+		 * If we have grouping or aggregation to do, the topmost scan/join
+		 * plan node must emit what the grouping step wants; otherwise, it
+		 * should emit grouping_target.
+		 */
+		have_grouping = (parse->groupClause || parse->groupingSets ||
+						 parse->hasAggs || root->hasHavingQual);
+		if (have_grouping)
+			scanjoin_target = make_group_input_target(root, final_target);
+		else
+			scanjoin_target = grouping_target;
+
+		/*
+		 * If there are any SRFs in the targetlist, we must separate each of
+		 * these PathTargets into SRF-computing and SRF-free targets.  Replace
+		 * each of the named targets with a SRF-free version, and remember the
+		 * list of additional projection steps we need to add afterwards.
+		 */
+		if (parse->hasTargetSRFs)
+		{
+			/* final_target doesn't recompute any SRFs in sort_input_target */
+			split_pathtarget_at_srfs(root, final_target, sort_input_target,
+									 &final_targets,
+									 &final_targets_contain_srfs);
+			final_target = (PathTarget *) linitial(final_targets);
+			Assert(!linitial_int(final_targets_contain_srfs));
+			/* likewise for sort_input_target vs. grouping_target */
+			split_pathtarget_at_srfs(root, sort_input_target, grouping_target,
+									 &sort_input_targets,
+									 &sort_input_targets_contain_srfs);
+			sort_input_target = (PathTarget *) linitial(sort_input_targets);
+			Assert(!linitial_int(sort_input_targets_contain_srfs));
+			/* likewise for grouping_target vs. scanjoin_target */
+			split_pathtarget_at_srfs(root, grouping_target, scanjoin_target,
+									 &grouping_targets,
+									 &grouping_targets_contain_srfs);
+			grouping_target = (PathTarget *) linitial(grouping_targets);
+			Assert(!linitial_int(grouping_targets_contain_srfs));
+			/* scanjoin_target will not have any SRFs precomputed for it */
+			split_pathtarget_at_srfs(root, scanjoin_target, NULL,
+									 &scanjoin_targets,
+									 &scanjoin_targets_contain_srfs);
+			scanjoin_target = (PathTarget *) linitial(scanjoin_targets);
+			Assert(!linitial_int(scanjoin_targets_contain_srfs));
+		}
+		else
+		{
+			/* initialize lists, just to keep compiler quiet */
+			final_targets = final_targets_contain_srfs = NIL;
+			sort_input_targets = sort_input_targets_contain_srfs = NIL;
+			grouping_targets = grouping_targets_contain_srfs = NIL;
+			scanjoin_targets = scanjoin_targets_contain_srfs = NIL;
+		}
+
+		/*
+		 * Forcibly apply SRF-free scan/join target to all the Paths for the
+		 * scan/join rel.
+		 *
+		 * In principle we should re-run set_cheapest() here to identify the
+		 * cheapest path, but it seems unlikely that adding the same tlist
+		 * eval costs to all the paths would change that, so we don't bother.
+		 * Instead, just assume that the cheapest-startup and cheapest-total
+		 * paths remain so.  (There should be no parameterized paths anymore,
+		 * so we needn't worry about updating cheapest_parameterized_paths.)
+		 */
+		foreach(lc, current_rel->pathlist)
+		{
+			Path	   *subpath = (Path *) lfirst(lc);
+			Path	   *path;
+
+			Assert(subpath->param_info == NULL);
+			path = apply_projection_to_path(root, current_rel,
+											subpath, scanjoin_target);
+			/* If we had to add a Result, path is different from subpath */
+			if (path != subpath)
+			{
+				lfirst(lc) = path;
+				if (subpath == current_rel->cheapest_startup_path)
+					current_rel->cheapest_startup_path = path;
+				if (subpath == current_rel->cheapest_total_path)
+					current_rel->cheapest_total_path = path;
+			}
+		}
+
+		/*
+		 * Upper planning steps which make use of the top scan/join rel's
+		 * partial pathlist will expect partial paths for that rel to produce
+		 * the same output as complete paths ... and we just changed the
+		 * output for the complete paths, so we'll need to do the same thing
+		 * for partial paths.  But only parallel-safe expressions can be
+		 * computed by partial paths.
+		 */
+		if (current_rel->partial_pathlist &&
+			is_parallel_safe(root, (Node *) scanjoin_target->exprs))
+		{
+			/* Apply the scan/join target to each partial path */
+			foreach(lc, current_rel->partial_pathlist)
+			{
+				Path	   *subpath = (Path *) lfirst(lc);
+				Path	   *newpath;
+
+				/* Shouldn't have any parameterized paths anymore */
+				Assert(subpath->param_info == NULL);
+
+				/*
+				 * Don't use apply_projection_to_path() here, because there
+				 * could be other pointers to these paths, and therefore we
+				 * mustn't modify them in place.
+				 */
+				newpath = (Path *) create_projection_path(root,
+														  current_rel,
+														  subpath,
+														  scanjoin_target);
+				lfirst(lc) = newpath;
+			}
+		}
+		else
+		{
+			/*
+			 * In the unfortunate event that scanjoin_target is not
+			 * parallel-safe, we can't apply it to the partial paths; in that
+			 * case, we'll need to forget about the partial paths, which
+			 * aren't valid input for upper planning steps.
+			 */
+			current_rel->partial_pathlist = NIL;
+		}
+
+		/* Now fix things up if scan/join target contains SRFs */
+		if (parse->hasTargetSRFs)
+			adjust_paths_for_srfs(root, current_rel,
+								  scanjoin_targets,
+								  scanjoin_targets_contain_srfs);
+
+		/*
+		 * Save the various upper-rel PathTargets we just computed into
+		 * root->upper_targets[].  The core code doesn't use this, but it
+		 * provides a convenient place for extensions to get at the info.  For
+		 * consistency, we save all the intermediate targets, even though some
+		 * of the corresponding upperrels might not be needed for this query.
+		 */
+		root->upper_targets[UPPERREL_FINAL] = final_target;
+		root->upper_targets[UPPERREL_WINDOW] = sort_input_target;
+		root->upper_targets[UPPERREL_GROUP_AGG] = grouping_target;
+
+		/*
+		 * If we have grouping and/or aggregation, consider ways to implement
+		 * that.  We build a new upperrel representing the output of this
+		 * phase.
+		 */
+		if (have_grouping)
+		{
+			current_rel = create_grouping_paths(root,
+												current_rel,
+												grouping_target,
+												&agg_costs,
+												gset_data);
+			/* Fix things up if grouping_target contains SRFs */
+			if (parse->hasTargetSRFs)
+				adjust_paths_for_srfs(root, current_rel,
+									  grouping_targets,
+									  grouping_targets_contain_srfs);
+		}
+
+		/*
+		 * If we have window functions, consider ways to implement those.  We
+		 * build a new upperrel representing the output of this phase.
+		 */
+		if (activeWindows)
+		{
+			current_rel = create_window_paths(root,
+											  current_rel,
+											  grouping_target,
+											  sort_input_target,
+											  tlist,
+											  wflists,
+											  activeWindows);
+			/* Fix things up if sort_input_target contains SRFs */
+			if (parse->hasTargetSRFs)
+				adjust_paths_for_srfs(root, current_rel,
+									  sort_input_targets,
+									  sort_input_targets_contain_srfs);
+		}
+
+		/*
+		 * If there is a DISTINCT clause, consider ways to implement that. We
+		 * build a new upperrel representing the output of this phase.
+		 */
+		if (parse->distinctClause)
+		{
+			current_rel = create_distinct_paths(root,
+												current_rel);
+		}
+	}							/* end of if (setOperations) */
+
+	/*
+	 * If ORDER BY was given, consider ways to implement that, and generate a
+	 * new upperrel containing only paths that emit the correct ordering and
+	 * project the correct final_target.  We can apply the original
+	 * limit_tuples limit in sort costing here, but only if there are no
+	 * postponed SRFs.
+	 */
+	if (parse->sortClause)
+	{
+		current_rel = create_ordered_paths(root,
+										   current_rel,
+										   final_target,
+										   have_postponed_srfs ? -1.0 :
+										   limit_tuples);
+		/* Fix things up if final_target contains SRFs */
+		if (parse->hasTargetSRFs)
+			adjust_paths_for_srfs(root, current_rel,
+								  final_targets,
+								  final_targets_contain_srfs);
+	}
+
+	/*
+	 * Now we are prepared to build the final-output upperrel.
+	 */
+	final_rel = fetch_upper_rel(root, UPPERREL_FINAL, NULL);
+
+	/*
+	 * If the input rel is marked consider_parallel and there's nothing that's
+	 * not parallel-safe in the LIMIT clause, then the final_rel can be marked
+	 * consider_parallel as well.  Note that if the query has rowMarks or is
+	 * not a SELECT, consider_parallel will be false for every relation in the
+	 * query.
+	 */
+	if (current_rel->consider_parallel &&
+		is_parallel_safe(root, parse->limitOffset) &&
+		is_parallel_safe(root, parse->limitCount))
+		final_rel->consider_parallel = true;
+
+	/*
+	 * If the current_rel belongs to a single FDW, so does the final_rel.
+	 */
+	final_rel->serverid = current_rel->serverid;
+	final_rel->userid = current_rel->userid;
+	final_rel->useridiscurrent = current_rel->useridiscurrent;
+	final_rel->fdwroutine = current_rel->fdwroutine;
+
+	/*
+	 * Generate paths for the final_rel.  Insert all surviving paths, with
+	 * LockRows, Limit, and/or ModifyTable steps added if needed.
+	 */
+	foreach(lc, current_rel->pathlist)
+	{
+		Path	   *path = (Path *) lfirst(lc);
+
+		/*
+		 * If there is a FOR [KEY] UPDATE/SHARE clause, add the LockRows node.
+		 * (Note: we intentionally test parse->rowMarks not root->rowMarks
+		 * here.  If there are only non-locking rowmarks, they should be
+		 * handled by the ModifyTable node instead.  However, root->rowMarks
+		 * is what goes into the LockRows node.)
+		 */
+		if (parse->rowMarks)
+		{
+			path = (Path *) create_lockrows_path(root, final_rel, path,
+												 root->rowMarks,
+												 SS_assign_special_param(root));
+		}
+
+		/*
+		 * If there is a LIMIT/OFFSET clause, add the LIMIT node.
+		 */
+		if (limit_needed(parse))
+		{
+			path = (Path *) create_limit_path(root, final_rel, path,
+											  parse->limitOffset,
+											  parse->limitCount,
+											  offset_est, count_est);
+		}
+
+		/*
+		 * If this is an INSERT/UPDATE/DELETE, and we're not being called from
+		 * inheritance_planner, add the ModifyTable node.
+		 */
+		if (parse->commandType != CMD_SELECT && !inheritance_update)
+		{
+			List	   *withCheckOptionLists;
+			List	   *returningLists;
+			List	   *rowMarks;
+
+			/*
+			 * Set up the WITH CHECK OPTION and RETURNING lists-of-lists, if
+			 * needed.
+			 */
+			if (parse->withCheckOptions)
+				withCheckOptionLists = list_make1(parse->withCheckOptions);
+			else
+				withCheckOptionLists = NIL;
+
+			if (parse->returningList)
+				returningLists = list_make1(parse->returningList);
+			else
+				returningLists = NIL;
+
+			/*
+			 * If there was a FOR [KEY] UPDATE/SHARE clause, the LockRows node
+			 * will have dealt with fetching non-locked marked rows, else we
+			 * need to have ModifyTable do that.
+			 */
+			if (parse->rowMarks)
+				rowMarks = NIL;
+			else
+				rowMarks = root->rowMarks;
+
+			path = (Path *)
+				create_modifytable_path(root, final_rel,
+										parse->commandType,
+										parse->canSetTag,
+										parse->resultRelation,
+										NIL,
+										list_make1_int(parse->resultRelation),
+										list_make1(path),
+										list_make1(root),
+										withCheckOptionLists,
+										returningLists,
+										rowMarks,
+										parse->onConflict,
+										SS_assign_special_param(root));
+		}
+
+		/* And shove it into final_rel */
+		add_path(final_rel, path);
+	}
+
+	/*
+	 * If there is an FDW that's responsible for all baserels of the query,
+	 * let it consider adding ForeignPaths.
+	 */
+	if (final_rel->fdwroutine &&
+		final_rel->fdwroutine->GetForeignUpperPaths)
+		final_rel->fdwroutine->GetForeignUpperPaths(root, UPPERREL_FINAL,
+													current_rel, final_rel);
+
+	/* Let extensions possibly add some more paths */
+	if (create_upper_paths_hook)
+		(*create_upper_paths_hook) (root, UPPERREL_FINAL,
+									current_rel, final_rel);
+
+	/* Note: currently, we leave it to callers to do set_cheapest() */
+}
+
+/*
+ * Do preprocessing for groupingSets clause and related data.  This handles the
+ * preliminary steps of expanding the grouping sets, organizing them into lists
+ * of rollups, and preparing annotations which will later be filled in with
+ * size estimates.
+ */
+static grouping_sets_data *
+preprocess_grouping_sets(PlannerInfo *root)
+{
+	Query	   *parse = root->parse;
+	List	   *sets;
+	int			maxref = 0;
+	ListCell   *lc;
+	ListCell   *lc_set;
+	grouping_sets_data *gd = palloc0(sizeof(grouping_sets_data));
+
+	parse->groupingSets = expand_grouping_sets(parse->groupingSets, -1);
+
+	gd->any_hashable = false;
+	gd->unhashable_refs = NULL;
+	gd->unsortable_refs = NULL;
+	gd->unsortable_sets = NIL;
+
+	if (parse->groupClause)
+	{
+		ListCell   *lc;
+
+		foreach(lc, parse->groupClause)
+		{
+			SortGroupClause *gc = lfirst(lc);
+			Index		ref = gc->tleSortGroupRef;
+
+			if (ref > maxref)
+				maxref = ref;
+
+			if (!gc->hashable)
+				gd->unhashable_refs = bms_add_member(gd->unhashable_refs, ref);
+
+			if (!OidIsValid(gc->sortop))
+				gd->unsortable_refs = bms_add_member(gd->unsortable_refs, ref);
+		}
+	}
+
+	/* Allocate workspace array for remapping */
+	gd->tleref_to_colnum_map = (int *) palloc((maxref + 1) * sizeof(int));
+
+	/*
+	 * If we have any unsortable sets, we must extract them before trying to
+	 * prepare rollups. Unsortable sets don't go through
+	 * reorder_grouping_sets, so we must apply the GroupingSetData annotation
+	 * here.
+	 */
+	if (!bms_is_empty(gd->unsortable_refs))
+	{
+		List	   *sortable_sets = NIL;
+
+		foreach(lc, parse->groupingSets)
+		{
+			List	   *gset = lfirst(lc);
+
+			if (bms_overlap_list(gd->unsortable_refs, gset))
+			{
+				GroupingSetData *gs = makeNode(GroupingSetData);
+
+				gs->set = gset;
+				gd->unsortable_sets = lappend(gd->unsortable_sets, gs);
+
+				/*
+				 * We must enforce here that an unsortable set is hashable;
+				 * later code assumes this.  Parse analysis only checks that
+				 * every individual column is either hashable or sortable.
+				 *
+				 * Note that passing this test doesn't guarantee we can
+				 * generate a plan; there might be other showstoppers.
+				 */
+				if (bms_overlap_list(gd->unhashable_refs, gset))
+					ereport(ERROR,
+							(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
+							 errmsg("could not implement GROUP BY"),
+							 errdetail("Some of the datatypes only support hashing, while others only support sorting.")));
+			}
+			else
+				sortable_sets = lappend(sortable_sets, gset);
+		}
+
+		if (sortable_sets)
+			sets = extract_rollup_sets(sortable_sets);
+		else
+			sets = NIL;
+	}
+	else
+		sets = extract_rollup_sets(parse->groupingSets);
+
+	foreach(lc_set, sets)
+	{
+		List	   *current_sets = (List *) lfirst(lc_set);
+		RollupData *rollup = makeNode(RollupData);
+		GroupingSetData *gs;
+
+		/*
+		 * Reorder the current list of grouping sets into correct prefix
+		 * order.  If only one aggregation pass is needed, try to make the
+		 * list match the ORDER BY clause; if more than one pass is needed, we
+		 * don't bother with that.
+		 *
+		 * Note that this reorders the sets from smallest-member-first to
+		 * largest-member-first, and applies the GroupingSetData annotations,
+		 * though the data will be filled in later.
+		 */
+		current_sets = reorder_grouping_sets(current_sets,
+											 (list_length(sets) == 1
+											  ? parse->sortClause
+											  : NIL));
+
+		/*
+		 * Get the initial (and therefore largest) grouping set.
+		 */
+		gs = linitial(current_sets);
+
+		/*
+		 * Order the groupClause appropriately.  If the first grouping set is
+		 * empty, then the groupClause must also be empty; otherwise we have
+		 * to force the groupClause to match that grouping set's order.
+		 *
+		 * (The first grouping set can be empty even though parse->groupClause
+		 * is not empty only if all non-empty grouping sets are unsortable.
+		 * The groupClauses for hashed grouping sets are built later on.)
+		 */
+		if (gs->set)
+			rollup->groupClause = preprocess_groupclause(root, gs->set);
+		else
+			rollup->groupClause = NIL;
+
+		/*
+		 * Is it hashable? We pretend empty sets are hashable even though we
+		 * actually force them not to be hashed later. But don't bother if
+		 * there's nothing but empty sets (since in that case we can't hash
+		 * anything).
+		 */
+		if (gs->set &&
+			!bms_overlap_list(gd->unhashable_refs, gs->set))
+		{
+			rollup->hashable = true;
+			gd->any_hashable = true;
+		}
+
+		/*
+		 * Now that we've pinned down an order for the groupClause for this
+		 * list of grouping sets, we need to remap the entries in the grouping
+		 * sets from sortgrouprefs to plain indices (0-based) into the
+		 * groupClause for this collection of grouping sets. We keep the
+		 * original form for later use, though.
+		 */
+		rollup->gsets = remap_to_groupclause_idx(rollup->groupClause,
+												 current_sets,
+												 gd->tleref_to_colnum_map);
+		rollup->gsets_data = current_sets;
+
+		gd->rollups = lappend(gd->rollups, rollup);
+	}
+
+	if (gd->unsortable_sets)
+	{
+		/*
+		 * We have not yet pinned down a groupclause for this, but we will
+		 * need index-based lists for estimation purposes. Construct
+		 * hash_sets_idx based on the entire original groupclause for now.
+		 */
+		gd->hash_sets_idx = remap_to_groupclause_idx(parse->groupClause,
+													 gd->unsortable_sets,
+													 gd->tleref_to_colnum_map);
+		gd->any_hashable = true;
+	}
+
+	return gd;
+}
+
+/*
+ * Given a groupclause and a list of GroupingSetData, return equivalent sets
+ * (without annotation) mapped to indexes into the given groupclause.
+ */
+static List *
+remap_to_groupclause_idx(List *groupClause,
+						 List *gsets,
+						 int *tleref_to_colnum_map)
+{
+	int			ref = 0;
+	List	   *result = NIL;
+	ListCell   *lc;
+
+	foreach(lc, groupClause)
+	{
+		SortGroupClause *gc = lfirst(lc);
+
+		tleref_to_colnum_map[gc->tleSortGroupRef] = ref++;
+	}
+
+	foreach(lc, gsets)
+	{
+		List	   *set = NIL;
+		ListCell   *lc2;
+		GroupingSetData *gs = lfirst(lc);
+
+		foreach(lc2, gs->set)
+		{
+			set = lappend_int(set, tleref_to_colnum_map[lfirst_int(lc2)]);
+		}
+
+		result = lappend(result, set);
+	}
+
+	return result;
+}
+
+
+
+/*
+ * Detect whether a plan node is a "dummy" plan created when a relation
+ * is deemed not to need scanning due to constraint exclusion.
+ *
+ * Currently, such dummy plans are Result nodes with constant FALSE
+ * filter quals (see set_dummy_rel_pathlist and create_append_plan).
+ *
+ * XXX this probably ought to be somewhere else, but not clear where.
+ */
+bool
+is_dummy_plan(Plan *plan)
+{
+	if (IsA(plan, Result))
+	{
+		List	   *rcqual = (List *) ((Result *) plan)->resconstantqual;
+
+		if (list_length(rcqual) == 1)
+		{
+			Const	   *constqual = (Const *) linitial(rcqual);
+
+			if (constqual && IsA(constqual, Const))
+			{
+				if (!constqual->constisnull &&
+					!DatumGetBool(constqual->constvalue))
+					return true;
+			}
+		}
+	}
+	return false;
+}
+
+/*
+ * preprocess_rowmarks - set up PlanRowMarks if needed
+ */
+static void
+preprocess_rowmarks(PlannerInfo *root)
+{
+	Query	   *parse = root->parse;
+	Bitmapset  *rels;
+	List	   *prowmarks;
+	ListCell   *l;
+	int			i;
+
+	if (parse->rowMarks)
+	{
+		/*
+		 * We've got trouble if FOR [KEY] UPDATE/SHARE appears inside
+		 * grouping, since grouping renders a reference to individual tuple
+		 * CTIDs invalid.  This is also checked at parse time, but that's
+		 * insufficient because of rule substitution, query pullup, etc.
+		 */
+		CheckSelectLocking(parse, ((RowMarkClause *)
+								   linitial(parse->rowMarks))->strength);
+	}
+	else
+	{
+		/*
+		 * We only need rowmarks for UPDATE, DELETE, or FOR [KEY]
+		 * UPDATE/SHARE.
+		 */
+		if (parse->commandType != CMD_UPDATE &&
+			parse->commandType != CMD_DELETE)
+			return;
+	}
+
+	/*
+	 * We need to have rowmarks for all base relations except the target. We
+	 * make a bitmapset of all base rels and then remove the items we don't
+	 * need or have FOR [KEY] UPDATE/SHARE marks for.
+	 */
+	rels = get_relids_in_jointree((Node *) parse->jointree, false);
+	if (parse->resultRelation)
+		rels = bms_del_member(rels, parse->resultRelation);
+
+	/*
+	 * Convert RowMarkClauses to PlanRowMark representation.
+	 */
+	prowmarks = NIL;
+	foreach(l, parse->rowMarks)
+	{
+		RowMarkClause *rc = (RowMarkClause *) lfirst(l);
+		RangeTblEntry *rte = rt_fetch(rc->rti, parse->rtable);
+		PlanRowMark *newrc;
+
+		/*
+		 * Currently, it is syntactically impossible to have FOR UPDATE et al
+		 * applied to an update/delete target rel.  If that ever becomes
+		 * possible, we should drop the target from the PlanRowMark list.
+		 */
+		Assert(rc->rti != parse->resultRelation);
+
+		/*
+		 * Ignore RowMarkClauses for subqueries; they aren't real tables and
+		 * can't support true locking.  Subqueries that got flattened into the
+		 * main query should be ignored completely.  Any that didn't will get
+		 * ROW_MARK_COPY items in the next loop.
+		 */
+		if (rte->rtekind != RTE_RELATION)
+			continue;
+
+		rels = bms_del_member(rels, rc->rti);
+
+		newrc = makeNode(PlanRowMark);
+		newrc->rti = newrc->prti = rc->rti;
+		newrc->rowmarkId = ++(root->glob->lastRowMarkId);
+		newrc->markType = select_rowmark_type(rte, rc->strength);
+		newrc->allMarkTypes = (1 << newrc->markType);
+		newrc->strength = rc->strength;
+		newrc->waitPolicy = rc->waitPolicy;
+		newrc->isParent = false;
+
+		prowmarks = lappend(prowmarks, newrc);
+	}
+
+	/*
+	 * Now, add rowmarks for any non-target, non-locked base relations.
+	 */
+	i = 0;
+	foreach(l, parse->rtable)
+	{
+		RangeTblEntry *rte = (RangeTblEntry *) lfirst(l);
+		PlanRowMark *newrc;
+
+		i++;
+		if (!bms_is_member(i, rels))
+			continue;
+
+		newrc = makeNode(PlanRowMark);
+		newrc->rti = newrc->prti = i;
+		newrc->rowmarkId = ++(root->glob->lastRowMarkId);
+		newrc->markType = select_rowmark_type(rte, LCS_NONE);
+		newrc->allMarkTypes = (1 << newrc->markType);
+		newrc->strength = LCS_NONE;
+		newrc->waitPolicy = LockWaitBlock;	/* doesn't matter */
+		newrc->isParent = false;
+
+		prowmarks = lappend(prowmarks, newrc);
+	}
+
+	root->rowMarks = prowmarks;
+}
+
+/*
+ * Select RowMarkType to use for a given table
+ */
+RowMarkType
+select_rowmark_type(RangeTblEntry *rte, LockClauseStrength strength)
+{
+	if (rte->rtekind != RTE_RELATION)
+	{
+		/* If it's not a table at all, use ROW_MARK_COPY */
+		return ROW_MARK_COPY;
+	}
+	else if (rte->relkind == RELKIND_FOREIGN_TABLE)
+	{
+		/* Let the FDW select the rowmark type, if it wants to */
+		FdwRoutine *fdwroutine = GetFdwRoutineByRelId(rte->relid);
+
+		if (fdwroutine->GetForeignRowMarkType != NULL)
+			return fdwroutine->GetForeignRowMarkType(rte, strength);
+		/* Otherwise, use ROW_MARK_COPY by default */
+		return ROW_MARK_COPY;
+	}
+	else
+	{
+		/* Regular table, apply the appropriate lock type */
+		switch (strength)
+		{
+			case LCS_NONE:
+
+				/*
+				 * We don't need a tuple lock, only the ability to re-fetch
+				 * the row.
+				 */
+				return ROW_MARK_REFERENCE;
+				break;
+			case LCS_FORKEYSHARE:
+				return ROW_MARK_KEYSHARE;
+				break;
+			case LCS_FORSHARE:
+				return ROW_MARK_SHARE;
+				break;
+			case LCS_FORNOKEYUPDATE:
+				return ROW_MARK_NOKEYEXCLUSIVE;
+				break;
+			case LCS_FORUPDATE:
+				return ROW_MARK_EXCLUSIVE;
+				break;
+		}
+		elog(ERROR, "unrecognized LockClauseStrength %d", (int) strength);
+		return ROW_MARK_EXCLUSIVE;	/* keep compiler quiet */
+	}
+}
+
+/*
+ * preprocess_limit - do pre-estimation for LIMIT and/or OFFSET clauses
+ *
+ * We try to estimate the values of the LIMIT/OFFSET clauses, and pass the
+ * results back in *count_est and *offset_est.  These variables are set to
+ * 0 if the corresponding clause is not present, and -1 if it's present
+ * but we couldn't estimate the value for it.  (The "0" convention is OK
+ * for OFFSET but a little bit bogus for LIMIT: effectively we estimate
+ * LIMIT 0 as though it were LIMIT 1.  But this is in line with the planner's
+ * usual practice of never estimating less than one row.)  These values will
+ * be passed to create_limit_path, which see if you change this code.
+ *
+ * The return value is the suitably adjusted tuple_fraction to use for
+ * planning the query.  This adjustment is not overridable, since it reflects
+ * plan actions that grouping_planner() will certainly take, not assumptions
+ * about context.
+ */
+static double
+preprocess_limit(PlannerInfo *root, double tuple_fraction,
+				 int64 *offset_est, int64 *count_est)
+{
+	Query	   *parse = root->parse;
+	Node	   *est;
+	double		limit_fraction;
+
+	/* Should not be called unless LIMIT or OFFSET */
+	Assert(parse->limitCount || parse->limitOffset);
+
+	/*
+	 * Try to obtain the clause values.  We use estimate_expression_value
+	 * primarily because it can sometimes do something useful with Params.
+	 */
+	if (parse->limitCount)
+	{
+		est = estimate_expression_value(root, parse->limitCount);
+		if (est && IsA(est, Const))
+		{
+			if (((Const *) est)->constisnull)
+			{
+				/* NULL indicates LIMIT ALL, ie, no limit */
+				*count_est = 0; /* treat as not present */
+			}
+			else
+			{
+				*count_est = DatumGetInt64(((Const *) est)->constvalue);
+				if (*count_est <= 0)
+					*count_est = 1; /* force to at least 1 */
+			}
+		}
+		else
+			*count_est = -1;	/* can't estimate */
+	}
+	else
+		*count_est = 0;			/* not present */
+
+	if (parse->limitOffset)
+	{
+		est = estimate_expression_value(root, parse->limitOffset);
+		if (est && IsA(est, Const))
+		{
+			if (((Const *) est)->constisnull)
+			{
+				/* Treat NULL as no offset; the executor will too */
+				*offset_est = 0;	/* treat as not present */
+			}
+			else
+			{
+				*offset_est = DatumGetInt64(((Const *) est)->constvalue);
+				if (*offset_est < 0)
+					*offset_est = 0;	/* treat as not present */
+			}
+		}
+		else
+			*offset_est = -1;	/* can't estimate */
+	}
+	else
+		*offset_est = 0;		/* not present */
+
+	if (*count_est != 0)
+	{
+		/*
+		 * A LIMIT clause limits the absolute number of tuples returned.
+		 * However, if it's not a constant LIMIT then we have to guess; for
+		 * lack of a better idea, assume 10% of the plan's result is wanted.
+		 */
+		if (*count_est < 0 || *offset_est < 0)
+		{
+			/* LIMIT or OFFSET is an expression ... punt ... */
+			limit_fraction = 0.10;
+		}
+		else
+		{
+			/* LIMIT (plus OFFSET, if any) is max number of tuples needed */
+			limit_fraction = (double) *count_est + (double) *offset_est;
+		}
+
+		/*
+		 * If we have absolute limits from both caller and LIMIT, use the
+		 * smaller value; likewise if they are both fractional.  If one is
+		 * fractional and the other absolute, we can't easily determine which
+		 * is smaller, but we use the heuristic that the absolute will usually
+		 * be smaller.
+		 */
+		if (tuple_fraction >= 1.0)
+		{
+			if (limit_fraction >= 1.0)
+			{
+				/* both absolute */
+				tuple_fraction = Min(tuple_fraction, limit_fraction);
+			}
+			else
+			{
+				/* caller absolute, limit fractional; use caller's value */
+			}
+		}
+		else if (tuple_fraction > 0.0)
+		{
+			if (limit_fraction >= 1.0)
+			{
+				/* caller fractional, limit absolute; use limit */
+				tuple_fraction = limit_fraction;
+			}
+			else
+			{
+				/* both fractional */
+				tuple_fraction = Min(tuple_fraction, limit_fraction);
+			}
+		}
+		else
+		{
+			/* no info from caller, just use limit */
+			tuple_fraction = limit_fraction;
+		}
+	}
+	else if (*offset_est != 0 && tuple_fraction > 0.0)
+	{
+		/*
+		 * We have an OFFSET but no LIMIT.  This acts entirely differently
+		 * from the LIMIT case: here, we need to increase rather than decrease
+		 * the caller's tuple_fraction, because the OFFSET acts to cause more
+		 * tuples to be fetched instead of fewer.  This only matters if we got
+		 * a tuple_fraction > 0, however.
+		 *
+		 * As above, use 10% if OFFSET is present but unestimatable.
+		 */
+		if (*offset_est < 0)
+			limit_fraction = 0.10;
+		else
+			limit_fraction = (double) *offset_est;
+
+		/*
+		 * If we have absolute counts from both caller and OFFSET, add them
+		 * together; likewise if they are both fractional.  If one is
+		 * fractional and the other absolute, we want to take the larger, and
+		 * we heuristically assume that's the fractional one.
+		 */
+		if (tuple_fraction >= 1.0)
+		{
+			if (limit_fraction >= 1.0)
+			{
+				/* both absolute, so add them together */
+				tuple_fraction += limit_fraction;
+			}
+			else
+			{
+				/* caller absolute, limit fractional; use limit */
+				tuple_fraction = limit_fraction;
+			}
+		}
+		else
+		{
+			if (limit_fraction >= 1.0)
+			{
+				/* caller fractional, limit absolute; use caller's value */
+			}
+			else
+			{
+				/* both fractional, so add them together */
+				tuple_fraction += limit_fraction;
+				if (tuple_fraction >= 1.0)
+					tuple_fraction = 0.0;	/* assume fetch all */
+			}
+		}
+	}
+
+	return tuple_fraction;
+}
+
+/*
+ * limit_needed - do we actually need a Limit plan node?
+ *
+ * If we have constant-zero OFFSET and constant-null LIMIT, we can skip adding
+ * a Limit node.  This is worth checking for because "OFFSET 0" is a common
+ * locution for an optimization fence.  (Because other places in the planner
+ * merely check whether parse->limitOffset isn't NULL, it will still work as
+ * an optimization fence --- we're just suppressing unnecessary run-time
+ * overhead.)
+ *
+ * This might look like it could be merged into preprocess_limit, but there's
+ * a key distinction: here we need hard constants in OFFSET/LIMIT, whereas
+ * in preprocess_limit it's good enough to consider estimated values.
+ */
+static bool
+limit_needed(Query *parse)
+{
+	Node	   *node;
+
+	node = parse->limitCount;
+	if (node)
+	{
+		if (IsA(node, Const))
+		{
+			/* NULL indicates LIMIT ALL, ie, no limit */
+			if (!((Const *) node)->constisnull)
+				return true;	/* LIMIT with a constant value */
+		}
+		else
+			return true;		/* non-constant LIMIT */
+	}
+
+	node = parse->limitOffset;
+	if (node)
+	{
+		if (IsA(node, Const))
+		{
+			/* Treat NULL as no offset; the executor would too */
+			if (!((Const *) node)->constisnull)
+			{
+				int64		offset = DatumGetInt64(((Const *) node)->constvalue);
+
+				if (offset != 0)
+					return true;	/* OFFSET with a nonzero value */
+			}
+		}
+		else
+			return true;		/* non-constant OFFSET */
+	}
+
+	return false;				/* don't need a Limit plan node */
+}
+
+
+/*
+ * remove_useless_groupby_columns
+ *		Remove any columns in the GROUP BY clause that are redundant due to
+ *		being functionally dependent on other GROUP BY columns.
+ *
+ * Since some other DBMSes do not allow references to ungrouped columns, it's
+ * not unusual to find all columns listed in GROUP BY even though listing the
+ * primary-key columns would be sufficient.  Deleting such excess columns
+ * avoids redundant sorting work, so it's worth doing.  When we do this, we
+ * must mark the plan as dependent on the pkey constraint (compare the
+ * parser's check_ungrouped_columns() and check_functional_grouping()).
+ *
+ * In principle, we could treat any NOT-NULL columns appearing in a UNIQUE
+ * index as the determining columns.  But as with check_functional_grouping(),
+ * there's currently no way to represent dependency on a NOT NULL constraint,
+ * so we consider only the pkey for now.
+ */
+static void
+remove_useless_groupby_columns(PlannerInfo *root)
+{
+	Query	   *parse = root->parse;
+	Bitmapset **groupbyattnos;
+	Bitmapset **surplusvars;
+	ListCell   *lc;
+	int			relid;
+
+	/* No chance to do anything if there are less than two GROUP BY items */
+	if (list_length(parse->groupClause) < 2)
+		return;
+
+	/* Don't fiddle with the GROUP BY clause if the query has grouping sets */
+	if (parse->groupingSets)
+		return;
+
+	/*
+	 * Scan the GROUP BY clause to find GROUP BY items that are simple Vars.
+	 * Fill groupbyattnos[k] with a bitmapset of the column attnos of RTE k
+	 * that are GROUP BY items.
+	 */
+	groupbyattnos = (Bitmapset **) palloc0(sizeof(Bitmapset *) *
+										   (list_length(parse->rtable) + 1));
+	foreach(lc, parse->groupClause)
+	{
+		SortGroupClause *sgc = (SortGroupClause *) lfirst(lc);
+		TargetEntry *tle = get_sortgroupclause_tle(sgc, parse->targetList);
+		Var		   *var = (Var *) tle->expr;
+
+		/*
+		 * Ignore non-Vars and Vars from other query levels.
+		 *
+		 * XXX in principle, stable expressions containing Vars could also be
+		 * removed, if all the Vars are functionally dependent on other GROUP
+		 * BY items.  But it's not clear that such cases occur often enough to
+		 * be worth troubling over.
+		 */
+		if (!IsA(var, Var) ||
+			var->varlevelsup > 0)
+			continue;
+
+		/* OK, remember we have this Var */
+		relid = var->varno;
+		Assert(relid <= list_length(parse->rtable));
+		groupbyattnos[relid] = bms_add_member(groupbyattnos[relid],
+											  var->varattno - FirstLowInvalidHeapAttributeNumber);
+	}
+
+	/*
+	 * Consider each relation and see if it is possible to remove some of its
+	 * Vars from GROUP BY.  For simplicity and speed, we do the actual removal
+	 * in a separate pass.  Here, we just fill surplusvars[k] with a bitmapset
+	 * of the column attnos of RTE k that are removable GROUP BY items.
+	 */
+	surplusvars = NULL;			/* don't allocate array unless required */
+	relid = 0;
+	foreach(lc, parse->rtable)
+	{
+		RangeTblEntry *rte = (RangeTblEntry *) lfirst(lc);
+		Bitmapset  *relattnos;
+		Bitmapset  *pkattnos;
+		Oid			constraintOid;
+
+		relid++;
+
+		/* Only plain relations could have primary-key constraints */
+		if (rte->rtekind != RTE_RELATION)
+			continue;
+
+		/* Nothing to do unless this rel has multiple Vars in GROUP BY */
+		relattnos = groupbyattnos[relid];
+		if (bms_membership(relattnos) != BMS_MULTIPLE)
+			continue;
+
+		/*
+		 * Can't remove any columns for this rel if there is no suitable
+		 * (i.e., nondeferrable) primary key constraint.
+		 */
+		pkattnos = get_primary_key_attnos(rte->relid, false, &constraintOid);
+		if (pkattnos == NULL)
+			continue;
+
+		/*
+		 * If the primary key is a proper subset of relattnos then we have
+		 * some items in the GROUP BY that can be removed.
+		 */
+		if (bms_subset_compare(pkattnos, relattnos) == BMS_SUBSET1)
+		{
+			/*
+			 * To easily remember whether we've found anything to do, we don't
+			 * allocate the surplusvars[] array until we find something.
+			 */
+			if (surplusvars == NULL)
+				surplusvars = (Bitmapset **) palloc0(sizeof(Bitmapset *) *
+													 (list_length(parse->rtable) + 1));
+
+			/* Remember the attnos of the removable columns */
+			surplusvars[relid] = bms_difference(relattnos, pkattnos);
+
+			/* Also, mark the resulting plan as dependent on this constraint */
+			parse->constraintDeps = lappend_oid(parse->constraintDeps,
+												constraintOid);
+		}
+	}
+
+	/*
+	 * If we found any surplus Vars, build a new GROUP BY clause without them.
+	 * (Note: this may leave some TLEs with unreferenced ressortgroupref
+	 * markings, but that's harmless.)
+	 */
+	if (surplusvars != NULL)
+	{
+		List	   *new_groupby = NIL;
+
+		foreach(lc, parse->groupClause)
+		{
+			SortGroupClause *sgc = (SortGroupClause *) lfirst(lc);
+			TargetEntry *tle = get_sortgroupclause_tle(sgc, parse->targetList);
+			Var		   *var = (Var *) tle->expr;
+
+			/*
+			 * New list must include non-Vars, outer Vars, and anything not
+			 * marked as surplus.
+			 */
+			if (!IsA(var, Var) ||
+				var->varlevelsup > 0 ||
+				!bms_is_member(var->varattno - FirstLowInvalidHeapAttributeNumber,
+							   surplusvars[var->varno]))
+				new_groupby = lappend(new_groupby, sgc);
+		}
+
+		parse->groupClause = new_groupby;
+	}
+}
+
+/*
+ * preprocess_groupclause - do preparatory work on GROUP BY clause
+ *
+ * The idea here is to adjust the ordering of the GROUP BY elements
+ * (which in itself is semantically insignificant) to match ORDER BY,
+ * thereby allowing a single sort operation to both implement the ORDER BY
+ * requirement and set up for a Unique step that implements GROUP BY.
+ *
+ * In principle it might be interesting to consider other orderings of the
+ * GROUP BY elements, which could match the sort ordering of other
+ * possible plans (eg an indexscan) and thereby reduce cost.  We don't
+ * bother with that, though.  Hashed grouping will frequently win anyway.
+ *
+ * Note: we need no comparable processing of the distinctClause because
+ * the parser already enforced that that matches ORDER BY.
+ *
+ * For grouping sets, the order of items is instead forced to agree with that
+ * of the grouping set (and items not in the grouping set are skipped). The
+ * work of sorting the order of grouping set elements to match the ORDER BY if
+ * possible is done elsewhere.
+ */
+static List *
+preprocess_groupclause(PlannerInfo *root, List *force)
+{
+	Query	   *parse = root->parse;
+	List	   *new_groupclause = NIL;
+	bool		partial_match;
+	ListCell   *sl;
+	ListCell   *gl;
+
+	/* For grouping sets, we need to force the ordering */
+	if (force)
+	{
+		foreach(sl, force)
+		{
+			Index		ref = lfirst_int(sl);
+			SortGroupClause *cl = get_sortgroupref_clause(ref, parse->groupClause);
+
+			new_groupclause = lappend(new_groupclause, cl);
+		}
+
+		return new_groupclause;
+	}
+
+	/* If no ORDER BY, nothing useful to do here */
+	if (parse->sortClause == NIL)
+		return parse->groupClause;
+
+	/*
+	 * Scan the ORDER BY clause and construct a list of matching GROUP BY
+	 * items, but only as far as we can make a matching prefix.
+	 *
+	 * This code assumes that the sortClause contains no duplicate items.
+	 */
+	foreach(sl, parse->sortClause)
+	{
+		SortGroupClause *sc = (SortGroupClause *) lfirst(sl);
+
+		foreach(gl, parse->groupClause)
+		{
+			SortGroupClause *gc = (SortGroupClause *) lfirst(gl);
+
+			if (equal(gc, sc))
+			{
+				new_groupclause = lappend(new_groupclause, gc);
+				break;
+			}
+		}
+		if (gl == NULL)
+			break;				/* no match, so stop scanning */
+	}
+
+	/* Did we match all of the ORDER BY list, or just some of it? */
+	partial_match = (sl != NULL);
+
+	/* If no match at all, no point in reordering GROUP BY */
+	if (new_groupclause == NIL)
+		return parse->groupClause;
+
+	/*
+	 * Add any remaining GROUP BY items to the new list, but only if we were
+	 * able to make a complete match.  In other words, we only rearrange the
+	 * GROUP BY list if the result is that one list is a prefix of the other
+	 * --- otherwise there's no possibility of a common sort.  Also, give up
+	 * if there are any non-sortable GROUP BY items, since then there's no
+	 * hope anyway.
+	 */
+	foreach(gl, parse->groupClause)
+	{
+		SortGroupClause *gc = (SortGroupClause *) lfirst(gl);
+
+		if (list_member_ptr(new_groupclause, gc))
+			continue;			/* it matched an ORDER BY item */
+		if (partial_match)
+			return parse->groupClause;	/* give up, no common sort possible */
+		if (!OidIsValid(gc->sortop))
+			return parse->groupClause;	/* give up, GROUP BY can't be sorted */
+		new_groupclause = lappend(new_groupclause, gc);
+	}
+
+	/* Success --- install the rearranged GROUP BY list */
+	Assert(list_length(parse->groupClause) == list_length(new_groupclause));
+	return new_groupclause;
+}
+
+/*
+ * Extract lists of grouping sets that can be implemented using a single
+ * rollup-type aggregate pass each. Returns a list of lists of grouping sets.
+ *
+ * Input must be sorted with smallest sets first. Result has each sublist
+ * sorted with smallest sets first.
+ *
+ * We want to produce the absolute minimum possible number of lists here to
+ * avoid excess sorts. Fortunately, there is an algorithm for this; the problem
+ * of finding the minimal partition of a partially-ordered set into chains
+ * (which is what we need, taking the list of grouping sets as a poset ordered
+ * by set inclusion) can be mapped to the problem of finding the maximum
+ * cardinality matching on a bipartite graph, which is solvable in polynomial
+ * time with a worst case of no worse than O(n^2.5) and usually much
+ * better. Since our N is at most 4096, we don't need to consider fallbacks to
+ * heuristic or approximate methods.  (Planning time for a 12-d cube is under
+ * half a second on my modest system even with optimization off and assertions
+ * on.)
+ */
+static List *
+extract_rollup_sets(List *groupingSets)
+{
+	int			num_sets_raw = list_length(groupingSets);
+	int			num_empty = 0;
+	int			num_sets = 0;	/* distinct sets */
+	int			num_chains = 0;
+	List	   *result = NIL;
+	List	  **results;
+	List	  **orig_sets;
+	Bitmapset **set_masks;
+	int		   *chains;
+	short	  **adjacency;
+	short	   *adjacency_buf;
+	BipartiteMatchState *state;
+	int			i;
+	int			j;
+	int			j_size;
+	ListCell   *lc1 = list_head(groupingSets);
+	ListCell   *lc;
+
+	/*
+	 * Start by stripping out empty sets.  The algorithm doesn't require this,
+	 * but the planner currently needs all empty sets to be returned in the
+	 * first list, so we strip them here and add them back after.
+	 */
+	while (lc1 && lfirst(lc1) == NIL)
+	{
+		++num_empty;
+		lc1 = lnext(lc1);
+	}
+
+	/* bail out now if it turns out that all we had were empty sets. */
+	if (!lc1)
+		return list_make1(groupingSets);
+
+	/*----------
+	 * We don't strictly need to remove duplicate sets here, but if we don't,
+	 * they tend to become scattered through the result, which is a bit
+	 * confusing (and irritating if we ever decide to optimize them out).
+	 * So we remove them here and add them back after.
+	 *
+	 * For each non-duplicate set, we fill in the following:
+	 *
+	 * orig_sets[i] = list of the original set lists
+	 * set_masks[i] = bitmapset for testing inclusion
+	 * adjacency[i] = array [n, v1, v2, ... vn] of adjacency indices
+	 *
+	 * chains[i] will be the result group this set is assigned to.
+	 *
+	 * We index all of these from 1 rather than 0 because it is convenient
+	 * to leave 0 free for the NIL node in the graph algorithm.
+	 *----------
+	 */
+	orig_sets = palloc0((num_sets_raw + 1) * sizeof(List *));
+	set_masks = palloc0((num_sets_raw + 1) * sizeof(Bitmapset *));
+	adjacency = palloc0((num_sets_raw + 1) * sizeof(short *));
+	adjacency_buf = palloc((num_sets_raw + 1) * sizeof(short));
+
+	j_size = 0;
+	j = 0;
+	i = 1;
+
+	for_each_cell(lc, lc1)
+	{
+		List	   *candidate = lfirst(lc);
+		Bitmapset  *candidate_set = NULL;
+		ListCell   *lc2;
+		int			dup_of = 0;
+
+		foreach(lc2, candidate)
+		{
+			candidate_set = bms_add_member(candidate_set, lfirst_int(lc2));
+		}
+
+		/* we can only be a dup if we're the same length as a previous set */
+		if (j_size == list_length(candidate))
+		{
+			int			k;
+
+			for (k = j; k < i; ++k)
+			{
+				if (bms_equal(set_masks[k], candidate_set))
+				{
+					dup_of = k;
+					break;
+				}
+			}
+		}
+		else if (j_size < list_length(candidate))
+		{
+			j_size = list_length(candidate);
+			j = i;
+		}
+
+		if (dup_of > 0)
+		{
+			orig_sets[dup_of] = lappend(orig_sets[dup_of], candidate);
+			bms_free(candidate_set);
+		}
+		else
+		{
+			int			k;
+			int			n_adj = 0;
+
+			orig_sets[i] = list_make1(candidate);
+			set_masks[i] = candidate_set;
+
+			/* fill in adjacency list; no need to compare equal-size sets */
+
+			for (k = j - 1; k > 0; --k)
+			{
+				if (bms_is_subset(set_masks[k], candidate_set))
+					adjacency_buf[++n_adj] = k;
+			}
+
+			if (n_adj > 0)
+			{
+				adjacency_buf[0] = n_adj;
+				adjacency[i] = palloc((n_adj + 1) * sizeof(short));
+				memcpy(adjacency[i], adjacency_buf, (n_adj + 1) * sizeof(short));
+			}
+			else
+				adjacency[i] = NULL;
+
+			++i;
+		}
+	}
+
+	num_sets = i - 1;
+
+	/*
+	 * Apply the graph matching algorithm to do the work.
+	 */
+	state = BipartiteMatch(num_sets, num_sets, adjacency);
+
+	/*
+	 * Now, the state->pair* fields have the info we need to assign sets to
+	 * chains. Two sets (u,v) belong to the same chain if pair_uv[u] = v or
+	 * pair_vu[v] = u (both will be true, but we check both so that we can do
+	 * it in one pass)
+	 */
+	chains = palloc0((num_sets + 1) * sizeof(int));
+
+	for (i = 1; i <= num_sets; ++i)
+	{
+		int			u = state->pair_vu[i];
+		int			v = state->pair_uv[i];
+
+		if (u > 0 && u < i)
+			chains[i] = chains[u];
+		else if (v > 0 && v < i)
+			chains[i] = chains[v];
+		else
+			chains[i] = ++num_chains;
+	}
+
+	/* build result lists. */
+	results = palloc0((num_chains + 1) * sizeof(List *));
+
+	for (i = 1; i <= num_sets; ++i)
+	{
+		int			c = chains[i];
+
+		Assert(c > 0);
+
+		results[c] = list_concat(results[c], orig_sets[i]);
+	}
+
+	/* push any empty sets back on the first list. */
+	while (num_empty-- > 0)
+		results[1] = lcons(NIL, results[1]);
+
+	/* make result list */
+	for (i = 1; i <= num_chains; ++i)
+		result = lappend(result, results[i]);
+
+	/*
+	 * Free all the things.
+	 *
+	 * (This is over-fussy for small sets but for large sets we could have
+	 * tied up a nontrivial amount of memory.)
+	 */
+	BipartiteMatchFree(state);
+	pfree(results);
+	pfree(chains);
+	for (i = 1; i <= num_sets; ++i)
+		if (adjacency[i])
+			pfree(adjacency[i]);
+	pfree(adjacency);
+	pfree(adjacency_buf);
+	pfree(orig_sets);
+	for (i = 1; i <= num_sets; ++i)
+		bms_free(set_masks[i]);
+	pfree(set_masks);
+
+	return result;
+}
+
+/*
+ * Reorder the elements of a list of grouping sets such that they have correct
+ * prefix relationships. Also inserts the GroupingSetData annotations.
+ *
+ * The input must be ordered with smallest sets first; the result is returned
+ * with largest sets first.  Note that the result shares no list substructure
+ * with the input, so it's safe for the caller to modify it later.
+ *
+ * If we're passed in a sortclause, we follow its order of columns to the
+ * extent possible, to minimize the chance that we add unnecessary sorts.
+ * (We're trying here to ensure that GROUPING SETS ((a,b,c),(c)) ORDER BY c,b,a
+ * gets implemented in one pass.)
+ */
+static List *
+reorder_grouping_sets(List *groupingsets, List *sortclause)
+{
+	ListCell   *lc;
+	ListCell   *lc2;
+	List	   *previous = NIL;
+	List	   *result = NIL;
+
+	foreach(lc, groupingsets)
+	{
+		List	   *candidate = lfirst(lc);
+		List	   *new_elems = list_difference_int(candidate, previous);
+		GroupingSetData *gs = makeNode(GroupingSetData);
+
+		if (list_length(new_elems) > 0)
+		{
+			while (list_length(sortclause) > list_length(previous))
+			{
+				SortGroupClause *sc = list_nth(sortclause, list_length(previous));
+				int			ref = sc->tleSortGroupRef;
+
+				if (list_member_int(new_elems, ref))
+				{
+					previous = lappend_int(previous, ref);
+					new_elems = list_delete_int(new_elems, ref);
+				}
+				else
+				{
+					/* diverged from the sortclause; give up on it */
+					sortclause = NIL;
+					break;
+				}
+			}
+
+			foreach(lc2, new_elems)
+			{
+				previous = lappend_int(previous, lfirst_int(lc2));
+			}
+		}
+
+		gs->set = list_copy(previous);
+		result = lcons(gs, result);
+		list_free(new_elems);
+	}
+
+	list_free(previous);
+
+	return result;
+}
+
+/*
+ * Compute query_pathkeys and other pathkeys during plan generation
+ */
+static void
+standard_qp_callback(PlannerInfo *root, void *extra)
+{
+	Query	   *parse = root->parse;
+	standard_qp_extra *qp_extra = (standard_qp_extra *) extra;
+	List	   *tlist = qp_extra->tlist;
+	List	   *activeWindows = qp_extra->activeWindows;
+
+	/*
+	 * Calculate pathkeys that represent grouping/ordering requirements.  The
+	 * sortClause is certainly sort-able, but GROUP BY and DISTINCT might not
+	 * be, in which case we just leave their pathkeys empty.
+	 */
+	if (qp_extra->groupClause &&
+		grouping_is_sortable(qp_extra->groupClause))
+		root->group_pathkeys =
+			make_pathkeys_for_sortclauses(root,
+										  qp_extra->groupClause,
+										  tlist);
+	else
+		root->group_pathkeys = NIL;
+
+	/* We consider only the first (bottom) window in pathkeys logic */
+	if (activeWindows != NIL)
+	{
+		WindowClause *wc = (WindowClause *) linitial(activeWindows);
+
+		root->window_pathkeys = make_pathkeys_for_window(root,
+														 wc,
+														 tlist);
+	}
+	else
+		root->window_pathkeys = NIL;
+
+	if (parse->distinctClause &&
+		grouping_is_sortable(parse->distinctClause))
+		root->distinct_pathkeys =
+			make_pathkeys_for_sortclauses(root,
+										  parse->distinctClause,
+										  tlist);
+	else
+		root->distinct_pathkeys = NIL;
+
+	root->sort_pathkeys =
+		make_pathkeys_for_sortclauses(root,
+									  parse->sortClause,
+									  tlist);
+
+	/*
+	 * Figure out whether we want a sorted result from query_planner.
+	 *
+	 * If we have a sortable GROUP BY clause, then we want a result sorted
+	 * properly for grouping.  Otherwise, if we have window functions to
+	 * evaluate, we try to sort for the first window.  Otherwise, if there's a
+	 * sortable DISTINCT clause that's more rigorous than the ORDER BY clause,
+	 * we try to produce output that's sufficiently well sorted for the
+	 * DISTINCT.  Otherwise, if there is an ORDER BY clause, we want to sort
+	 * by the ORDER BY clause.
+	 *
+	 * Note: if we have both ORDER BY and GROUP BY, and ORDER BY is a superset
+	 * of GROUP BY, it would be tempting to request sort by ORDER BY --- but
+	 * that might just leave us failing to exploit an available sort order at
+	 * all.  Needs more thought.  The choice for DISTINCT versus ORDER BY is
+	 * much easier, since we know that the parser ensured that one is a
+	 * superset of the other.
+	 */
+	if (root->group_pathkeys)
+		root->query_pathkeys = root->group_pathkeys;
+	else if (root->window_pathkeys)
+		root->query_pathkeys = root->window_pathkeys;
+	else if (list_length(root->distinct_pathkeys) >
+			 list_length(root->sort_pathkeys))
+		root->query_pathkeys = root->distinct_pathkeys;
+	else if (root->sort_pathkeys)
+		root->query_pathkeys = root->sort_pathkeys;
+	else
+		root->query_pathkeys = NIL;
+}
+
+/*
+ * Estimate number of groups produced by grouping clauses (1 if not grouping)
+ *
+ * path_rows: number of output rows from scan/join step
+ * gsets: grouping set data, or NULL if not doing grouping sets
+ *
+ * If doing grouping sets, we also annotate the gsets data with the estimates
+ * for each set and each individual rollup list, with a view to later
+ * determining whether some combination of them could be hashed instead.
+ */
+static double
+get_number_of_groups(PlannerInfo *root,
+					 double path_rows,
+					 grouping_sets_data *gd)
+{
+	Query	   *parse = root->parse;
+	double		dNumGroups;
+
+	if (parse->groupClause)
+	{
+		List	   *groupExprs;
+
+		if (parse->groupingSets)
+		{
+			/* Add up the estimates for each grouping set */
+			ListCell   *lc;
+			ListCell   *lc2;
+
+			Assert(gd);			/* keep Coverity happy */
+
+			dNumGroups = 0;
+
+			foreach(lc, gd->rollups)
+			{
+				RollupData *rollup = lfirst(lc);
+				ListCell   *lc;
+
+				groupExprs = get_sortgrouplist_exprs(rollup->groupClause,
+													 parse->targetList);
+
+				rollup->numGroups = 0.0;
+
+				forboth(lc, rollup->gsets, lc2, rollup->gsets_data)
+				{
+					List	   *gset = (List *) lfirst(lc);
+					GroupingSetData *gs = lfirst(lc2);
+					double		numGroups = estimate_num_groups(root,
+																groupExprs,
+																path_rows,
+																&gset);
+
+					gs->numGroups = numGroups;
+					rollup->numGroups += numGroups;
+				}
+
+				dNumGroups += rollup->numGroups;
+			}
+
+			if (gd->hash_sets_idx)
+			{
+				ListCell   *lc;
+
+				gd->dNumHashGroups = 0;
+
+				groupExprs = get_sortgrouplist_exprs(parse->groupClause,
+													 parse->targetList);
+
+				forboth(lc, gd->hash_sets_idx, lc2, gd->unsortable_sets)
+				{
+					List	   *gset = (List *) lfirst(lc);
+					GroupingSetData *gs = lfirst(lc2);
+					double		numGroups = estimate_num_groups(root,
+																groupExprs,
+																path_rows,
+																&gset);
+
+					gs->numGroups = numGroups;
+					gd->dNumHashGroups += numGroups;
+				}
+
+				dNumGroups += gd->dNumHashGroups;
+			}
+		}
+		else
+		{
+			/* Plain GROUP BY */
+			groupExprs = get_sortgrouplist_exprs(parse->groupClause,
+												 parse->targetList);
+
+			dNumGroups = estimate_num_groups(root, groupExprs, path_rows,
+											 NULL);
+		}
+	}
+	else if (parse->groupingSets)
+	{
+		/* Empty grouping sets ... one result row for each one */
+		dNumGroups = list_length(parse->groupingSets);
+	}
+	else if (parse->hasAggs || root->hasHavingQual)
+	{
+		/* Plain aggregation, one result row */
+		dNumGroups = 1;
+	}
+	else
+	{
+		/* Not grouping */
+		dNumGroups = 1;
+	}
+
+	return dNumGroups;
+}
+
+/*
+ * estimate_hashagg_tablesize
+ *	  estimate the number of bytes that a hash aggregate hashtable will
+ *	  require based on the agg_costs, path width and dNumGroups.
+ *
+ * XXX this may be over-estimating the size now that hashagg knows to omit
+ * unneeded columns from the hashtable. Also for mixed-mode grouping sets,
+ * grouping columns not in the hashed set are counted here even though hashagg
+ * won't store them. Is this a problem?
+ */
+static Size
+estimate_hashagg_tablesize(Path *path, const AggClauseCosts *agg_costs,
+						   double dNumGroups)
+{
+	Size		hashentrysize;
+
+	/* Estimate per-hash-entry space at tuple width... */
+	hashentrysize = MAXALIGN(path->pathtarget->width) +
+		MAXALIGN(SizeofMinimalTupleHeader);
+
+	/* plus space for pass-by-ref transition values... */
+	hashentrysize += agg_costs->transitionSpace;
+	/* plus the per-hash-entry overhead */
+	hashentrysize += hash_agg_entry_size(agg_costs->numAggs);
+
+	/*
+	 * Note that this disregards the effect of fill-factor and growth policy
+	 * of the hash-table. That's probably ok, given default the default
+	 * fill-factor is relatively high. It'd be hard to meaningfully factor in
+	 * "double-in-size" growth policies here.
+	 */
+	return hashentrysize * dNumGroups;
+}
+
+/*
+ * create_grouping_paths
+ *
+ * Build a new upperrel containing Paths for grouping and/or aggregation.
+ *
+ * input_rel: contains the source-data Paths
+ * target: the pathtarget for the result Paths to compute
+ * agg_costs: cost info about all aggregates in query (in AGGSPLIT_SIMPLE mode)
+ * rollup_lists: list of grouping sets, or NIL if not doing grouping sets
+ * rollup_groupclauses: list of grouping clauses for grouping sets,
+ *		or NIL if not doing grouping sets
+ *
+ * Note: all Paths in input_rel are expected to return the target computed
+ * by make_group_input_target.
+ *
+ * We need to consider sorted and hashed aggregation in the same function,
+ * because otherwise (1) it would be harder to throw an appropriate error
+ * message if neither way works, and (2) we should not allow hashtable size
+ * considerations to dissuade us from using hashing if sorting is not possible.
+ */
+static RelOptInfo *
+create_grouping_paths(PlannerInfo *root,
+					  RelOptInfo *input_rel,
+					  PathTarget *target,
+					  const AggClauseCosts *agg_costs,
+					  grouping_sets_data *gd)
+{
+	Query	   *parse = root->parse;
+	Path	   *cheapest_path = input_rel->cheapest_total_path;
+	RelOptInfo *grouped_rel;
+	PathTarget *partial_grouping_target = NULL;
+	AggClauseCosts agg_partial_costs;	/* parallel only */
+	AggClauseCosts agg_final_costs; /* parallel only */
+	Size		hashaggtablesize;
+	double		dNumGroups;
+	double		dNumPartialGroups = 0;
+	bool		can_hash;
+	bool		can_sort;
+	bool		try_parallel_aggregation;
+
+	ListCell   *lc;
+
+	/* For now, do all work in the (GROUP_AGG, NULL) upperrel */
+	grouped_rel = fetch_upper_rel(root, UPPERREL_GROUP_AGG, NULL);
+
+	/*
+	 * If the input relation is not parallel-safe, then the grouped relation
+	 * can't be parallel-safe, either.  Otherwise, it's parallel-safe if the
+	 * target list and HAVING quals are parallel-safe.
+	 */
+	if (input_rel->consider_parallel &&
+		is_parallel_safe(root, (Node *) target->exprs) &&
+		is_parallel_safe(root, (Node *) parse->havingQual))
+		grouped_rel->consider_parallel = true;
+
+	/*
+	 * If the input rel belongs to a single FDW, so does the grouped rel.
+	 */
+	grouped_rel->serverid = input_rel->serverid;
+	grouped_rel->userid = input_rel->userid;
+	grouped_rel->useridiscurrent = input_rel->useridiscurrent;
+	grouped_rel->fdwroutine = input_rel->fdwroutine;
+
+	/*
+	 * Check for degenerate grouping.
+	 */
+	if ((root->hasHavingQual || parse->groupingSets) &&
+		!parse->hasAggs && parse->groupClause == NIL)
+	{
+		/*
+		 * We have a HAVING qual and/or grouping sets, but no aggregates and
+		 * no GROUP BY (which implies that the grouping sets are all empty).
+		 *
+		 * This is a degenerate case in which we are supposed to emit either
+		 * zero or one row for each grouping set depending on whether HAVING
+		 * succeeds.  Furthermore, there cannot be any variables in either
+		 * HAVING or the targetlist, so we actually do not need the FROM table
+		 * at all!	We can just throw away the plan-so-far and generate a
+		 * Result node.  This is a sufficiently unusual corner case that it's
+		 * not worth contorting the structure of this module to avoid having
+		 * to generate the earlier paths in the first place.
+		 */
+		int			nrows = list_length(parse->groupingSets);
+		Path	   *path;
+
+		if (nrows > 1)
+		{
+			/*
+			 * Doesn't seem worthwhile writing code to cons up a
+			 * generate_series or a values scan to emit multiple rows. Instead
+			 * just make N clones and append them.  (With a volatile HAVING
+			 * clause, this means you might get between 0 and N output rows.
+			 * Offhand I think that's desired.)
+			 */
+			List	   *paths = NIL;
+
+			while (--nrows >= 0)
+			{
+				path = (Path *)
+					create_result_path(root, grouped_rel,
+									   target,
+									   (List *) parse->havingQual);
+				paths = lappend(paths, path);
+			}
+			path = (Path *)
+				create_append_path(grouped_rel,
+								   paths,
+								   NULL,
+								   0,
+								   NIL);
+			path->pathtarget = target;
+		}
+		else
+		{
+			/* No grouping sets, or just one, so one output row */
+			path = (Path *)
+				create_result_path(root, grouped_rel,
+								   target,
+								   (List *) parse->havingQual);
+		}
+
+		add_path(grouped_rel, path);
+
+		/* No need to consider any other alternatives. */
+		set_cheapest(grouped_rel);
+
+		return grouped_rel;
+	}
+
+	/*
+	 * Estimate number of groups.
+	 */
+	dNumGroups = get_number_of_groups(root,
+									  cheapest_path->rows,
+									  gd);
+
+	/*
+	 * Determine whether it's possible to perform sort-based implementations
+	 * of grouping.  (Note that if groupClause is empty,
+	 * grouping_is_sortable() is trivially true, and all the
+	 * pathkeys_contained_in() tests will succeed too, so that we'll consider
+	 * every surviving input path.)
+	 *
+	 * If we have grouping sets, we might be able to sort some but not all of
+	 * them; in this case, we need can_sort to be true as long as we must
+	 * consider any sorted-input plan.
+	 */
+	can_sort = (gd && gd->rollups != NIL)
+		|| grouping_is_sortable(parse->groupClause);
+
+	/*
+	 * Determine whether we should consider hash-based implementations of
+	 * grouping.
+	 *
+	 * Hashed aggregation only applies if we're grouping. If we have grouping
+	 * sets, some groups might be hashable but others not; in this case we set
+	 * can_hash true as long as there is nothing globally preventing us from
+	 * hashing (and we should therefore consider plans with hashes).
+	 *
+	 * Executor doesn't support hashed aggregation with DISTINCT or ORDER BY
+	 * aggregates.  (Doing so would imply storing *all* the input values in
+	 * the hash table, and/or running many sorts in parallel, either of which
+	 * seems like a certain loser.)  We similarly don't support ordered-set
+	 * aggregates in hashed aggregation, but that case is also included in the
+	 * numOrderedAggs count.
+	 *
+	 * Note: grouping_is_hashable() is much more expensive to check than the
+	 * other gating conditions, so we want to do it last.
+	 */
+	can_hash = (parse->groupClause != NIL &&
+				agg_costs->numOrderedAggs == 0 &&
+				(gd ? gd->any_hashable : grouping_is_hashable(parse->groupClause)));
+
+	/*
+	 * If grouped_rel->consider_parallel is true, then paths that we generate
+	 * for this grouping relation could be run inside of a worker, but that
+	 * doesn't mean we can actually use the PartialAggregate/FinalizeAggregate
+	 * execution strategy.  Figure that out.
+	 */
+	if (!grouped_rel->consider_parallel)
+	{
+		/* Not even parallel-safe. */
+		try_parallel_aggregation = false;
+	}
+	else if (input_rel->partial_pathlist == NIL)
+	{
+		/* Nothing to use as input for partial aggregate. */
+		try_parallel_aggregation = false;
+	}
+	else if (!parse->hasAggs && parse->groupClause == NIL)
+	{
+		/*
+		 * We don't know how to do parallel aggregation unless we have either
+		 * some aggregates or a grouping clause.
+		 */
+		try_parallel_aggregation = false;
+	}
+	else if (parse->groupingSets)
+	{
+		/* We don't know how to do grouping sets in parallel. */
+		try_parallel_aggregation = false;
+	}
+	else if (agg_costs->hasNonPartial || agg_costs->hasNonSerial)
+	{
+		/* Insufficient support for partial mode. */
+		try_parallel_aggregation = false;
+	}
+	else
+	{
+		/* Everything looks good. */
+		try_parallel_aggregation = true;
+	}
+
+	/*
+	 * Before generating paths for grouped_rel, we first generate any possible
+	 * partial paths; that way, later code can easily consider both parallel
+	 * and non-parallel approaches to grouping.  Note that the partial paths
+	 * we generate here are also partially aggregated, so simply pushing a
+	 * Gather node on top is insufficient to create a final path, as would be
+	 * the case for a scan/join rel.
+	 */
+	if (try_parallel_aggregation)
+	{
+		Path	   *cheapest_partial_path = linitial(input_rel->partial_pathlist);
+
+		/*
+		 * Build target list for partial aggregate paths.  These paths cannot
+		 * just emit the same tlist as regular aggregate paths, because (1) we
+		 * must include Vars and Aggrefs needed in HAVING, which might not
+		 * appear in the result tlist, and (2) the Aggrefs must be set in
+		 * partial mode.
+		 */
+		partial_grouping_target = make_partial_grouping_target(root, target);
+
+		/* Estimate number of partial groups. */
+		dNumPartialGroups = get_number_of_groups(root,
+												 cheapest_partial_path->rows,
+												 gd);
+
+		/*
+		 * Collect statistics about aggregates for estimating costs of
+		 * performing aggregation in parallel.
+		 */
+		MemSet(&agg_partial_costs, 0, sizeof(AggClauseCosts));
+		MemSet(&agg_final_costs, 0, sizeof(AggClauseCosts));
+		if (parse->hasAggs)
+		{
+			/* partial phase */
+			get_agg_clause_costs(root, (Node *) partial_grouping_target->exprs,
+								 AGGSPLIT_INITIAL_SERIAL,
+								 &agg_partial_costs);
+
+			/* final phase */
+			get_agg_clause_costs(root, (Node *) target->exprs,
+								 AGGSPLIT_FINAL_DESERIAL,
+								 &agg_final_costs);
+			get_agg_clause_costs(root, parse->havingQual,
+								 AGGSPLIT_FINAL_DESERIAL,
+								 &agg_final_costs);
+		}
+
+		if (can_sort)
+		{
+			/* This was checked before setting try_parallel_aggregation */
+			Assert(parse->hasAggs || parse->groupClause);
+
+			/*
+			 * Use any available suitably-sorted path as input, and also
+			 * consider sorting the cheapest partial path.
+			 */
+			foreach(lc, input_rel->partial_pathlist)
+			{
+				Path	   *path = (Path *) lfirst(lc);
+				bool		is_sorted;
+
+				is_sorted = pathkeys_contained_in(root->group_pathkeys,
+												  path->pathkeys);
+				if (path == cheapest_partial_path || is_sorted)
+				{
+					/* Sort the cheapest partial path, if it isn't already */
+					if (!is_sorted)
+						path = (Path *) create_sort_path(root,
+														 grouped_rel,
+														 path,
+														 root->group_pathkeys,
+														 -1.0);
+
+					if (parse->hasAggs)
+						add_partial_path(grouped_rel, (Path *)
+										 create_agg_path(root,
+														 grouped_rel,
+														 path,
+														 partial_grouping_target,
+														 parse->groupClause ? AGG_SORTED : AGG_PLAIN,
+														 AGGSPLIT_INITIAL_SERIAL,
+														 parse->groupClause,
+														 NIL,
+														 &agg_partial_costs,
+														 dNumPartialGroups));
+					else
+						add_partial_path(grouped_rel, (Path *)
+										 create_group_path(root,
+														   grouped_rel,
+														   path,
+														   partial_grouping_target,
+														   parse->groupClause,
+														   NIL,
+														   dNumPartialGroups));
+				}
+			}
+		}
+
+		if (can_hash)
+		{
+			/* Checked above */
+			Assert(parse->hasAggs || parse->groupClause);
+
+			hashaggtablesize =
+				estimate_hashagg_tablesize(cheapest_partial_path,
+										   &agg_partial_costs,
+										   dNumPartialGroups);
+
+			/*
+			 * Tentatively produce a partial HashAgg Path, depending on if it
+			 * looks as if the hash table will fit in work_mem.
+			 */
+			if (hashaggtablesize < work_mem * 1024L)
+			{
+				add_partial_path(grouped_rel, (Path *)
+								 create_agg_path(root,
+												 grouped_rel,
+												 cheapest_partial_path,
+												 partial_grouping_target,
+												 AGG_HASHED,
+												 AGGSPLIT_INITIAL_SERIAL,
+												 parse->groupClause,
+												 NIL,
+												 &agg_partial_costs,
+												 dNumPartialGroups));
+			}
+		}
+	}
+
+	/* Build final grouping paths */
+	if (can_sort)
+	{
+		/*
+		 * Use any available suitably-sorted path as input, and also consider
+		 * sorting the cheapest-total path.
+		 */
+		foreach(lc, input_rel->pathlist)
+		{
+			Path	   *path = (Path *) lfirst(lc);
+			bool		is_sorted;
+
+			is_sorted = pathkeys_contained_in(root->group_pathkeys,
+											  path->pathkeys);
+			if (path == cheapest_path || is_sorted)
+			{
+				/* Sort the cheapest-total path if it isn't already sorted */
+				if (!is_sorted)
+					path = (Path *) create_sort_path(root,
+													 grouped_rel,
+													 path,
+													 root->group_pathkeys,
+													 -1.0);
+
+				/* Now decide what to stick atop it */
+				if (parse->groupingSets)
+				{
+					consider_groupingsets_paths(root, grouped_rel,
+												path, true, can_hash, target,
+												gd, agg_costs, dNumGroups);
+				}
+				else if (parse->hasAggs)
+				{
+					/*
+					 * We have aggregation, possibly with plain GROUP BY. Make
+					 * an AggPath.
+					 */
+					add_path(grouped_rel, (Path *)
+							 create_agg_path(root,
+											 grouped_rel,
+											 path,
+											 target,
+											 parse->groupClause ? AGG_SORTED : AGG_PLAIN,
+											 AGGSPLIT_SIMPLE,
+											 parse->groupClause,
+											 (List *) parse->havingQual,
+											 agg_costs,
+											 dNumGroups));
+				}
+				else if (parse->groupClause)
+				{
+					/*
+					 * We have GROUP BY without aggregation or grouping sets.
+					 * Make a GroupPath.
+					 */
+					add_path(grouped_rel, (Path *)
+							 create_group_path(root,
+											   grouped_rel,
+											   path,
+											   target,
+											   parse->groupClause,
+											   (List *) parse->havingQual,
+											   dNumGroups));
+				}
+				else
+				{
+					/* Other cases should have been handled above */
+					Assert(false);
+				}
+			}
+		}
+
+		/*
+		 * Now generate a complete GroupAgg Path atop of the cheapest partial
+		 * path.  We can do this using either Gather or Gather Merge.
+		 */
+		if (grouped_rel->partial_pathlist)
+		{
+			Path	   *path = (Path *) linitial(grouped_rel->partial_pathlist);
+			double		total_groups = path->rows * path->parallel_workers;
+
+			path = (Path *) create_gather_path(root,
+											   grouped_rel,
+											   path,
+											   partial_grouping_target,
+											   NULL,
+											   &total_groups);
+
+			/*
+			 * Since Gather's output is always unsorted, we'll need to sort,
+			 * unless there's no GROUP BY clause or a degenerate (constant)
+			 * one, in which case there will only be a single group.
+			 */
+			if (root->group_pathkeys)
+				path = (Path *) create_sort_path(root,
+												 grouped_rel,
+												 path,
+												 root->group_pathkeys,
+												 -1.0);
+
+			if (parse->hasAggs)
+				add_path(grouped_rel, (Path *)
+						 create_agg_path(root,
+										 grouped_rel,
+										 path,
+										 target,
+										 parse->groupClause ? AGG_SORTED : AGG_PLAIN,
+										 AGGSPLIT_FINAL_DESERIAL,
+										 parse->groupClause,
+										 (List *) parse->havingQual,
+										 &agg_final_costs,
+										 dNumGroups));
+			else
+				add_path(grouped_rel, (Path *)
+						 create_group_path(root,
+										   grouped_rel,
+										   path,
+										   target,
+										   parse->groupClause,
+										   (List *) parse->havingQual,
+										   dNumGroups));
+
+			/*
+			 * The point of using Gather Merge rather than Gather is that it
+			 * can preserve the ordering of the input path, so there's no
+			 * reason to try it unless (1) it's possible to produce more than
+			 * one output row and (2) we want the output path to be ordered.
+			 */
+			if (parse->groupClause != NIL && root->group_pathkeys != NIL)
+			{
+				foreach(lc, grouped_rel->partial_pathlist)
+				{
+					Path	   *subpath = (Path *) lfirst(lc);
+					Path	   *gmpath;
+					double		total_groups;
+
+					/*
+					 * It's useful to consider paths that are already properly
+					 * ordered for Gather Merge, because those don't need a
+					 * sort.  It's also useful to consider the cheapest path,
+					 * because sorting it in parallel and then doing Gather
+					 * Merge may be better than doing an unordered Gather
+					 * followed by a sort.  But there's no point in
+					 * considering non-cheapest paths that aren't already
+					 * sorted correctly.
+					 */
+					if (path != subpath &&
+						!pathkeys_contained_in(root->group_pathkeys,
+											   subpath->pathkeys))
+						continue;
+
+					total_groups = subpath->rows * subpath->parallel_workers;
+
+					gmpath = (Path *)
+						create_gather_merge_path(root,
+												 grouped_rel,
+												 subpath,
+												 partial_grouping_target,
+												 root->group_pathkeys,
+												 NULL,
+												 &total_groups);
+
+					if (parse->hasAggs)
+						add_path(grouped_rel, (Path *)
+								 create_agg_path(root,
+												 grouped_rel,
+												 gmpath,
+												 target,
+												 parse->groupClause ? AGG_SORTED : AGG_PLAIN,
+												 AGGSPLIT_FINAL_DESERIAL,
+												 parse->groupClause,
+												 (List *) parse->havingQual,
+												 &agg_final_costs,
+												 dNumGroups));
+					else
+						add_path(grouped_rel, (Path *)
+								 create_group_path(root,
+												   grouped_rel,
+												   gmpath,
+												   target,
+												   parse->groupClause,
+												   (List *) parse->havingQual,
+												   dNumGroups));
+				}
+			}
+		}
+	}
+
+	if (can_hash)
+	{
+		if (parse->groupingSets)
+		{
+			/*
+			 * Try for a hash-only groupingsets path over unsorted input.
+			 */
+			consider_groupingsets_paths(root, grouped_rel,
+										cheapest_path, false, true, target,
+										gd, agg_costs, dNumGroups);
+		}
+		else
+		{
+			hashaggtablesize = estimate_hashagg_tablesize(cheapest_path,
+														  agg_costs,
+														  dNumGroups);
+
+			/*
+			 * Provided that the estimated size of the hashtable does not
+			 * exceed work_mem, we'll generate a HashAgg Path, although if we
+			 * were unable to sort above, then we'd better generate a Path, so
+			 * that we at least have one.
+			 */
+			if (hashaggtablesize < work_mem * 1024L ||
+				grouped_rel->pathlist == NIL)
+			{
+				/*
+				 * We just need an Agg over the cheapest-total input path,
+				 * since input order won't matter.
+				 */
+				add_path(grouped_rel, (Path *)
+						 create_agg_path(root, grouped_rel,
+										 cheapest_path,
+										 target,
+										 AGG_HASHED,
+										 AGGSPLIT_SIMPLE,
+										 parse->groupClause,
+										 (List *) parse->havingQual,
+										 agg_costs,
+										 dNumGroups));
+			}
+		}
+
+		/*
+		 * Generate a HashAgg Path atop of the cheapest partial path. Once
+		 * again, we'll only do this if it looks as though the hash table
+		 * won't exceed work_mem.
+		 */
+		if (grouped_rel->partial_pathlist)
+		{
+			Path	   *path = (Path *) linitial(grouped_rel->partial_pathlist);
+
+			hashaggtablesize = estimate_hashagg_tablesize(path,
+														  &agg_final_costs,
+														  dNumGroups);
+
+			if (hashaggtablesize < work_mem * 1024L)
+			{
+				double		total_groups = path->rows * path->parallel_workers;
+
+				path = (Path *) create_gather_path(root,
+												   grouped_rel,
+												   path,
+												   partial_grouping_target,
+												   NULL,
+												   &total_groups);
+
+				add_path(grouped_rel, (Path *)
+						 create_agg_path(root,
+										 grouped_rel,
+										 path,
+										 target,
+										 AGG_HASHED,
+										 AGGSPLIT_FINAL_DESERIAL,
+										 parse->groupClause,
+										 (List *) parse->havingQual,
+										 &agg_final_costs,
+										 dNumGroups));
+			}
+		}
+	}
+
+	/* Give a helpful error if we failed to find any implementation */
+	if (grouped_rel->pathlist == NIL)
+		ereport(ERROR,
+				(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
+				 errmsg("could not implement GROUP BY"),
+				 errdetail("Some of the datatypes only support hashing, while others only support sorting.")));
+
+	/*
+	 * If there is an FDW that's responsible for all baserels of the query,
+	 * let it consider adding ForeignPaths.
+	 */
+	if (grouped_rel->fdwroutine &&
+		grouped_rel->fdwroutine->GetForeignUpperPaths)
+		grouped_rel->fdwroutine->GetForeignUpperPaths(root, UPPERREL_GROUP_AGG,
+													  input_rel, grouped_rel);
+
+	/* Let extensions possibly add some more paths */
+	if (create_upper_paths_hook)
+		(*create_upper_paths_hook) (root, UPPERREL_GROUP_AGG,
+									input_rel, grouped_rel);
+
+	/* Now choose the best path(s) */
+	set_cheapest(grouped_rel);
+
+	/*
+	 * We've been using the partial pathlist for the grouped relation to hold
+	 * partially aggregated paths, but that's actually a little bit bogus
+	 * because it's unsafe for later planning stages -- like ordered_rel ---
+	 * to get the idea that they can use these partial paths as if they didn't
+	 * need a FinalizeAggregate step.  Zap the partial pathlist at this stage
+	 * so we don't get confused.
+	 */
+	grouped_rel->partial_pathlist = NIL;
+
+	return grouped_rel;
+}
+
+
+/*
+ * For a given input path, consider the possible ways of doing grouping sets on
+ * it, by combinations of hashing and sorting.  This can be called multiple
+ * times, so it's important that it not scribble on input.  No result is
+ * returned, but any generated paths are added to grouped_rel.
+ */
+static void
+consider_groupingsets_paths(PlannerInfo *root,
+							RelOptInfo *grouped_rel,
+							Path *path,
+							bool is_sorted,
+							bool can_hash,
+							PathTarget *target,
+							grouping_sets_data *gd,
+							const AggClauseCosts *agg_costs,
+							double dNumGroups)
+{
+	Query	   *parse = root->parse;
+
+	/*
+	 * If we're not being offered sorted input, then only consider plans that
+	 * can be done entirely by hashing.
+	 *
+	 * We can hash everything if it looks like it'll fit in work_mem. But if
+	 * the input is actually sorted despite not being advertised as such, we
+	 * prefer to make use of that in order to use less memory.
+	 *
+	 * If none of the grouping sets are sortable, then ignore the work_mem
+	 * limit and generate a path anyway, since otherwise we'll just fail.
+	 */
+	if (!is_sorted)
+	{
+		List	   *new_rollups = NIL;
+		RollupData *unhashed_rollup = NULL;
+		List	   *sets_data;
+		List	   *empty_sets_data = NIL;
+		List	   *empty_sets = NIL;
+		ListCell   *lc;
+		ListCell   *l_start = list_head(gd->rollups);
+		AggStrategy strat = AGG_HASHED;
+		Size		hashsize;
+		double		exclude_groups = 0.0;
+
+		Assert(can_hash);
+
+		if (pathkeys_contained_in(root->group_pathkeys, path->pathkeys))
+		{
+			unhashed_rollup = lfirst(l_start);
+			exclude_groups = unhashed_rollup->numGroups;
+			l_start = lnext(l_start);
+		}
+
+		hashsize = estimate_hashagg_tablesize(path,
+											  agg_costs,
+											  dNumGroups - exclude_groups);
+
+		/*
+		 * gd->rollups is empty if we have only unsortable columns to work
+		 * with.  Override work_mem in that case; otherwise, we'll rely on the
+		 * sorted-input case to generate usable mixed paths.
+		 */
+		if (hashsize > work_mem * 1024L && gd->rollups)
+			return;				/* nope, won't fit */
+
+		/*
+		 * We need to burst the existing rollups list into individual grouping
+		 * sets and recompute a groupClause for each set.
+		 */
+		sets_data = list_copy(gd->unsortable_sets);
+
+		for_each_cell(lc, l_start)
+		{
+			RollupData *rollup = lfirst(lc);
+
+			/*
+			 * If we find an unhashable rollup that's not been skipped by the
+			 * "actually sorted" check above, we can't cope; we'd need sorted
+			 * input (with a different sort order) but we can't get that here.
+			 * So bail out; we'll get a valid path from the is_sorted case
+			 * instead.
+			 *
+			 * The mere presence of empty grouping sets doesn't make a rollup
+			 * unhashable (see preprocess_grouping_sets), we handle those
+			 * specially below.
+			 */
+			if (!rollup->hashable)
+				return;
+			else
+				sets_data = list_concat(sets_data, list_copy(rollup->gsets_data));
+		}
+		foreach(lc, sets_data)
+		{
+			GroupingSetData *gs = lfirst(lc);
+			List	   *gset = gs->set;
+			RollupData *rollup;
+
+			if (gset == NIL)
+			{
+				/* Empty grouping sets can't be hashed. */
+				empty_sets_data = lappend(empty_sets_data, gs);
+				empty_sets = lappend(empty_sets, NIL);
+			}
+			else
+			{
+				rollup = makeNode(RollupData);
+
+				rollup->groupClause = preprocess_groupclause(root, gset);
+				rollup->gsets_data = list_make1(gs);
+				rollup->gsets = remap_to_groupclause_idx(rollup->groupClause,
+														 rollup->gsets_data,
+														 gd->tleref_to_colnum_map);
+				rollup->numGroups = gs->numGroups;
+				rollup->hashable = true;
+				rollup->is_hashed = true;
+				new_rollups = lappend(new_rollups, rollup);
+			}
+		}
+
+		/*
+		 * If we didn't find anything nonempty to hash, then bail.  We'll
+		 * generate a path from the is_sorted case.
+		 */
+		if (new_rollups == NIL)
+			return;
+
+		/*
+		 * If there were empty grouping sets they should have been in the
+		 * first rollup.
+		 */
+		Assert(!unhashed_rollup || !empty_sets);
+
+		if (unhashed_rollup)
+		{
+			new_rollups = lappend(new_rollups, unhashed_rollup);
+			strat = AGG_MIXED;
+		}
+		else if (empty_sets)
+		{
+			RollupData *rollup = makeNode(RollupData);
+
+			rollup->groupClause = NIL;
+			rollup->gsets_data = empty_sets_data;
+			rollup->gsets = empty_sets;
+			rollup->numGroups = list_length(empty_sets);
+			rollup->hashable = false;
+			rollup->is_hashed = false;
+			new_rollups = lappend(new_rollups, rollup);
+			strat = AGG_MIXED;
+		}
+
+		add_path(grouped_rel, (Path *)
+				 create_groupingsets_path(root,
+										  grouped_rel,
+										  path,
+										  target,
+										  (List *) parse->havingQual,
+										  strat,
+										  new_rollups,
+										  agg_costs,
+										  dNumGroups));
+		return;
+	}
+
+	/*
+	 * If we have sorted input but nothing we can do with it, bail.
+	 */
+	if (list_length(gd->rollups) == 0)
+		return;
+
+	/*
+	 * Given sorted input, we try and make two paths: one sorted and one mixed
+	 * sort/hash. (We need to try both because hashagg might be disabled, or
+	 * some columns might not be sortable.)
+	 *
+	 * can_hash is passed in as false if some obstacle elsewhere (such as
+	 * ordered aggs) means that we shouldn't consider hashing at all.
+	 */
+	if (can_hash && gd->any_hashable)
+	{
+		List	   *rollups = NIL;
+		List	   *hash_sets = list_copy(gd->unsortable_sets);
+		double		availspace = (work_mem * 1024.0);
+		ListCell   *lc;
+
+		/*
+		 * Account first for space needed for groups we can't sort at all.
+		 */
+		availspace -= (double) estimate_hashagg_tablesize(path,
+														  agg_costs,
+														  gd->dNumHashGroups);
+
+		if (availspace > 0 && list_length(gd->rollups) > 1)
+		{
+			double		scale;
+			int			num_rollups = list_length(gd->rollups);
+			int			k_capacity;
+			int		   *k_weights = palloc(num_rollups * sizeof(int));
+			Bitmapset  *hash_items = NULL;
+			int			i;
+
+			/*
+			 * We treat this as a knapsack problem: the knapsack capacity
+			 * represents work_mem, the item weights are the estimated memory
+			 * usage of the hashtables needed to implement a single rollup,
+			 * and we really ought to use the cost saving as the item value;
+			 * however, currently the costs assigned to sort nodes don't
+			 * reflect the comparison costs well, and so we treat all items as
+			 * of equal value (each rollup we hash instead saves us one sort).
+			 *
+			 * To use the discrete knapsack, we need to scale the values to a
+			 * reasonably small bounded range.  We choose to allow a 5% error
+			 * margin; we have no more than 4096 rollups in the worst possible
+			 * case, which with a 5% error margin will require a bit over 42MB
+			 * of workspace. (Anyone wanting to plan queries that complex had
+			 * better have the memory for it.  In more reasonable cases, with
+			 * no more than a couple of dozen rollups, the memory usage will
+			 * be negligible.)
+			 *
+			 * k_capacity is naturally bounded, but we clamp the values for
+			 * scale and weight (below) to avoid overflows or underflows (or
+			 * uselessly trying to use a scale factor less than 1 byte).
+			 */
+			scale = Max(availspace / (20.0 * num_rollups), 1.0);
+			k_capacity = (int) floor(availspace / scale);
+
+			/*
+			 * We leave the first rollup out of consideration since it's the
+			 * one that matches the input sort order.  We assign indexes "i"
+			 * to only those entries considered for hashing; the second loop,
+			 * below, must use the same condition.
+			 */
+			i = 0;
+			for_each_cell(lc, lnext(list_head(gd->rollups)))
+			{
+				RollupData *rollup = lfirst(lc);
+
+				if (rollup->hashable)
+				{
+					double		sz = estimate_hashagg_tablesize(path,
+																agg_costs,
+																rollup->numGroups);
+
+					/*
+					 * If sz is enormous, but work_mem (and hence scale) is
+					 * small, avoid integer overflow here.
+					 */
+					k_weights[i] = (int) Min(floor(sz / scale),
+											 k_capacity + 1.0);
+					++i;
+				}
+			}
+
+			/*
+			 * Apply knapsack algorithm; compute the set of items which
+			 * maximizes the value stored (in this case the number of sorts
+			 * saved) while keeping the total size (approximately) within
+			 * capacity.
+			 */
+			if (i > 0)
+				hash_items = DiscreteKnapsack(k_capacity, i, k_weights, NULL);
+
+			if (!bms_is_empty(hash_items))
+			{
+				rollups = list_make1(linitial(gd->rollups));
+
+				i = 0;
+				for_each_cell(lc, lnext(list_head(gd->rollups)))
+				{
+					RollupData *rollup = lfirst(lc);
+
+					if (rollup->hashable)
+					{
+						if (bms_is_member(i, hash_items))
+							hash_sets = list_concat(hash_sets,
+													list_copy(rollup->gsets_data));
+						else
+							rollups = lappend(rollups, rollup);
+						++i;
+					}
+					else
+						rollups = lappend(rollups, rollup);
+				}
+			}
+		}
+
+		if (!rollups && hash_sets)
+			rollups = list_copy(gd->rollups);
+
+		foreach(lc, hash_sets)
+		{
+			GroupingSetData *gs = lfirst(lc);
+			RollupData *rollup = makeNode(RollupData);
+
+			Assert(gs->set != NIL);
+
+			rollup->groupClause = preprocess_groupclause(root, gs->set);
+			rollup->gsets_data = list_make1(gs);
+			rollup->gsets = remap_to_groupclause_idx(rollup->groupClause,
+													 rollup->gsets_data,
+													 gd->tleref_to_colnum_map);
+			rollup->numGroups = gs->numGroups;
+			rollup->hashable = true;
+			rollup->is_hashed = true;
+			rollups = lcons(rollup, rollups);
+		}
+
+		if (rollups)
+		{
+			add_path(grouped_rel, (Path *)
+					 create_groupingsets_path(root,
+											  grouped_rel,
+											  path,
+											  target,
+											  (List *) parse->havingQual,
+											  AGG_MIXED,
+											  rollups,
+											  agg_costs,
+											  dNumGroups));
+		}
+	}
+
+	/*
+	 * Now try the simple sorted case.
+	 */
+	if (!gd->unsortable_sets)
+		add_path(grouped_rel, (Path *)
+				 create_groupingsets_path(root,
+										  grouped_rel,
+										  path,
+										  target,
+										  (List *) parse->havingQual,
+										  AGG_SORTED,
+										  gd->rollups,
+										  agg_costs,
+										  dNumGroups));
+}
+
+/*
+ * create_window_paths
+ *
+ * Build a new upperrel containing Paths for window-function evaluation.
+ *
+ * input_rel: contains the source-data Paths
+ * input_target: result of make_window_input_target
+ * output_target: what the topmost WindowAggPath should return
+ * tlist: query's target list (needed to look up pathkeys)
+ * wflists: result of find_window_functions
+ * activeWindows: result of select_active_windows
+ *
+ * Note: all Paths in input_rel are expected to return input_target.
+ */
+static RelOptInfo *
+create_window_paths(PlannerInfo *root,
+					RelOptInfo *input_rel,
+					PathTarget *input_target,
+					PathTarget *output_target,
+					List *tlist,
+					WindowFuncLists *wflists,
+					List *activeWindows)
+{
+	RelOptInfo *window_rel;
+	ListCell   *lc;
+
+	/* For now, do all work in the (WINDOW, NULL) upperrel */
+	window_rel = fetch_upper_rel(root, UPPERREL_WINDOW, NULL);
+
+	/*
+	 * If the input relation is not parallel-safe, then the window relation
+	 * can't be parallel-safe, either.  Otherwise, we need to examine the
+	 * target list and active windows for non-parallel-safe constructs.
+	 */
+	if (input_rel->consider_parallel &&
+		is_parallel_safe(root, (Node *) output_target->exprs) &&
+		is_parallel_safe(root, (Node *) activeWindows))
+		window_rel->consider_parallel = true;
+
+	/*
+	 * If the input rel belongs to a single FDW, so does the window rel.
+	 */
+	window_rel->serverid = input_rel->serverid;
+	window_rel->userid = input_rel->userid;
+	window_rel->useridiscurrent = input_rel->useridiscurrent;
+	window_rel->fdwroutine = input_rel->fdwroutine;
+
+	/*
+	 * Consider computing window functions starting from the existing
+	 * cheapest-total path (which will likely require a sort) as well as any
+	 * existing paths that satisfy root->window_pathkeys (which won't).
+	 */
+	foreach(lc, input_rel->pathlist)
+	{
+		Path	   *path = (Path *) lfirst(lc);
+
+		if (path == input_rel->cheapest_total_path ||
+			pathkeys_contained_in(root->window_pathkeys, path->pathkeys))
+			create_one_window_path(root,
+								   window_rel,
+								   path,
+								   input_target,
+								   output_target,
+								   tlist,
+								   wflists,
+								   activeWindows);
+	}
+
+	/*
+	 * If there is an FDW that's responsible for all baserels of the query,
+	 * let it consider adding ForeignPaths.
+	 */
+	if (window_rel->fdwroutine &&
+		window_rel->fdwroutine->GetForeignUpperPaths)
+		window_rel->fdwroutine->GetForeignUpperPaths(root, UPPERREL_WINDOW,
+													 input_rel, window_rel);
+
+	/* Let extensions possibly add some more paths */
+	if (create_upper_paths_hook)
+		(*create_upper_paths_hook) (root, UPPERREL_WINDOW,
+									input_rel, window_rel);
+
+	/* Now choose the best path(s) */
+	set_cheapest(window_rel);
+
+	return window_rel;
+}
+
+/*
+ * Stack window-function implementation steps atop the given Path, and
+ * add the result to window_rel.
+ *
+ * window_rel: upperrel to contain result
+ * path: input Path to use (must return input_target)
+ * input_target: result of make_window_input_target
+ * output_target: what the topmost WindowAggPath should return
+ * tlist: query's target list (needed to look up pathkeys)
+ * wflists: result of find_window_functions
+ * activeWindows: result of select_active_windows
+ */
+static void
+create_one_window_path(PlannerInfo *root,
+					   RelOptInfo *window_rel,
+					   Path *path,
+					   PathTarget *input_target,
+					   PathTarget *output_target,
+					   List *tlist,
+					   WindowFuncLists *wflists,
+					   List *activeWindows)
+{
+	PathTarget *window_target;
+	ListCell   *l;
+
+	/*
+	 * Since each window clause could require a different sort order, we stack
+	 * up a WindowAgg node for each clause, with sort steps between them as
+	 * needed.  (We assume that select_active_windows chose a good order for
+	 * executing the clauses in.)
+	 *
+	 * input_target should contain all Vars and Aggs needed for the result.
+	 * (In some cases we wouldn't need to propagate all of these all the way
+	 * to the top, since they might only be needed as inputs to WindowFuncs.
+	 * It's probably not worth trying to optimize that though.)  It must also
+	 * contain all window partitioning and sorting expressions, to ensure
+	 * they're computed only once at the bottom of the stack (that's critical
+	 * for volatile functions).  As we climb up the stack, we'll add outputs
+	 * for the WindowFuncs computed at each level.
+	 */
+	window_target = input_target;
+
+	foreach(l, activeWindows)
+	{
+		WindowClause *wc = (WindowClause *) lfirst(l);
+		List	   *window_pathkeys;
+
+		window_pathkeys = make_pathkeys_for_window(root,
+												   wc,
+												   tlist);
+
+		/* Sort if necessary */
+		if (!pathkeys_contained_in(window_pathkeys, path->pathkeys))
+		{
+			path = (Path *) create_sort_path(root, window_rel,
+											 path,
+											 window_pathkeys,
+											 -1.0);
+		}
+
+		if (lnext(l))
+		{
+			/*
+			 * Add the current WindowFuncs to the output target for this
+			 * intermediate WindowAggPath.  We must copy window_target to
+			 * avoid changing the previous path's target.
+			 *
+			 * Note: a WindowFunc adds nothing to the target's eval costs; but
+			 * we do need to account for the increase in tlist width.
+			 */
+			ListCell   *lc2;
+
+			window_target = copy_pathtarget(window_target);
+			foreach(lc2, wflists->windowFuncs[wc->winref])
+			{
+				WindowFunc *wfunc = lfirst_node(WindowFunc, lc2);
+
+				add_column_to_pathtarget(window_target, (Expr *) wfunc, 0);
+				window_target->width += get_typavgwidth(wfunc->wintype, -1);
+			}
+		}
+		else
+		{
+			/* Install the goal target in the topmost WindowAgg */
+			window_target = output_target;
+		}
+
+		path = (Path *)
+			create_windowagg_path(root, window_rel, path, window_target,
+								  wflists->windowFuncs[wc->winref],
+								  wc,
+								  window_pathkeys);
+	}
+
+	add_path(window_rel, path);
+}
+
+/*
+ * create_distinct_paths
+ *
+ * Build a new upperrel containing Paths for SELECT DISTINCT evaluation.
+ *
+ * input_rel: contains the source-data Paths
+ *
+ * Note: input paths should already compute the desired pathtarget, since
+ * Sort/Unique won't project anything.
+ */
+static RelOptInfo *
+create_distinct_paths(PlannerInfo *root,
+					  RelOptInfo *input_rel)
+{
+	Query	   *parse = root->parse;
+	Path	   *cheapest_input_path = input_rel->cheapest_total_path;
+	RelOptInfo *distinct_rel;
+	double		numDistinctRows;
+	bool		allow_hash;
+	Path	   *path;
+	ListCell   *lc;
+
+	/* For now, do all work in the (DISTINCT, NULL) upperrel */
+	distinct_rel = fetch_upper_rel(root, UPPERREL_DISTINCT, NULL);
+
+	/*
+	 * We don't compute anything at this level, so distinct_rel will be
+	 * parallel-safe if the input rel is parallel-safe.  In particular, if
+	 * there is a DISTINCT ON (...) clause, any path for the input_rel will
+	 * output those expressions, and will not be parallel-safe unless those
+	 * expressions are parallel-safe.
+	 */
+	distinct_rel->consider_parallel = input_rel->consider_parallel;
+
+	/*
+	 * If the input rel belongs to a single FDW, so does the distinct_rel.
+	 */
+	distinct_rel->serverid = input_rel->serverid;
+	distinct_rel->userid = input_rel->userid;
+	distinct_rel->useridiscurrent = input_rel->useridiscurrent;
+	distinct_rel->fdwroutine = input_rel->fdwroutine;
+
+	/* Estimate number of distinct rows there will be */
+	if (parse->groupClause || parse->groupingSets || parse->hasAggs ||
+		root->hasHavingQual)
+	{
+		/*
+		 * If there was grouping or aggregation, use the number of input rows
+		 * as the estimated number of DISTINCT rows (ie, assume the input is
+		 * already mostly unique).
+		 */
+		numDistinctRows = cheapest_input_path->rows;
+	}
+	else
+	{
+		/*
+		 * Otherwise, the UNIQUE filter has effects comparable to GROUP BY.
+		 */
+		List	   *distinctExprs;
+
+		distinctExprs = get_sortgrouplist_exprs(parse->distinctClause,
+												parse->targetList);
+		numDistinctRows = estimate_num_groups(root, distinctExprs,
+											  cheapest_input_path->rows,
+											  NULL);
+	}
+
+	/*
+	 * Consider sort-based implementations of DISTINCT, if possible.
+	 */
+	if (grouping_is_sortable(parse->distinctClause))
+	{
+		/*
+		 * First, if we have any adequately-presorted paths, just stick a
+		 * Unique node on those.  Then consider doing an explicit sort of the
+		 * cheapest input path and Unique'ing that.
+		 *
+		 * When we have DISTINCT ON, we must sort by the more rigorous of
+		 * DISTINCT and ORDER BY, else it won't have the desired behavior.
+		 * Also, if we do have to do an explicit sort, we might as well use
+		 * the more rigorous ordering to avoid a second sort later.  (Note
+		 * that the parser will have ensured that one clause is a prefix of
+		 * the other.)
+		 */
+		List	   *needed_pathkeys;
+
+		if (parse->hasDistinctOn &&
+			list_length(root->distinct_pathkeys) <
+			list_length(root->sort_pathkeys))
+			needed_pathkeys = root->sort_pathkeys;
+		else
+			needed_pathkeys = root->distinct_pathkeys;
+
+		foreach(lc, input_rel->pathlist)
+		{
+			Path	   *path = (Path *) lfirst(lc);
+
+			if (pathkeys_contained_in(needed_pathkeys, path->pathkeys))
+			{
+				add_path(distinct_rel, (Path *)
+						 create_upper_unique_path(root, distinct_rel,
+												  path,
+												  list_length(root->distinct_pathkeys),
+												  numDistinctRows));
+			}
+		}
+
+		/* For explicit-sort case, always use the more rigorous clause */
+		if (list_length(root->distinct_pathkeys) <
+			list_length(root->sort_pathkeys))
+		{
+			needed_pathkeys = root->sort_pathkeys;
+			/* Assert checks that parser didn't mess up... */
+			Assert(pathkeys_contained_in(root->distinct_pathkeys,
+										 needed_pathkeys));
+		}
+		else
+			needed_pathkeys = root->distinct_pathkeys;
+
+		path = cheapest_input_path;
+		if (!pathkeys_contained_in(needed_pathkeys, path->pathkeys))
+			path = (Path *) create_sort_path(root, distinct_rel,
+											 path,
+											 needed_pathkeys,
+											 -1.0);
+
+		add_path(distinct_rel, (Path *)
+				 create_upper_unique_path(root, distinct_rel,
+										  path,
+										  list_length(root->distinct_pathkeys),
+										  numDistinctRows));
+	}
+
+	/*
+	 * Consider hash-based implementations of DISTINCT, if possible.
+	 *
+	 * If we were not able to make any other types of path, we *must* hash or
+	 * die trying.  If we do have other choices, there are several things that
+	 * should prevent selection of hashing: if the query uses DISTINCT ON
+	 * (because it won't really have the expected behavior if we hash), or if
+	 * enable_hashagg is off, or if it looks like the hashtable will exceed
+	 * work_mem.
+	 *
+	 * Note: grouping_is_hashable() is much more expensive to check than the
+	 * other gating conditions, so we want to do it last.
+	 */
+	if (distinct_rel->pathlist == NIL)
+		allow_hash = true;		/* we have no alternatives */
+	else if (parse->hasDistinctOn || !enable_hashagg)
+		allow_hash = false;		/* policy-based decision not to hash */
+	else
+	{
+		Size		hashentrysize;
+
+		/* Estimate per-hash-entry space at tuple width... */
+		hashentrysize = MAXALIGN(cheapest_input_path->pathtarget->width) +
+			MAXALIGN(SizeofMinimalTupleHeader);
+		/* plus the per-hash-entry overhead */
+		hashentrysize += hash_agg_entry_size(0);
+
+		/* Allow hashing only if hashtable is predicted to fit in work_mem */
+		allow_hash = (hashentrysize * numDistinctRows <= work_mem * 1024L);
+	}
+
+	if (allow_hash && grouping_is_hashable(parse->distinctClause))
+	{
+		/* Generate hashed aggregate path --- no sort needed */
+		add_path(distinct_rel, (Path *)
+				 create_agg_path(root,
+								 distinct_rel,
+								 cheapest_input_path,
+								 cheapest_input_path->pathtarget,
+								 AGG_HASHED,
+								 AGGSPLIT_SIMPLE,
+								 parse->distinctClause,
+								 NIL,
+								 NULL,
+								 numDistinctRows));
+	}
+
+	/* Give a helpful error if we failed to find any implementation */
+	if (distinct_rel->pathlist == NIL)
+		ereport(ERROR,
+				(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
+				 errmsg("could not implement DISTINCT"),
+				 errdetail("Some of the datatypes only support hashing, while others only support sorting.")));
+
+	/*
+	 * If there is an FDW that's responsible for all baserels of the query,
+	 * let it consider adding ForeignPaths.
+	 */
+	if (distinct_rel->fdwroutine &&
+		distinct_rel->fdwroutine->GetForeignUpperPaths)
+		distinct_rel->fdwroutine->GetForeignUpperPaths(root, UPPERREL_DISTINCT,
+													   input_rel, distinct_rel);
+
+	/* Let extensions possibly add some more paths */
+	if (create_upper_paths_hook)
+		(*create_upper_paths_hook) (root, UPPERREL_DISTINCT,
+									input_rel, distinct_rel);
+
+	/* Now choose the best path(s) */
+	set_cheapest(distinct_rel);
+
+	return distinct_rel;
+}
+
+/*
+ * create_ordered_paths
+ *
+ * Build a new upperrel containing Paths for ORDER BY evaluation.
+ *
+ * All paths in the result must satisfy the ORDER BY ordering.
+ * The only new path we need consider is an explicit sort on the
+ * cheapest-total existing path.
+ *
+ * input_rel: contains the source-data Paths
+ * target: the output tlist the result Paths must emit
+ * limit_tuples: estimated bound on the number of output tuples,
+ *		or -1 if no LIMIT or couldn't estimate
+ */
+static RelOptInfo *
+create_ordered_paths(PlannerInfo *root,
+					 RelOptInfo *input_rel,
+					 PathTarget *target,
+					 double limit_tuples)
+{
+	Path	   *cheapest_input_path = input_rel->cheapest_total_path;
+	RelOptInfo *ordered_rel;
+	ListCell   *lc;
+
+	/* For now, do all work in the (ORDERED, NULL) upperrel */
+	ordered_rel = fetch_upper_rel(root, UPPERREL_ORDERED, NULL);
+
+	/*
+	 * If the input relation is not parallel-safe, then the ordered relation
+	 * can't be parallel-safe, either.  Otherwise, it's parallel-safe if the
+	 * target list is parallel-safe.
+	 */
+	if (input_rel->consider_parallel &&
+		is_parallel_safe(root, (Node *) target->exprs))
+		ordered_rel->consider_parallel = true;
+
+	/*
+	 * If the input rel belongs to a single FDW, so does the ordered_rel.
+	 */
+	ordered_rel->serverid = input_rel->serverid;
+	ordered_rel->userid = input_rel->userid;
+	ordered_rel->useridiscurrent = input_rel->useridiscurrent;
+	ordered_rel->fdwroutine = input_rel->fdwroutine;
+
+	foreach(lc, input_rel->pathlist)
+	{
+		Path	   *path = (Path *) lfirst(lc);
+		bool		is_sorted;
+
+		is_sorted = pathkeys_contained_in(root->sort_pathkeys,
+										  path->pathkeys);
+		if (path == cheapest_input_path || is_sorted)
+		{
+			if (!is_sorted)
+			{
+				/* An explicit sort here can take advantage of LIMIT */
+				path = (Path *) create_sort_path(root,
+												 ordered_rel,
+												 path,
+												 root->sort_pathkeys,
+												 limit_tuples);
+			}
+
+			/* Add projection step if needed */
+			if (path->pathtarget != target)
+				path = apply_projection_to_path(root, ordered_rel,
+												path, target);
+
+			add_path(ordered_rel, path);
+		}
+	}
+
+	/*
+	 * generate_gather_paths() will have already generated a simple Gather
+	 * path for the best parallel path, if any, and the loop above will have
+	 * considered sorting it.  Similarly, generate_gather_paths() will also
+	 * have generated order-preserving Gather Merge plans which can be used
+	 * without sorting if they happen to match the sort_pathkeys, and the loop
+	 * above will have handled those as well.  However, there's one more
+	 * possibility: it may make sense to sort the cheapest partial path
+	 * according to the required output order and then use Gather Merge.
+	 */
+	if (ordered_rel->consider_parallel && root->sort_pathkeys != NIL &&
+		input_rel->partial_pathlist != NIL)
+	{
+		Path	   *cheapest_partial_path;
+
+		cheapest_partial_path = linitial(input_rel->partial_pathlist);
+
+		/*
+		 * If cheapest partial path doesn't need a sort, this is redundant
+		 * with what's already been tried.
+		 */
+		if (!pathkeys_contained_in(root->sort_pathkeys,
+								   cheapest_partial_path->pathkeys))
+		{
+			Path	   *path;
+			double		total_groups;
+
+			path = (Path *) create_sort_path(root,
+											 ordered_rel,
+											 cheapest_partial_path,
+											 root->sort_pathkeys,
+											 -1.0);
+
+			total_groups = cheapest_partial_path->rows *
+				cheapest_partial_path->parallel_workers;
+			path = (Path *)
+				create_gather_merge_path(root, ordered_rel,
+										 path,
+										 target, root->sort_pathkeys, NULL,
+										 &total_groups);
+
+			/* Add projection step if needed */
+			if (path->pathtarget != target)
+				path = apply_projection_to_path(root, ordered_rel,
+												path, target);
+
+			add_path(ordered_rel, path);
+		}
+	}
+
+	/*
+	 * If there is an FDW that's responsible for all baserels of the query,
+	 * let it consider adding ForeignPaths.
+	 */
+	if (ordered_rel->fdwroutine &&
+		ordered_rel->fdwroutine->GetForeignUpperPaths)
+		ordered_rel->fdwroutine->GetForeignUpperPaths(root, UPPERREL_ORDERED,
+													  input_rel, ordered_rel);
+
+	/* Let extensions possibly add some more paths */
+	if (create_upper_paths_hook)
+		(*create_upper_paths_hook) (root, UPPERREL_ORDERED,
+									input_rel, ordered_rel);
+
+	/*
+	 * No need to bother with set_cheapest here; grouping_planner does not
+	 * need us to do it.
+	 */
+	Assert(ordered_rel->pathlist != NIL);
+
+	return ordered_rel;
+}
+
+
+/*
+ * make_group_input_target
+ *	  Generate appropriate PathTarget for initial input to grouping nodes.
+ *
+ * If there is grouping or aggregation, the scan/join subplan cannot emit
+ * the query's final targetlist; for example, it certainly can't emit any
+ * aggregate function calls.  This routine generates the correct target
+ * for the scan/join subplan.
+ *
+ * The query target list passed from the parser already contains entries
+ * for all ORDER BY and GROUP BY expressions, but it will not have entries
+ * for variables used only in HAVING clauses; so we need to add those
+ * variables to the subplan target list.  Also, we flatten all expressions
+ * except GROUP BY items into their component variables; other expressions
+ * will be computed by the upper plan nodes rather than by the subplan.
+ * For example, given a query like
+ *		SELECT a+b,SUM(c+d) FROM table GROUP BY a+b;
+ * we want to pass this targetlist to the subplan:
+ *		a+b,c,d
+ * where the a+b target will be used by the Sort/Group steps, and the
+ * other targets will be used for computing the final results.
+ *
+ * 'final_target' is the query's final target list (in PathTarget form)
+ *
+ * The result is the PathTarget to be computed by the Paths returned from
+ * query_planner().
+ */
+static PathTarget *
+make_group_input_target(PlannerInfo *root, PathTarget *final_target)
+{
+	Query	   *parse = root->parse;
+	PathTarget *input_target;
+	List	   *non_group_cols;
+	List	   *non_group_vars;
+	int			i;
+	ListCell   *lc;
+
+	/*
+	 * We must build a target containing all grouping columns, plus any other
+	 * Vars mentioned in the query's targetlist and HAVING qual.
+	 */
+	input_target = create_empty_pathtarget();
+	non_group_cols = NIL;
+
+	i = 0;
+	foreach(lc, final_target->exprs)
+	{
+		Expr	   *expr = (Expr *) lfirst(lc);
+		Index		sgref = get_pathtarget_sortgroupref(final_target, i);
+
+		if (sgref && parse->groupClause &&
+			get_sortgroupref_clause_noerr(sgref, parse->groupClause) != NULL)
+		{
+			/*
+			 * It's a grouping column, so add it to the input target as-is.
+			 */
+			add_column_to_pathtarget(input_target, expr, sgref);
+		}
+		else
+		{
+			/*
+			 * Non-grouping column, so just remember the expression for later
+			 * call to pull_var_clause.
+			 */
+			non_group_cols = lappend(non_group_cols, expr);
+		}
+
+		i++;
+	}
+
+	/*
+	 * If there's a HAVING clause, we'll need the Vars it uses, too.
+	 */
+	if (parse->havingQual)
+		non_group_cols = lappend(non_group_cols, parse->havingQual);
+
+	/*
+	 * Pull out all the Vars mentioned in non-group cols (plus HAVING), and
+	 * add them to the input target if not already present.  (A Var used
+	 * directly as a GROUP BY item will be present already.)  Note this
+	 * includes Vars used in resjunk items, so we are covering the needs of
+	 * ORDER BY and window specifications.  Vars used within Aggrefs and
+	 * WindowFuncs will be pulled out here, too.
+	 */
+	non_group_vars = pull_var_clause((Node *) non_group_cols,
+									 PVC_RECURSE_AGGREGATES |
+									 PVC_RECURSE_WINDOWFUNCS |
+									 PVC_INCLUDE_PLACEHOLDERS);
+	add_new_columns_to_pathtarget(input_target, non_group_vars);
+
+	/* clean up cruft */
+	list_free(non_group_vars);
+	list_free(non_group_cols);
+
+	/* XXX this causes some redundant cost calculation ... */
+	return set_pathtarget_cost_width(root, input_target);
+}
+
+/*
+ * make_partial_grouping_target
+ *	  Generate appropriate PathTarget for output of partial aggregate
+ *	  (or partial grouping, if there are no aggregates) nodes.
+ *
+ * A partial aggregation node needs to emit all the same aggregates that
+ * a regular aggregation node would, plus any aggregates used in HAVING;
+ * except that the Aggref nodes should be marked as partial aggregates.
+ *
+ * In addition, we'd better emit any Vars and PlaceholderVars that are
+ * used outside of Aggrefs in the aggregation tlist and HAVING.  (Presumably,
+ * these would be Vars that are grouped by or used in grouping expressions.)
+ *
+ * grouping_target is the tlist to be emitted by the topmost aggregation step.
+ * We get the HAVING clause out of *root.
+ */
+static PathTarget *
+make_partial_grouping_target(PlannerInfo *root, PathTarget *grouping_target)
+{
+	Query	   *parse = root->parse;
+	PathTarget *partial_target;
+	List	   *non_group_cols;
+	List	   *non_group_exprs;
+	int			i;
+	ListCell   *lc;
+
+	partial_target = create_empty_pathtarget();
+	non_group_cols = NIL;
+
+	i = 0;
+	foreach(lc, grouping_target->exprs)
+	{
+		Expr	   *expr = (Expr *) lfirst(lc);
+		Index		sgref = get_pathtarget_sortgroupref(grouping_target, i);
+
+		if (sgref && parse->groupClause &&
+			get_sortgroupref_clause_noerr(sgref, parse->groupClause) != NULL)
+		{
+			/*
+			 * It's a grouping column, so add it to the partial_target as-is.
+			 * (This allows the upper agg step to repeat the grouping calcs.)
+			 */
+			add_column_to_pathtarget(partial_target, expr, sgref);
+		}
+		else
+		{
+			/*
+			 * Non-grouping column, so just remember the expression for later
+			 * call to pull_var_clause.
+			 */
+			non_group_cols = lappend(non_group_cols, expr);
+		}
+
+		i++;
+	}
+
+	/*
+	 * If there's a HAVING clause, we'll need the Vars/Aggrefs it uses, too.
+	 */
+	if (parse->havingQual)
+		non_group_cols = lappend(non_group_cols, parse->havingQual);
+
+	/*
+	 * Pull out all the Vars, PlaceHolderVars, and Aggrefs mentioned in
+	 * non-group cols (plus HAVING), and add them to the partial_target if not
+	 * already present.  (An expression used directly as a GROUP BY item will
+	 * be present already.)  Note this includes Vars used in resjunk items, so
+	 * we are covering the needs of ORDER BY and window specifications.
+	 */
+	non_group_exprs = pull_var_clause((Node *) non_group_cols,
+									  PVC_INCLUDE_AGGREGATES |
+									  PVC_RECURSE_WINDOWFUNCS |
+									  PVC_INCLUDE_PLACEHOLDERS);
+
+	add_new_columns_to_pathtarget(partial_target, non_group_exprs);
+
+	/*
+	 * Adjust Aggrefs to put them in partial mode.  At this point all Aggrefs
+	 * are at the top level of the target list, so we can just scan the list
+	 * rather than recursing through the expression trees.
+	 */
+	foreach(lc, partial_target->exprs)
+	{
+		Aggref	   *aggref = (Aggref *) lfirst(lc);
+
+		if (IsA(aggref, Aggref))
+		{
+			Aggref	   *newaggref;
+
+			/*
+			 * We shouldn't need to copy the substructure of the Aggref node,
+			 * but flat-copy the node itself to avoid damaging other trees.
+			 */
+			newaggref = makeNode(Aggref);
+			memcpy(newaggref, aggref, sizeof(Aggref));
+
+			/* For now, assume serialization is required */
+			mark_partial_aggref(newaggref, AGGSPLIT_INITIAL_SERIAL);
+
+			lfirst(lc) = newaggref;
+		}
+	}
+
+	/* clean up cruft */
+	list_free(non_group_exprs);
+	list_free(non_group_cols);
+
+	/* XXX this causes some redundant cost calculation ... */
+	return set_pathtarget_cost_width(root, partial_target);
+}
+
+/*
+ * mark_partial_aggref
+ *	  Adjust an Aggref to make it represent a partial-aggregation step.
+ *
+ * The Aggref node is modified in-place; caller must do any copying required.
+ */
+void
+mark_partial_aggref(Aggref *agg, AggSplit aggsplit)
+{
+	/* aggtranstype should be computed by this point */
+	Assert(OidIsValid(agg->aggtranstype));
+	/* ... but aggsplit should still be as the parser left it */
+	Assert(agg->aggsplit == AGGSPLIT_SIMPLE);
+
+	/* Mark the Aggref with the intended partial-aggregation mode */
+	agg->aggsplit = aggsplit;
+
+	/*
+	 * Adjust result type if needed.  Normally, a partial aggregate returns
+	 * the aggregate's transition type; but if that's INTERNAL and we're
+	 * serializing, it returns BYTEA instead.
+	 */
+	if (DO_AGGSPLIT_SKIPFINAL(aggsplit))
+	{
+		if (agg->aggtranstype == INTERNALOID && DO_AGGSPLIT_SERIALIZE(aggsplit))
+			agg->aggtype = BYTEAOID;
+		else
+			agg->aggtype = agg->aggtranstype;
+	}
+}
+
+/*
+ * postprocess_setop_tlist
+ *	  Fix up targetlist returned by plan_set_operations().
+ *
+ * We need to transpose sort key info from the orig_tlist into new_tlist.
+ * NOTE: this would not be good enough if we supported resjunk sort keys
+ * for results of set operations --- then, we'd need to project a whole
+ * new tlist to evaluate the resjunk columns.  For now, just ereport if we
+ * find any resjunk columns in orig_tlist.
+ */
+static List *
+postprocess_setop_tlist(List *new_tlist, List *orig_tlist)
+{
+	ListCell   *l;
+	ListCell   *orig_tlist_item = list_head(orig_tlist);
+
+	foreach(l, new_tlist)
+	{
+		TargetEntry *new_tle = (TargetEntry *) lfirst(l);
+		TargetEntry *orig_tle;
+
+		/* ignore resjunk columns in setop result */
+		if (new_tle->resjunk)
+			continue;
+
+		Assert(orig_tlist_item != NULL);
+		orig_tle = (TargetEntry *) lfirst(orig_tlist_item);
+		orig_tlist_item = lnext(orig_tlist_item);
+		if (orig_tle->resjunk)	/* should not happen */
+			elog(ERROR, "resjunk output columns are not implemented");
+		Assert(new_tle->resno == orig_tle->resno);
+		new_tle->ressortgroupref = orig_tle->ressortgroupref;
+	}
+	if (orig_tlist_item != NULL)
+		elog(ERROR, "resjunk output columns are not implemented");
+	return new_tlist;
+}
+
+/*
+ * select_active_windows
+ *		Create a list of the "active" window clauses (ie, those referenced
+ *		by non-deleted WindowFuncs) in the order they are to be executed.
+ */
+static List *
+select_active_windows(PlannerInfo *root, WindowFuncLists *wflists)
+{
+	List	   *result;
+	List	   *actives;
+	ListCell   *lc;
+
+	/* First, make a list of the active windows */
+	actives = NIL;
+	foreach(lc, root->parse->windowClause)
+	{
+		WindowClause *wc = (WindowClause *) lfirst(lc);
+
+		/* It's only active if wflists shows some related WindowFuncs */
+		Assert(wc->winref <= wflists->maxWinRef);
+		if (wflists->windowFuncs[wc->winref] != NIL)
+			actives = lappend(actives, wc);
+	}
+
+	/*
+	 * Now, ensure that windows with identical partitioning/ordering clauses
+	 * are adjacent in the list.  This is required by the SQL standard, which
+	 * says that only one sort is to be used for such windows, even if they
+	 * are otherwise distinct (eg, different names or framing clauses).
+	 *
+	 * There is room to be much smarter here, for example detecting whether
+	 * one window's sort keys are a prefix of another's (so that sorting for
+	 * the latter would do for the former), or putting windows first that
+	 * match a sort order available for the underlying query.  For the moment
+	 * we are content with meeting the spec.
+	 */
+	result = NIL;
+	while (actives != NIL)
+	{
+		WindowClause *wc = (WindowClause *) linitial(actives);
+		ListCell   *prev;
+		ListCell   *next;
+
+		/* Move wc from actives to result */
+		actives = list_delete_first(actives);
+		result = lappend(result, wc);
+
+		/* Now move any matching windows from actives to result */
+		prev = NULL;
+		for (lc = list_head(actives); lc; lc = next)
+		{
+			WindowClause *wc2 = (WindowClause *) lfirst(lc);
+
+			next = lnext(lc);
+			/* framing options are NOT to be compared here! */
+			if (equal(wc->partitionClause, wc2->partitionClause) &&
+				equal(wc->orderClause, wc2->orderClause))
+			{
+				actives = list_delete_cell(actives, lc, prev);
+				result = lappend(result, wc2);
+			}
+			else
+				prev = lc;
+		}
+	}
+
+	return result;
+}
+
+/*
+ * make_window_input_target
+ *	  Generate appropriate PathTarget for initial input to WindowAgg nodes.
+ *
+ * When the query has window functions, this function computes the desired
+ * target to be computed by the node just below the first WindowAgg.
+ * This tlist must contain all values needed to evaluate the window functions,
+ * compute the final target list, and perform any required final sort step.
+ * If multiple WindowAggs are needed, each intermediate one adds its window
+ * function results onto this base tlist; only the topmost WindowAgg computes
+ * the actual desired target list.
+ *
+ * This function is much like make_group_input_target, though not quite enough
+ * like it to share code.  As in that function, we flatten most expressions
+ * into their component variables.  But we do not want to flatten window
+ * PARTITION BY/ORDER BY clauses, since that might result in multiple
+ * evaluations of them, which would be bad (possibly even resulting in
+ * inconsistent answers, if they contain volatile functions).
+ * Also, we must not flatten GROUP BY clauses that were left unflattened by
+ * make_group_input_target, because we may no longer have access to the
+ * individual Vars in them.
+ *
+ * Another key difference from make_group_input_target is that we don't
+ * flatten Aggref expressions, since those are to be computed below the
+ * window functions and just referenced like Vars above that.
+ *
+ * 'final_target' is the query's final target list (in PathTarget form)
+ * 'activeWindows' is the list of active windows previously identified by
+ *			select_active_windows.
+ *
+ * The result is the PathTarget to be computed by the plan node immediately
+ * below the first WindowAgg node.
+ */
+static PathTarget *
+make_window_input_target(PlannerInfo *root,
+						 PathTarget *final_target,
+						 List *activeWindows)
+{
+	Query	   *parse = root->parse;
+	PathTarget *input_target;
+	Bitmapset  *sgrefs;
+	List	   *flattenable_cols;
+	List	   *flattenable_vars;
+	int			i;
+	ListCell   *lc;
+
+	Assert(parse->hasWindowFuncs);
+
+	/*
+	 * Collect the sortgroupref numbers of window PARTITION/ORDER BY clauses
+	 * into a bitmapset for convenient reference below.
+	 */
+	sgrefs = NULL;
+	foreach(lc, activeWindows)
+	{
+		WindowClause *wc = (WindowClause *) lfirst(lc);
+		ListCell   *lc2;
+
+		foreach(lc2, wc->partitionClause)
+		{
+			SortGroupClause *sortcl = (SortGroupClause *) lfirst(lc2);
+
+			sgrefs = bms_add_member(sgrefs, sortcl->tleSortGroupRef);
+		}
+		foreach(lc2, wc->orderClause)
+		{
+			SortGroupClause *sortcl = (SortGroupClause *) lfirst(lc2);
+
+			sgrefs = bms_add_member(sgrefs, sortcl->tleSortGroupRef);
+		}
+	}
+
+	/* Add in sortgroupref numbers of GROUP BY clauses, too */
+	foreach(lc, parse->groupClause)
+	{
+		SortGroupClause *grpcl = (SortGroupClause *) lfirst(lc);
+
+		sgrefs = bms_add_member(sgrefs, grpcl->tleSortGroupRef);
+	}
+
+	/*
+	 * Construct a target containing all the non-flattenable targetlist items,
+	 * and save aside the others for a moment.
+	 */
+	input_target = create_empty_pathtarget();
+	flattenable_cols = NIL;
+
+	i = 0;
+	foreach(lc, final_target->exprs)
+	{
+		Expr	   *expr = (Expr *) lfirst(lc);
+		Index		sgref = get_pathtarget_sortgroupref(final_target, i);
+
+		/*
+		 * Don't want to deconstruct window clauses or GROUP BY items.  (Note
+		 * that such items can't contain window functions, so it's okay to
+		 * compute them below the WindowAgg nodes.)
+		 */
+		if (sgref != 0 && bms_is_member(sgref, sgrefs))
+		{
+			/*
+			 * Don't want to deconstruct this value, so add it to the input
+			 * target as-is.
+			 */
+			add_column_to_pathtarget(input_target, expr, sgref);
+		}
+		else
+		{
+			/*
+			 * Column is to be flattened, so just remember the expression for
+			 * later call to pull_var_clause.
+			 */
+			flattenable_cols = lappend(flattenable_cols, expr);
+		}
+
+		i++;
+	}
+
+	/*
+	 * Pull out all the Vars and Aggrefs mentioned in flattenable columns, and
+	 * add them to the input target if not already present.  (Some might be
+	 * there already because they're used directly as window/group clauses.)
+	 *
+	 * Note: it's essential to use PVC_INCLUDE_AGGREGATES here, so that any
+	 * Aggrefs are placed in the Agg node's tlist and not left to be computed
+	 * at higher levels.  On the other hand, we should recurse into
+	 * WindowFuncs to make sure their input expressions are available.
+	 */
+	flattenable_vars = pull_var_clause((Node *) flattenable_cols,
+									   PVC_INCLUDE_AGGREGATES |
+									   PVC_RECURSE_WINDOWFUNCS |
+									   PVC_INCLUDE_PLACEHOLDERS);
+	add_new_columns_to_pathtarget(input_target, flattenable_vars);
+
+	/* clean up cruft */
+	list_free(flattenable_vars);
+	list_free(flattenable_cols);
+
+	/* XXX this causes some redundant cost calculation ... */
+	return set_pathtarget_cost_width(root, input_target);
+}
+
+/*
+ * make_pathkeys_for_window
+ *		Create a pathkeys list describing the required input ordering
+ *		for the given WindowClause.
+ *
+ * The required ordering is first the PARTITION keys, then the ORDER keys.
+ * In the future we might try to implement windowing using hashing, in which
+ * case the ordering could be relaxed, but for now we always sort.
+ *
+ * Caution: if you change this, see createplan.c's get_column_info_for_window!
+ */
+static List *
+make_pathkeys_for_window(PlannerInfo *root, WindowClause *wc,
+						 List *tlist)
+{
+	List	   *window_pathkeys;
+	List	   *window_sortclauses;
+
+	/* Throw error if can't sort */
+	if (!grouping_is_sortable(wc->partitionClause))
+		ereport(ERROR,
+				(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
+				 errmsg("could not implement window PARTITION BY"),
+				 errdetail("Window partitioning columns must be of sortable datatypes.")));
+	if (!grouping_is_sortable(wc->orderClause))
+		ereport(ERROR,
+				(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
+				 errmsg("could not implement window ORDER BY"),
+				 errdetail("Window ordering columns must be of sortable datatypes.")));
+
+	/* Okay, make the combined pathkeys */
+	window_sortclauses = list_concat(list_copy(wc->partitionClause),
+									 list_copy(wc->orderClause));
+	window_pathkeys = make_pathkeys_for_sortclauses(root,
+													window_sortclauses,
+													tlist);
+	list_free(window_sortclauses);
+	return window_pathkeys;
+}
+
+/*
+ * make_sort_input_target
+ *	  Generate appropriate PathTarget for initial input to Sort step.
+ *
+ * If the query has ORDER BY, this function chooses the target to be computed
+ * by the node just below the Sort (and DISTINCT, if any, since Unique can't
+ * project) steps.  This might or might not be identical to the query's final
+ * output target.
+ *
+ * The main argument for keeping the sort-input tlist the same as the final
+ * is that we avoid a separate projection node (which will be needed if
+ * they're different, because Sort can't project).  However, there are also
+ * advantages to postponing tlist evaluation till after the Sort: it ensures
+ * a consistent order of evaluation for any volatile functions in the tlist,
+ * and if there's also a LIMIT, we can stop the query without ever computing
+ * tlist functions for later rows, which is beneficial for both volatile and
+ * expensive functions.
+ *
+ * Our current policy is to postpone volatile expressions till after the sort
+ * unconditionally (assuming that that's possible, ie they are in plain tlist
+ * columns and not ORDER BY/GROUP BY/DISTINCT columns).  We also prefer to
+ * postpone set-returning expressions, because running them beforehand would
+ * bloat the sort dataset, and because it might cause unexpected output order
+ * if the sort isn't stable.  However there's a constraint on that: all SRFs
+ * in the tlist should be evaluated at the same plan step, so that they can
+ * run in sync in nodeProjectSet.  So if any SRFs are in sort columns, we
+ * mustn't postpone any SRFs.  (Note that in principle that policy should
+ * probably get applied to the group/window input targetlists too, but we
+ * have not done that historically.)  Lastly, expensive expressions are
+ * postponed if there is a LIMIT, or if root->tuple_fraction shows that
+ * partial evaluation of the query is possible (if neither is true, we expect
+ * to have to evaluate the expressions for every row anyway), or if there are
+ * any volatile or set-returning expressions (since once we've put in a
+ * projection at all, it won't cost any more to postpone more stuff).
+ *
+ * Another issue that could potentially be considered here is that
+ * evaluating tlist expressions could result in data that's either wider
+ * or narrower than the input Vars, thus changing the volume of data that
+ * has to go through the Sort.  However, we usually have only a very bad
+ * idea of the output width of any expression more complex than a Var,
+ * so for now it seems too risky to try to optimize on that basis.
+ *
+ * Note that if we do produce a modified sort-input target, and then the
+ * query ends up not using an explicit Sort, no particular harm is done:
+ * we'll initially use the modified target for the preceding path nodes,
+ * but then change them to the final target with apply_projection_to_path.
+ * Moreover, in such a case the guarantees about evaluation order of
+ * volatile functions still hold, since the rows are sorted already.
+ *
+ * This function has some things in common with make_group_input_target and
+ * make_window_input_target, though the detailed rules for what to do are
+ * different.  We never flatten/postpone any grouping or ordering columns;
+ * those are needed before the sort.  If we do flatten a particular
+ * expression, we leave Aggref and WindowFunc nodes alone, since those were
+ * computed earlier.
+ *
+ * 'final_target' is the query's final target list (in PathTarget form)
+ * 'have_postponed_srfs' is an output argument, see below
+ *
+ * The result is the PathTarget to be computed by the plan node immediately
+ * below the Sort step (and the Distinct step, if any).  This will be
+ * exactly final_target if we decide a projection step wouldn't be helpful.
+ *
+ * In addition, *have_postponed_srfs is set to TRUE if we choose to postpone
+ * any set-returning functions to after the Sort.
+ */
+static PathTarget *
+make_sort_input_target(PlannerInfo *root,
+					   PathTarget *final_target,
+					   bool *have_postponed_srfs)
+{
+	Query	   *parse = root->parse;
+	PathTarget *input_target;
+	int			ncols;
+	bool	   *col_is_srf;
+	bool	   *postpone_col;
+	bool		have_srf;
+	bool		have_volatile;
+	bool		have_expensive;
+	bool		have_srf_sortcols;
+	bool		postpone_srfs;
+	List	   *postponable_cols;
+	List	   *postponable_vars;
+	int			i;
+	ListCell   *lc;
+
+	/* Shouldn't get here unless query has ORDER BY */
+	Assert(parse->sortClause);
+
+	*have_postponed_srfs = false;	/* default result */
+
+	/* Inspect tlist and collect per-column information */
+	ncols = list_length(final_target->exprs);
+	col_is_srf = (bool *) palloc0(ncols * sizeof(bool));
+	postpone_col = (bool *) palloc0(ncols * sizeof(bool));
+	have_srf = have_volatile = have_expensive = have_srf_sortcols = false;
+
+	i = 0;
+	foreach(lc, final_target->exprs)
+	{
+		Expr	   *expr = (Expr *) lfirst(lc);
+
+		/*
+		 * If the column has a sortgroupref, assume it has to be evaluated
+		 * before sorting.  Generally such columns would be ORDER BY, GROUP
+		 * BY, etc targets.  One exception is columns that were removed from
+		 * GROUP BY by remove_useless_groupby_columns() ... but those would
+		 * only be Vars anyway.  There don't seem to be any cases where it
+		 * would be worth the trouble to double-check.
+		 */
+		if (get_pathtarget_sortgroupref(final_target, i) == 0)
+		{
+			/*
+			 * Check for SRF or volatile functions.  Check the SRF case first
+			 * because we must know whether we have any postponed SRFs.
+			 */
+			if (parse->hasTargetSRFs &&
+				expression_returns_set((Node *) expr))
+			{
+				/* We'll decide below whether these are postponable */
+				col_is_srf[i] = true;
+				have_srf = true;
+			}
+			else if (contain_volatile_functions((Node *) expr))
+			{
+				/* Unconditionally postpone */
+				postpone_col[i] = true;
+				have_volatile = true;
+			}
+			else
+			{
+				/*
+				 * Else check the cost.  XXX it's annoying to have to do this
+				 * when set_pathtarget_cost_width() just did it.  Refactor to
+				 * allow sharing the work?
+				 */
+				QualCost	cost;
+
+				cost_qual_eval_node(&cost, (Node *) expr, root);
+
+				/*
+				 * We arbitrarily define "expensive" as "more than 10X
+				 * cpu_operator_cost".  Note this will take in any PL function
+				 * with default cost.
+				 */
+				if (cost.per_tuple > 10 * cpu_operator_cost)
+				{
+					postpone_col[i] = true;
+					have_expensive = true;
+				}
+			}
+		}
+		else
+		{
+			/* For sortgroupref cols, just check if any contain SRFs */
+			if (!have_srf_sortcols &&
+				parse->hasTargetSRFs &&
+				expression_returns_set((Node *) expr))
+				have_srf_sortcols = true;
+		}
+
+		i++;
+	}
+
+	/*
+	 * We can postpone SRFs if we have some but none are in sortgroupref cols.
+	 */
+	postpone_srfs = (have_srf && !have_srf_sortcols);
+
+	/*
+	 * If we don't need a post-sort projection, just return final_target.
+	 */
+	if (!(postpone_srfs || have_volatile ||
+		  (have_expensive &&
+		   (parse->limitCount || root->tuple_fraction > 0))))
+		return final_target;
+
+	/*
+	 * Report whether the post-sort projection will contain set-returning
+	 * functions.  This is important because it affects whether the Sort can
+	 * rely on the query's LIMIT (if any) to bound the number of rows it needs
+	 * to return.
+	 */
+	*have_postponed_srfs = postpone_srfs;
+
+	/*
+	 * Construct the sort-input target, taking all non-postponable columns and
+	 * then adding Vars, PlaceHolderVars, Aggrefs, and WindowFuncs found in
+	 * the postponable ones.
+	 */
+	input_target = create_empty_pathtarget();
+	postponable_cols = NIL;
+
+	i = 0;
+	foreach(lc, final_target->exprs)
+	{
+		Expr	   *expr = (Expr *) lfirst(lc);
+
+		if (postpone_col[i] || (postpone_srfs && col_is_srf[i]))
+			postponable_cols = lappend(postponable_cols, expr);
+		else
+			add_column_to_pathtarget(input_target, expr,
+									 get_pathtarget_sortgroupref(final_target, i));
+
+		i++;
+	}
+
+	/*
+	 * Pull out all the Vars, Aggrefs, and WindowFuncs mentioned in
+	 * postponable columns, and add them to the sort-input target if not
+	 * already present.  (Some might be there already.)  We mustn't
+	 * deconstruct Aggrefs or WindowFuncs here, since the projection node
+	 * would be unable to recompute them.
+	 */
+	postponable_vars = pull_var_clause((Node *) postponable_cols,
+									   PVC_INCLUDE_AGGREGATES |
+									   PVC_INCLUDE_WINDOWFUNCS |
+									   PVC_INCLUDE_PLACEHOLDERS);
+	add_new_columns_to_pathtarget(input_target, postponable_vars);
+
+	/* clean up cruft */
+	list_free(postponable_vars);
+	list_free(postponable_cols);
+
+	/* XXX this represents even more redundant cost calculation ... */
+	return set_pathtarget_cost_width(root, input_target);
+}
+
+/*
+ * get_cheapest_fractional_path
+ *	  Find the cheapest path for retrieving a specified fraction of all
+ *	  the tuples expected to be returned by the given relation.
+ *
+ * We interpret tuple_fraction the same way as grouping_planner.
+ *
+ * We assume set_cheapest() has been run on the given rel.
+ */
+Path *
+get_cheapest_fractional_path(RelOptInfo *rel, double tuple_fraction)
+{
+	Path	   *best_path = rel->cheapest_total_path;
+	ListCell   *l;
+
+	/* If all tuples will be retrieved, just return the cheapest-total path */
+	if (tuple_fraction <= 0.0)
+		return best_path;
+
+	/* Convert absolute # of tuples to a fraction; no need to clamp to 0..1 */
+	if (tuple_fraction >= 1.0 && best_path->rows > 0)
+		tuple_fraction /= best_path->rows;
+
+	foreach(l, rel->pathlist)
+	{
+		Path	   *path = (Path *) lfirst(l);
+
+		if (path == rel->cheapest_total_path ||
+			compare_fractional_path_costs(best_path, path, tuple_fraction) <= 0)
+			continue;
+
+		best_path = path;
+	}
+
+	return best_path;
+}
+
+/*
+ * adjust_paths_for_srfs
+ *		Fix up the Paths of the given upperrel to handle tSRFs properly.
+ *
+ * The executor can only handle set-returning functions that appear at the
+ * top level of the targetlist of a ProjectSet plan node.  If we have any SRFs
+ * that are not at top level, we need to split up the evaluation into multiple
+ * plan levels in which each level satisfies this constraint.  This function
+ * modifies each Path of an upperrel that (might) compute any SRFs in its
+ * output tlist to insert appropriate projection steps.
+ *
+ * The given targets and targets_contain_srfs lists are from
+ * split_pathtarget_at_srfs().  We assume the existing Paths emit the first
+ * target in targets.
+ */
+static void
+adjust_paths_for_srfs(PlannerInfo *root, RelOptInfo *rel,
+					  List *targets, List *targets_contain_srfs)
+{
+	ListCell   *lc;
+
+	Assert(list_length(targets) == list_length(targets_contain_srfs));
+	Assert(!linitial_int(targets_contain_srfs));
+
+	/* If no SRFs appear at this plan level, nothing to do */
+	if (list_length(targets) == 1)
+		return;
+
+	/*
+	 * Stack SRF-evaluation nodes atop each path for the rel.
+	 *
+	 * In principle we should re-run set_cheapest() here to identify the
+	 * cheapest path, but it seems unlikely that adding the same tlist eval
+	 * costs to all the paths would change that, so we don't bother. Instead,
+	 * just assume that the cheapest-startup and cheapest-total paths remain
+	 * so.  (There should be no parameterized paths anymore, so we needn't
+	 * worry about updating cheapest_parameterized_paths.)
+	 */
+	foreach(lc, rel->pathlist)
+	{
+		Path	   *subpath = (Path *) lfirst(lc);
+		Path	   *newpath = subpath;
+		ListCell   *lc1,
+				   *lc2;
+
+		Assert(subpath->param_info == NULL);
+		forboth(lc1, targets, lc2, targets_contain_srfs)
+		{
+			PathTarget *thistarget = (PathTarget *) lfirst(lc1);
+			bool		contains_srfs = (bool) lfirst_int(lc2);
+
+			/* If this level doesn't contain SRFs, do regular projection */
+			if (contains_srfs)
+				newpath = (Path *) create_set_projection_path(root,
+															  rel,
+															  newpath,
+															  thistarget);
+			else
+				newpath = (Path *) apply_projection_to_path(root,
+															rel,
+															newpath,
+															thistarget);
+		}
+		lfirst(lc) = newpath;
+		if (subpath == rel->cheapest_startup_path)
+			rel->cheapest_startup_path = newpath;
+		if (subpath == rel->cheapest_total_path)
+			rel->cheapest_total_path = newpath;
+	}
+
+	/* Likewise for partial paths, if any */
+	foreach(lc, rel->partial_pathlist)
+	{
+		Path	   *subpath = (Path *) lfirst(lc);
+		Path	   *newpath = subpath;
+		ListCell   *lc1,
+				   *lc2;
+
+		Assert(subpath->param_info == NULL);
+		forboth(lc1, targets, lc2, targets_contain_srfs)
+		{
+			PathTarget *thistarget = (PathTarget *) lfirst(lc1);
+			bool		contains_srfs = (bool) lfirst_int(lc2);
+
+			/* If this level doesn't contain SRFs, do regular projection */
+			if (contains_srfs)
+				newpath = (Path *) create_set_projection_path(root,
+															  rel,
+															  newpath,
+															  thistarget);
+			else
+			{
+				/* avoid apply_projection_to_path, in case of multiple refs */
+				newpath = (Path *) create_projection_path(root,
+														  rel,
+														  newpath,
+														  thistarget);
+			}
+		}
+		lfirst(lc) = newpath;
+	}
+}
+
+/*
+ * expression_planner
+ *		Perform planner's transformations on a standalone expression.
+ *
+ * Various utility commands need to evaluate expressions that are not part
+ * of a plannable query.  They can do so using the executor's regular
+ * expression-execution machinery, but first the expression has to be fed
+ * through here to transform it from parser output to something executable.
+ *
+ * Currently, we disallow sublinks in standalone expressions, so there's no
+ * real "planning" involved here.  (That might not always be true though.)
+ * What we must do is run eval_const_expressions to ensure that any function
+ * calls are converted to positional notation and function default arguments
+ * get inserted.  The fact that constant subexpressions get simplified is a
+ * side-effect that is useful when the expression will get evaluated more than
+ * once.  Also, we must fix operator function IDs.
+ *
+ * Note: this must not make any damaging changes to the passed-in expression
+ * tree.  (It would actually be okay to apply fix_opfuncids to it, but since
+ * we first do an expression_tree_mutator-based walk, what is returned will
+ * be a new node tree.)
+ */
+Expr *
+expression_planner(Expr *expr)
+{
+	Node	   *result;
+
+	/*
+	 * Convert named-argument function calls, insert default arguments and
+	 * simplify constant subexprs
+	 */
+	result = eval_const_expressions(NULL, (Node *) expr);
+
+	/* Fill in opfuncid values if missing */
+	fix_opfuncids(result);
+
+	return (Expr *) result;
+}
+
+
+/*
+ * plan_cluster_use_sort
+ *		Use the planner to decide how CLUSTER should implement sorting
+ *
+ * tableOid is the OID of a table to be clustered on its index indexOid
+ * (which is already known to be a btree index).  Decide whether it's
+ * cheaper to do an indexscan or a seqscan-plus-sort to execute the CLUSTER.
+ * Return TRUE to use sorting, FALSE to use an indexscan.
+ *
+ * Note: caller had better already hold some type of lock on the table.
+ */
+bool
+plan_cluster_use_sort(Oid tableOid, Oid indexOid)
+{
+	PlannerInfo *root;
+	Query	   *query;
+	PlannerGlobal *glob;
+	RangeTblEntry *rte;
+	RelOptInfo *rel;
+	IndexOptInfo *indexInfo;
+	QualCost	indexExprCost;
+	Cost		comparisonCost;
+	Path	   *seqScanPath;
+	Path		seqScanAndSortPath;
+	IndexPath  *indexScanPath;
+	ListCell   *lc;
+
+	/* We can short-circuit the cost comparison if indexscans are disabled */
+	if (!enable_indexscan)
+		return true;			/* use sort */
+
+	/* Set up mostly-dummy planner state */
+	query = makeNode(Query);
+	query->commandType = CMD_SELECT;
+
+	glob = makeNode(PlannerGlobal);
+
+	root = makeNode(PlannerInfo);
+	root->parse = query;
+	root->glob = glob;
+	root->query_level = 1;
+	root->planner_cxt = CurrentMemoryContext;
+	root->wt_param_id = -1;
+
+	/* Build a minimal RTE for the rel */
+	rte = makeNode(RangeTblEntry);
+	rte->rtekind = RTE_RELATION;
+	rte->relid = tableOid;
+	rte->relkind = RELKIND_RELATION;	/* Don't be too picky. */
+	rte->lateral = false;
+	rte->inh = false;
+	rte->inFromCl = true;
+	query->rtable = list_make1(rte);
+
+	/* Set up RTE/RelOptInfo arrays */
+	setup_simple_rel_arrays(root);
+
+	/* Build RelOptInfo */
+	rel = build_simple_rel(root, 1, NULL);
+
+	/* Locate IndexOptInfo for the target index */
+	indexInfo = NULL;
+	foreach(lc, rel->indexlist)
+	{
+		indexInfo = (IndexOptInfo *) lfirst(lc);
+		if (indexInfo->indexoid == indexOid)
+			break;
+	}
+
+	/*
+	 * It's possible that get_relation_info did not generate an IndexOptInfo
+	 * for the desired index; this could happen if it's not yet reached its
+	 * indcheckxmin usability horizon, or if it's a system index and we're
+	 * ignoring system indexes.  In such cases we should tell CLUSTER to not
+	 * trust the index contents but use seqscan-and-sort.
+	 */
+	if (lc == NULL)				/* not in the list? */
+		return true;			/* use sort */
+
+	/*
+	 * Rather than doing all the pushups that would be needed to use
+	 * set_baserel_size_estimates, just do a quick hack for rows and width.
+	 */
+	rel->rows = rel->tuples;
+	rel->reltarget->width = get_relation_data_width(tableOid, NULL);
+
+	root->total_table_pages = rel->pages;
+
+	/*
+	 * Determine eval cost of the index expressions, if any.  We need to
+	 * charge twice that amount for each tuple comparison that happens during
+	 * the sort, since tuplesort.c will have to re-evaluate the index
+	 * expressions each time.  (XXX that's pretty inefficient...)
+	 */
+	cost_qual_eval(&indexExprCost, indexInfo->indexprs, root);
+	comparisonCost = 2.0 * (indexExprCost.startup + indexExprCost.per_tuple);
+
+	/* Estimate the cost of seq scan + sort */
+	seqScanPath = create_seqscan_path(root, rel, NULL, 0);
+	cost_sort(&seqScanAndSortPath, root, NIL,
+			  seqScanPath->total_cost, rel->tuples, rel->reltarget->width,
+			  comparisonCost, maintenance_work_mem, -1.0);
+
+	/* Estimate the cost of index scan */
+	indexScanPath = create_index_path(root, indexInfo,
+									  NIL, NIL, NIL, NIL, NIL,
+									  ForwardScanDirection, false,
+									  NULL, 1.0, false);
+
+	return (seqScanAndSortPath.total_cost < indexScanPath->path.total_cost);
+}
+
+/*
+ * get_partitioned_child_rels
+ *		Returns a list of the RT indexes of the partitioned child relations
+ *		with rti as the root parent RT index.
+ *
+ * Note: This function might get called even for range table entries that
+ * are not partitioned tables; in such a case, it will simply return NIL.
+ */
+List *
+get_partitioned_child_rels(PlannerInfo *root, Index rti)
+{
+	List	   *result = NIL;
+	ListCell   *l;
+
+	foreach(l, root->pcinfo_list)
+	{
+		PartitionedChildRelInfo *pc = lfirst(l);
+
+		if (pc->parent_relid == rti)
+		{
+			result = pc->child_rels;
+			break;
+		}
+	}
+
+	return result;
+}
diff -ruN a/src/backend/optimizer/plan/setrefs.c b/src/backend/optimizer/plan/setrefs.c
--- a/src/backend/optimizer/plan/setrefs.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/plan/setrefs.c	2017-12-28 14:58:03.495304864 +0300
@@ -2209,6 +2209,10 @@
 	{
 		Var		   *var = (Var *) node;
 
+		/* join_references_mutator already checks this node */
+		if (var->varno == OUTER_VAR)
+			return (Node*)copyObject(var);
+
 		/* Look for the var in the input tlists, first in the outer */
 		if (context->outer_itlist)
 		{
@@ -2223,6 +2227,9 @@
 		/* then in the inner. */
 		if (context->inner_itlist)
 		{
+			if (var->varno == INNER_VAR)
+				return (Node*)copyObject(var);
+
 			newvar = search_indexed_tlist_for_var(var,
 												  context->inner_itlist,
 												  INNER_VAR,
diff -ruN a/src/backend/optimizer/plan/setrefs.c.orig b/src/backend/optimizer/plan/setrefs.c.orig
--- a/src/backend/optimizer/plan/setrefs.c.orig	1970-01-01 03:00:00.000000000 +0300
+++ b/src/backend/optimizer/plan/setrefs.c.orig	2017-12-28 14:58:03.495304864 +0300
@@ -0,0 +1,2609 @@
+/*-------------------------------------------------------------------------
+ *
+ * setrefs.c
+ *	  Post-processing of a completed plan tree: fix references to subplan
+ *	  vars, compute regproc values for operators, etc
+ *
+ * Portions Copyright (c) 1996-2017, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/optimizer/plan/setrefs.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/transam.h"
+#include "catalog/pg_type.h"
+#include "nodes/makefuncs.h"
+#include "nodes/nodeFuncs.h"
+#include "optimizer/pathnode.h"
+#include "optimizer/planmain.h"
+#include "optimizer/planner.h"
+#include "optimizer/tlist.h"
+#include "tcop/utility.h"
+#include "utils/lsyscache.h"
+#include "utils/syscache.h"
+
+
+typedef struct
+{
+	Index		varno;			/* RT index of Var */
+	AttrNumber	varattno;		/* attr number of Var */
+	AttrNumber	resno;			/* TLE position of Var */
+} tlist_vinfo;
+
+typedef struct
+{
+	List	   *tlist;			/* underlying target list */
+	int			num_vars;		/* number of plain Var tlist entries */
+	bool		has_ph_vars;	/* are there PlaceHolderVar entries? */
+	bool		has_non_vars;	/* are there other entries? */
+	tlist_vinfo vars[FLEXIBLE_ARRAY_MEMBER];	/* has num_vars entries */
+} indexed_tlist;
+
+typedef struct
+{
+	PlannerInfo *root;
+	int			rtoffset;
+} fix_scan_expr_context;
+
+typedef struct
+{
+	PlannerInfo *root;
+	indexed_tlist *outer_itlist;
+	indexed_tlist *inner_itlist;
+	Index		acceptable_rel;
+	int			rtoffset;
+} fix_join_expr_context;
+
+typedef struct
+{
+	PlannerInfo *root;
+	indexed_tlist *subplan_itlist;
+	Index		newvarno;
+	int			rtoffset;
+} fix_upper_expr_context;
+
+/*
+ * Check if a Const node is a regclass value.  We accept plain OID too,
+ * since a regclass Const will get folded to that type if it's an argument
+ * to oideq or similar operators.  (This might result in some extraneous
+ * values in a plan's list of relation dependencies, but the worst result
+ * would be occasional useless replans.)
+ */
+#define ISREGCLASSCONST(con) \
+	(((con)->consttype == REGCLASSOID || (con)->consttype == OIDOID) && \
+	 !(con)->constisnull)
+
+#define fix_scan_list(root, lst, rtoffset) \
+	((List *) fix_scan_expr(root, (Node *) (lst), rtoffset))
+
+static void add_rtes_to_flat_rtable(PlannerInfo *root, bool recursing);
+static void flatten_unplanned_rtes(PlannerGlobal *glob, RangeTblEntry *rte);
+static bool flatten_rtes_walker(Node *node, PlannerGlobal *glob);
+static void add_rte_to_flat_rtable(PlannerGlobal *glob, RangeTblEntry *rte);
+static Plan *set_plan_refs(PlannerInfo *root, Plan *plan, int rtoffset);
+static Plan *set_indexonlyscan_references(PlannerInfo *root,
+							 IndexOnlyScan *plan,
+							 int rtoffset);
+static Plan *set_subqueryscan_references(PlannerInfo *root,
+							SubqueryScan *plan,
+							int rtoffset);
+static bool trivial_subqueryscan(SubqueryScan *plan);
+static void set_foreignscan_references(PlannerInfo *root,
+						   ForeignScan *fscan,
+						   int rtoffset);
+static void set_customscan_references(PlannerInfo *root,
+						  CustomScan *cscan,
+						  int rtoffset);
+static Node *fix_scan_expr(PlannerInfo *root, Node *node, int rtoffset);
+static Node *fix_scan_expr_mutator(Node *node, fix_scan_expr_context *context);
+static bool fix_scan_expr_walker(Node *node, fix_scan_expr_context *context);
+static void set_join_references(PlannerInfo *root, Join *join, int rtoffset);
+static void set_upper_references(PlannerInfo *root, Plan *plan, int rtoffset);
+static Node *convert_combining_aggrefs(Node *node, void *context);
+static void set_dummy_tlist_references(Plan *plan, int rtoffset);
+static indexed_tlist *build_tlist_index(List *tlist);
+static Var *search_indexed_tlist_for_var(Var *var,
+							 indexed_tlist *itlist,
+							 Index newvarno,
+							 int rtoffset);
+static Var *search_indexed_tlist_for_non_var(Expr *node,
+								 indexed_tlist *itlist,
+								 Index newvarno);
+static Var *search_indexed_tlist_for_sortgroupref(Expr *node,
+									  Index sortgroupref,
+									  indexed_tlist *itlist,
+									  Index newvarno);
+static List *fix_join_expr(PlannerInfo *root,
+			  List *clauses,
+			  indexed_tlist *outer_itlist,
+			  indexed_tlist *inner_itlist,
+			  Index acceptable_rel, int rtoffset);
+static Node *fix_join_expr_mutator(Node *node,
+					  fix_join_expr_context *context);
+static Node *fix_upper_expr(PlannerInfo *root,
+			   Node *node,
+			   indexed_tlist *subplan_itlist,
+			   Index newvarno,
+			   int rtoffset);
+static Node *fix_upper_expr_mutator(Node *node,
+					   fix_upper_expr_context *context);
+static List *set_returning_clause_references(PlannerInfo *root,
+								List *rlist,
+								Plan *topplan,
+								Index resultRelation,
+								int rtoffset);
+static bool extract_query_dependencies_walker(Node *node,
+								  PlannerInfo *context);
+
+/*****************************************************************************
+ *
+ *		SUBPLAN REFERENCES
+ *
+ *****************************************************************************/
+
+/*
+ * set_plan_references
+ *
+ * This is the final processing pass of the planner/optimizer.  The plan
+ * tree is complete; we just have to adjust some representational details
+ * for the convenience of the executor:
+ *
+ * 1. We flatten the various subquery rangetables into a single list, and
+ * zero out RangeTblEntry fields that are not useful to the executor.
+ *
+ * 2. We adjust Vars in scan nodes to be consistent with the flat rangetable.
+ *
+ * 3. We adjust Vars in upper plan nodes to refer to the outputs of their
+ * subplans.
+ *
+ * 4. Aggrefs in Agg plan nodes need to be adjusted in some cases involving
+ * partial aggregation or minmax aggregate optimization.
+ *
+ * 5. PARAM_MULTIEXPR Params are replaced by regular PARAM_EXEC Params,
+ * now that we have finished planning all MULTIEXPR subplans.
+ *
+ * 6. We compute regproc OIDs for operators (ie, we look up the function
+ * that implements each op).
+ *
+ * 7. We create lists of specific objects that the plan depends on.
+ * This will be used by plancache.c to drive invalidation of cached plans.
+ * Relation dependencies are represented by OIDs, and everything else by
+ * PlanInvalItems (this distinction is motivated by the shared-inval APIs).
+ * Currently, relations and user-defined functions are the only types of
+ * objects that are explicitly tracked this way.
+ *
+ * 8. We assign every plan node in the tree a unique ID.
+ *
+ * We also perform one final optimization step, which is to delete
+ * SubqueryScan plan nodes that aren't doing anything useful (ie, have
+ * no qual and a no-op targetlist).  The reason for doing this last is that
+ * it can't readily be done before set_plan_references, because it would
+ * break set_upper_references: the Vars in the subquery's top tlist
+ * wouldn't match up with the Vars in the outer plan tree.  The SubqueryScan
+ * serves a necessary function as a buffer between outer query and subquery
+ * variable numbering ... but after we've flattened the rangetable this is
+ * no longer a problem, since then there's only one rtindex namespace.
+ *
+ * set_plan_references recursively traverses the whole plan tree.
+ *
+ * The return value is normally the same Plan node passed in, but can be
+ * different when the passed-in Plan is a SubqueryScan we decide isn't needed.
+ *
+ * The flattened rangetable entries are appended to root->glob->finalrtable.
+ * Also, rowmarks entries are appended to root->glob->finalrowmarks, and the
+ * RT indexes of ModifyTable result relations to root->glob->resultRelations.
+ * Plan dependencies are appended to root->glob->relationOids (for relations)
+ * and root->glob->invalItems (for everything else).
+ *
+ * Notice that we modify Plan nodes in-place, but use expression_tree_mutator
+ * to process targetlist and qual expressions.  We can assume that the Plan
+ * nodes were just built by the planner and are not multiply referenced, but
+ * it's not so safe to assume that for expression tree nodes.
+ */
+Plan *
+set_plan_references(PlannerInfo *root, Plan *plan)
+{
+	PlannerGlobal *glob = root->glob;
+	int			rtoffset = list_length(glob->finalrtable);
+	ListCell   *lc;
+
+	/*
+	 * Add all the query's RTEs to the flattened rangetable.  The live ones
+	 * will have their rangetable indexes increased by rtoffset.  (Additional
+	 * RTEs, not referenced by the Plan tree, might get added after those.)
+	 */
+	add_rtes_to_flat_rtable(root, false);
+
+	/*
+	 * Adjust RT indexes of PlanRowMarks and add to final rowmarks list
+	 */
+	foreach(lc, root->rowMarks)
+	{
+		PlanRowMark *rc = lfirst_node(PlanRowMark, lc);
+		PlanRowMark *newrc;
+
+		/* flat copy is enough since all fields are scalars */
+		newrc = (PlanRowMark *) palloc(sizeof(PlanRowMark));
+		memcpy(newrc, rc, sizeof(PlanRowMark));
+
+		/* adjust indexes ... but *not* the rowmarkId */
+		newrc->rti += rtoffset;
+		newrc->prti += rtoffset;
+
+		glob->finalrowmarks = lappend(glob->finalrowmarks, newrc);
+	}
+
+	/* Now fix the Plan tree */
+	return set_plan_refs(root, plan, rtoffset);
+}
+
+/*
+ * Extract RangeTblEntries from the plan's rangetable, and add to flat rtable
+ *
+ * This can recurse into subquery plans; "recursing" is true if so.
+ */
+static void
+add_rtes_to_flat_rtable(PlannerInfo *root, bool recursing)
+{
+	PlannerGlobal *glob = root->glob;
+	Index		rti;
+	ListCell   *lc;
+
+	/*
+	 * Add the query's own RTEs to the flattened rangetable.
+	 *
+	 * At top level, we must add all RTEs so that their indexes in the
+	 * flattened rangetable match up with their original indexes.  When
+	 * recursing, we only care about extracting relation RTEs.
+	 */
+	foreach(lc, root->parse->rtable)
+	{
+		RangeTblEntry *rte = (RangeTblEntry *) lfirst(lc);
+
+		if (!recursing || rte->rtekind == RTE_RELATION)
+			add_rte_to_flat_rtable(glob, rte);
+	}
+
+	/*
+	 * If there are any dead subqueries, they are not referenced in the Plan
+	 * tree, so we must add RTEs contained in them to the flattened rtable
+	 * separately.  (If we failed to do this, the executor would not perform
+	 * expected permission checks for tables mentioned in such subqueries.)
+	 *
+	 * Note: this pass over the rangetable can't be combined with the previous
+	 * one, because that would mess up the numbering of the live RTEs in the
+	 * flattened rangetable.
+	 */
+	rti = 1;
+	foreach(lc, root->parse->rtable)
+	{
+		RangeTblEntry *rte = (RangeTblEntry *) lfirst(lc);
+
+		/*
+		 * We should ignore inheritance-parent RTEs: their contents have been
+		 * pulled up into our rangetable already.  Also ignore any subquery
+		 * RTEs without matching RelOptInfos, as they likewise have been
+		 * pulled up.
+		 */
+		if (rte->rtekind == RTE_SUBQUERY && !rte->inh &&
+			rti < root->simple_rel_array_size)
+		{
+			RelOptInfo *rel = root->simple_rel_array[rti];
+
+			if (rel != NULL)
+			{
+				Assert(rel->relid == rti);	/* sanity check on array */
+
+				/*
+				 * The subquery might never have been planned at all, if it
+				 * was excluded on the basis of self-contradictory constraints
+				 * in our query level.  In this case apply
+				 * flatten_unplanned_rtes.
+				 *
+				 * If it was planned but the result rel is dummy, we assume
+				 * that it has been omitted from our plan tree (see
+				 * set_subquery_pathlist), and recurse to pull up its RTEs.
+				 *
+				 * Otherwise, it should be represented by a SubqueryScan node
+				 * somewhere in our plan tree, and we'll pull up its RTEs when
+				 * we process that plan node.
+				 *
+				 * However, if we're recursing, then we should pull up RTEs
+				 * whether the subquery is dummy or not, because we've found
+				 * that some upper query level is treating this one as dummy,
+				 * and so we won't scan this level's plan tree at all.
+				 */
+				if (rel->subroot == NULL)
+					flatten_unplanned_rtes(glob, rte);
+				else if (recursing ||
+						 IS_DUMMY_REL(fetch_upper_rel(rel->subroot,
+													  UPPERREL_FINAL, NULL)))
+					add_rtes_to_flat_rtable(rel->subroot, true);
+			}
+		}
+		rti++;
+	}
+}
+
+/*
+ * Extract RangeTblEntries from a subquery that was never planned at all
+ */
+static void
+flatten_unplanned_rtes(PlannerGlobal *glob, RangeTblEntry *rte)
+{
+	/* Use query_tree_walker to find all RTEs in the parse tree */
+	(void) query_tree_walker(rte->subquery,
+							 flatten_rtes_walker,
+							 (void *) glob,
+							 QTW_EXAMINE_RTES);
+}
+
+static bool
+flatten_rtes_walker(Node *node, PlannerGlobal *glob)
+{
+	if (node == NULL)
+		return false;
+	if (IsA(node, RangeTblEntry))
+	{
+		RangeTblEntry *rte = (RangeTblEntry *) node;
+
+		/* As above, we need only save relation RTEs */
+		if (rte->rtekind == RTE_RELATION)
+			add_rte_to_flat_rtable(glob, rte);
+		return false;
+	}
+	if (IsA(node, Query))
+	{
+		/* Recurse into subselects */
+		return query_tree_walker((Query *) node,
+								 flatten_rtes_walker,
+								 (void *) glob,
+								 QTW_EXAMINE_RTES);
+	}
+	return expression_tree_walker(node, flatten_rtes_walker,
+								  (void *) glob);
+}
+
+/*
+ * Add (a copy of) the given RTE to the final rangetable
+ *
+ * In the flat rangetable, we zero out substructure pointers that are not
+ * needed by the executor; this reduces the storage space and copying cost
+ * for cached plans.  We keep only the ctename, alias and eref Alias fields,
+ * which are needed by EXPLAIN, and the selectedCols, insertedCols and
+ * updatedCols bitmaps, which are needed for executor-startup permissions
+ * checking and for trigger event checking.
+ */
+static void
+add_rte_to_flat_rtable(PlannerGlobal *glob, RangeTblEntry *rte)
+{
+	RangeTblEntry *newrte;
+
+	/* flat copy to duplicate all the scalar fields */
+	newrte = (RangeTblEntry *) palloc(sizeof(RangeTblEntry));
+	memcpy(newrte, rte, sizeof(RangeTblEntry));
+
+	/* zap unneeded sub-structure */
+	newrte->tablesample = NULL;
+	newrte->subquery = NULL;
+	newrte->joinaliasvars = NIL;
+	newrte->functions = NIL;
+	newrte->tablefunc = NULL;
+	newrte->values_lists = NIL;
+	newrte->coltypes = NIL;
+	newrte->coltypmods = NIL;
+	newrte->colcollations = NIL;
+	newrte->securityQuals = NIL;
+
+	glob->finalrtable = lappend(glob->finalrtable, newrte);
+
+	/*
+	 * Check for RT index overflow; it's very unlikely, but if it did happen,
+	 * the executor would get confused by varnos that match the special varno
+	 * values.
+	 */
+	if (IS_SPECIAL_VARNO(list_length(glob->finalrtable)))
+		ereport(ERROR,
+				(errcode(ERRCODE_PROGRAM_LIMIT_EXCEEDED),
+				 errmsg("too many range table entries")));
+
+	/*
+	 * If it's a plain relation RTE, add the table to relationOids.
+	 *
+	 * We do this even though the RTE might be unreferenced in the plan tree;
+	 * this would correspond to cases such as views that were expanded, child
+	 * tables that were eliminated by constraint exclusion, etc. Schema
+	 * invalidation on such a rel must still force rebuilding of the plan.
+	 *
+	 * Note we don't bother to avoid making duplicate list entries.  We could,
+	 * but it would probably cost more cycles than it would save.
+	 */
+	if (newrte->rtekind == RTE_RELATION)
+		glob->relationOids = lappend_oid(glob->relationOids, newrte->relid);
+}
+
+/*
+ * set_plan_refs: recurse through the Plan nodes of a single subquery level
+ */
+static Plan *
+set_plan_refs(PlannerInfo *root, Plan *plan, int rtoffset)
+{
+	ListCell   *l;
+
+	if (plan == NULL)
+		return NULL;
+
+	/* Assign this node a unique ID. */
+	plan->plan_node_id = root->glob->lastPlanNodeId++;
+
+	/*
+	 * Plan-type-specific fixes
+	 */
+	switch (nodeTag(plan))
+	{
+		case T_SeqScan:
+			{
+				SeqScan    *splan = (SeqScan *) plan;
+
+				splan->scanrelid += rtoffset;
+				splan->plan.targetlist =
+					fix_scan_list(root, splan->plan.targetlist, rtoffset);
+				splan->plan.qual =
+					fix_scan_list(root, splan->plan.qual, rtoffset);
+			}
+			break;
+		case T_SampleScan:
+			{
+				SampleScan *splan = (SampleScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+				splan->tablesample = (TableSampleClause *)
+					fix_scan_expr(root, (Node *) splan->tablesample, rtoffset);
+			}
+			break;
+		case T_IndexScan:
+			{
+				IndexScan  *splan = (IndexScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+				splan->indexqual =
+					fix_scan_list(root, splan->indexqual, rtoffset);
+				splan->indexqualorig =
+					fix_scan_list(root, splan->indexqualorig, rtoffset);
+				splan->indexorderby =
+					fix_scan_list(root, splan->indexorderby, rtoffset);
+				splan->indexorderbyorig =
+					fix_scan_list(root, splan->indexorderbyorig, rtoffset);
+			}
+			break;
+		case T_IndexOnlyScan:
+			{
+				IndexOnlyScan *splan = (IndexOnlyScan *) plan;
+
+				return set_indexonlyscan_references(root, splan, rtoffset);
+			}
+			break;
+		case T_BitmapIndexScan:
+			{
+				BitmapIndexScan *splan = (BitmapIndexScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				/* no need to fix targetlist and qual */
+				Assert(splan->scan.plan.targetlist == NIL);
+				Assert(splan->scan.plan.qual == NIL);
+				splan->indexqual =
+					fix_scan_list(root, splan->indexqual, rtoffset);
+				splan->indexqualorig =
+					fix_scan_list(root, splan->indexqualorig, rtoffset);
+			}
+			break;
+		case T_BitmapHeapScan:
+			{
+				BitmapHeapScan *splan = (BitmapHeapScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+				splan->bitmapqualorig =
+					fix_scan_list(root, splan->bitmapqualorig, rtoffset);
+			}
+			break;
+		case T_TidScan:
+			{
+				TidScan    *splan = (TidScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+				splan->tidquals =
+					fix_scan_list(root, splan->tidquals, rtoffset);
+			}
+			break;
+		case T_SubqueryScan:
+			/* Needs special treatment, see comments below */
+			return set_subqueryscan_references(root,
+											   (SubqueryScan *) plan,
+											   rtoffset);
+		case T_FunctionScan:
+			{
+				FunctionScan *splan = (FunctionScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+				splan->functions =
+					fix_scan_list(root, splan->functions, rtoffset);
+			}
+			break;
+		case T_TableFuncScan:
+			{
+				TableFuncScan *splan = (TableFuncScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+				splan->tablefunc = (TableFunc *)
+					fix_scan_expr(root, (Node *) splan->tablefunc, rtoffset);
+			}
+			break;
+		case T_ValuesScan:
+			{
+				ValuesScan *splan = (ValuesScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+				splan->values_lists =
+					fix_scan_list(root, splan->values_lists, rtoffset);
+			}
+			break;
+		case T_CteScan:
+			{
+				CteScan    *splan = (CteScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+			}
+			break;
+		case T_NamedTuplestoreScan:
+			{
+				NamedTuplestoreScan *splan = (NamedTuplestoreScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+			}
+			break;
+		case T_WorkTableScan:
+			{
+				WorkTableScan *splan = (WorkTableScan *) plan;
+
+				splan->scan.scanrelid += rtoffset;
+				splan->scan.plan.targetlist =
+					fix_scan_list(root, splan->scan.plan.targetlist, rtoffset);
+				splan->scan.plan.qual =
+					fix_scan_list(root, splan->scan.plan.qual, rtoffset);
+			}
+			break;
+		case T_ForeignScan:
+			set_foreignscan_references(root, (ForeignScan *) plan, rtoffset);
+			break;
+		case T_CustomScan:
+			set_customscan_references(root, (CustomScan *) plan, rtoffset);
+			break;
+
+		case T_NestLoop:
+		case T_MergeJoin:
+		case T_HashJoin:
+			set_join_references(root, (Join *) plan, rtoffset);
+			break;
+
+		case T_Gather:
+		case T_GatherMerge:
+			set_upper_references(root, plan, rtoffset);
+			break;
+
+		case T_Hash:
+		case T_Material:
+		case T_Sort:
+		case T_Unique:
+		case T_SetOp:
+
+			/*
+			 * These plan types don't actually bother to evaluate their
+			 * targetlists, because they just return their unmodified input
+			 * tuples.  Even though the targetlist won't be used by the
+			 * executor, we fix it up for possible use by EXPLAIN (not to
+			 * mention ease of debugging --- wrong varnos are very confusing).
+			 */
+			set_dummy_tlist_references(plan, rtoffset);
+
+			/*
+			 * Since these plan types don't check quals either, we should not
+			 * find any qual expression attached to them.
+			 */
+			Assert(plan->qual == NIL);
+			break;
+		case T_LockRows:
+			{
+				LockRows   *splan = (LockRows *) plan;
+
+				/*
+				 * Like the plan types above, LockRows doesn't evaluate its
+				 * tlist or quals.  But we have to fix up the RT indexes in
+				 * its rowmarks.
+				 */
+				set_dummy_tlist_references(plan, rtoffset);
+				Assert(splan->plan.qual == NIL);
+
+				foreach(l, splan->rowMarks)
+				{
+					PlanRowMark *rc = (PlanRowMark *) lfirst(l);
+
+					rc->rti += rtoffset;
+					rc->prti += rtoffset;
+				}
+			}
+			break;
+		case T_Limit:
+			{
+				Limit	   *splan = (Limit *) plan;
+
+				/*
+				 * Like the plan types above, Limit doesn't evaluate its tlist
+				 * or quals.  It does have live expressions for limit/offset,
+				 * however; and those cannot contain subplan variable refs, so
+				 * fix_scan_expr works for them.
+				 */
+				set_dummy_tlist_references(plan, rtoffset);
+				Assert(splan->plan.qual == NIL);
+
+				splan->limitOffset =
+					fix_scan_expr(root, splan->limitOffset, rtoffset);
+				splan->limitCount =
+					fix_scan_expr(root, splan->limitCount, rtoffset);
+			}
+			break;
+		case T_Agg:
+			{
+				Agg		   *agg = (Agg *) plan;
+
+				/*
+				 * If this node is combining partial-aggregation results, we
+				 * must convert its Aggrefs to contain references to the
+				 * partial-aggregate subexpressions that will be available
+				 * from the child plan node.
+				 */
+				if (DO_AGGSPLIT_COMBINE(agg->aggsplit))
+				{
+					plan->targetlist = (List *)
+						convert_combining_aggrefs((Node *) plan->targetlist,
+												  NULL);
+					plan->qual = (List *)
+						convert_combining_aggrefs((Node *) plan->qual,
+												  NULL);
+				}
+
+				set_upper_references(root, plan, rtoffset);
+			}
+			break;
+		case T_Group:
+			set_upper_references(root, plan, rtoffset);
+			break;
+		case T_WindowAgg:
+			{
+				WindowAgg  *wplan = (WindowAgg *) plan;
+
+				set_upper_references(root, plan, rtoffset);
+
+				/*
+				 * Like Limit node limit/offset expressions, WindowAgg has
+				 * frame offset expressions, which cannot contain subplan
+				 * variable refs, so fix_scan_expr works for them.
+				 */
+				wplan->startOffset =
+					fix_scan_expr(root, wplan->startOffset, rtoffset);
+				wplan->endOffset =
+					fix_scan_expr(root, wplan->endOffset, rtoffset);
+			}
+			break;
+		case T_Result:
+			{
+				Result	   *splan = (Result *) plan;
+
+				/*
+				 * Result may or may not have a subplan; if not, it's more
+				 * like a scan node than an upper node.
+				 */
+				if (splan->plan.lefttree != NULL)
+					set_upper_references(root, plan, rtoffset);
+				else
+				{
+					splan->plan.targetlist =
+						fix_scan_list(root, splan->plan.targetlist, rtoffset);
+					splan->plan.qual =
+						fix_scan_list(root, splan->plan.qual, rtoffset);
+				}
+				/* resconstantqual can't contain any subplan variable refs */
+				splan->resconstantqual =
+					fix_scan_expr(root, splan->resconstantqual, rtoffset);
+			}
+			break;
+		case T_ProjectSet:
+			set_upper_references(root, plan, rtoffset);
+			break;
+		case T_ModifyTable:
+			{
+				ModifyTable *splan = (ModifyTable *) plan;
+
+				Assert(splan->plan.targetlist == NIL);
+				Assert(splan->plan.qual == NIL);
+
+				splan->withCheckOptionLists =
+					fix_scan_list(root, splan->withCheckOptionLists, rtoffset);
+
+				if (splan->returningLists)
+				{
+					List	   *newRL = NIL;
+					ListCell   *lcrl,
+							   *lcrr,
+							   *lcp;
+
+					/*
+					 * Pass each per-subplan returningList through
+					 * set_returning_clause_references().
+					 */
+					Assert(list_length(splan->returningLists) == list_length(splan->resultRelations));
+					Assert(list_length(splan->returningLists) == list_length(splan->plans));
+					forthree(lcrl, splan->returningLists,
+							 lcrr, splan->resultRelations,
+							 lcp, splan->plans)
+					{
+						List	   *rlist = (List *) lfirst(lcrl);
+						Index		resultrel = lfirst_int(lcrr);
+						Plan	   *subplan = (Plan *) lfirst(lcp);
+
+						rlist = set_returning_clause_references(root,
+																rlist,
+																subplan,
+																resultrel,
+																rtoffset);
+						newRL = lappend(newRL, rlist);
+					}
+					splan->returningLists = newRL;
+
+					/*
+					 * Set up the visible plan targetlist as being the same as
+					 * the first RETURNING list. This is for the use of
+					 * EXPLAIN; the executor won't pay any attention to the
+					 * targetlist.  We postpone this step until here so that
+					 * we don't have to do set_returning_clause_references()
+					 * twice on identical targetlists.
+					 */
+					splan->plan.targetlist = copyObject(linitial(newRL));
+				}
+
+				/*
+				 * We treat ModifyTable with ON CONFLICT as a form of 'pseudo
+				 * join', where the inner side is the EXCLUDED tuple.
+				 * Therefore use fix_join_expr to setup the relevant variables
+				 * to INNER_VAR. We explicitly don't create any OUTER_VARs as
+				 * those are already used by RETURNING and it seems better to
+				 * be non-conflicting.
+				 */
+				if (splan->onConflictSet)
+				{
+					indexed_tlist *itlist;
+
+					itlist = build_tlist_index(splan->exclRelTlist);
+
+					splan->onConflictSet =
+						fix_join_expr(root, splan->onConflictSet,
+									  NULL, itlist,
+									  linitial_int(splan->resultRelations),
+									  rtoffset);
+
+					splan->onConflictWhere = (Node *)
+						fix_join_expr(root, (List *) splan->onConflictWhere,
+									  NULL, itlist,
+									  linitial_int(splan->resultRelations),
+									  rtoffset);
+
+					pfree(itlist);
+
+					splan->exclRelTlist =
+						fix_scan_list(root, splan->exclRelTlist, rtoffset);
+				}
+
+				splan->nominalRelation += rtoffset;
+				splan->exclRelRTI += rtoffset;
+
+				foreach(l, splan->partitioned_rels)
+				{
+					lfirst_int(l) += rtoffset;
+				}
+				foreach(l, splan->resultRelations)
+				{
+					lfirst_int(l) += rtoffset;
+				}
+				foreach(l, splan->rowMarks)
+				{
+					PlanRowMark *rc = (PlanRowMark *) lfirst(l);
+
+					rc->rti += rtoffset;
+					rc->prti += rtoffset;
+				}
+				foreach(l, splan->plans)
+				{
+					lfirst(l) = set_plan_refs(root,
+											  (Plan *) lfirst(l),
+											  rtoffset);
+				}
+
+				/*
+				 * Append this ModifyTable node's final result relation RT
+				 * index(es) to the global list for the plan, and set its
+				 * resultRelIndex to reflect their starting position in the
+				 * global list.
+				 */
+				splan->resultRelIndex = list_length(root->glob->resultRelations);
+				root->glob->resultRelations =
+					list_concat(root->glob->resultRelations,
+								list_copy(splan->resultRelations));
+
+				/*
+				 * If the main target relation is a partitioned table, the
+				 * following list contains the RT indexes of partitioned child
+				 * relations including the root, which are not included in the
+				 * above list.  We also keep RT indexes of the roots
+				 * separately to be identitied as such during the executor
+				 * initialization.
+				 */
+				if (splan->partitioned_rels != NIL)
+				{
+					root->glob->nonleafResultRelations =
+						list_concat(root->glob->nonleafResultRelations,
+									list_copy(splan->partitioned_rels));
+					/* Remember where this root will be in the global list. */
+					splan->rootResultRelIndex =
+						list_length(root->glob->rootResultRelations);
+					root->glob->rootResultRelations =
+						lappend_int(root->glob->rootResultRelations,
+									linitial_int(splan->partitioned_rels));
+				}
+			}
+			break;
+		case T_Append:
+			{
+				Append	   *splan = (Append *) plan;
+
+				/*
+				 * Append, like Sort et al, doesn't actually evaluate its
+				 * targetlist or check quals.
+				 */
+				set_dummy_tlist_references(plan, rtoffset);
+				Assert(splan->plan.qual == NIL);
+				foreach(l, splan->partitioned_rels)
+				{
+					lfirst_int(l) += rtoffset;
+				}
+				foreach(l, splan->appendplans)
+				{
+					lfirst(l) = set_plan_refs(root,
+											  (Plan *) lfirst(l),
+											  rtoffset);
+				}
+			}
+			break;
+		case T_MergeAppend:
+			{
+				MergeAppend *splan = (MergeAppend *) plan;
+
+				/*
+				 * MergeAppend, like Sort et al, doesn't actually evaluate its
+				 * targetlist or check quals.
+				 */
+				set_dummy_tlist_references(plan, rtoffset);
+				Assert(splan->plan.qual == NIL);
+				foreach(l, splan->partitioned_rels)
+				{
+					lfirst_int(l) += rtoffset;
+				}
+				foreach(l, splan->mergeplans)
+				{
+					lfirst(l) = set_plan_refs(root,
+											  (Plan *) lfirst(l),
+											  rtoffset);
+				}
+			}
+			break;
+		case T_RecursiveUnion:
+			/* This doesn't evaluate targetlist or check quals either */
+			set_dummy_tlist_references(plan, rtoffset);
+			Assert(plan->qual == NIL);
+			break;
+		case T_BitmapAnd:
+			{
+				BitmapAnd  *splan = (BitmapAnd *) plan;
+
+				/* BitmapAnd works like Append, but has no tlist */
+				Assert(splan->plan.targetlist == NIL);
+				Assert(splan->plan.qual == NIL);
+				foreach(l, splan->bitmapplans)
+				{
+					lfirst(l) = set_plan_refs(root,
+											  (Plan *) lfirst(l),
+											  rtoffset);
+				}
+			}
+			break;
+		case T_BitmapOr:
+			{
+				BitmapOr   *splan = (BitmapOr *) plan;
+
+				/* BitmapOr works like Append, but has no tlist */
+				Assert(splan->plan.targetlist == NIL);
+				Assert(splan->plan.qual == NIL);
+				foreach(l, splan->bitmapplans)
+				{
+					lfirst(l) = set_plan_refs(root,
+											  (Plan *) lfirst(l),
+											  rtoffset);
+				}
+			}
+			break;
+		default:
+			elog(ERROR, "unrecognized node type: %d",
+				 (int) nodeTag(plan));
+			break;
+	}
+
+	/*
+	 * Now recurse into child plans, if any
+	 *
+	 * NOTE: it is essential that we recurse into child plans AFTER we set
+	 * subplan references in this plan's tlist and quals.  If we did the
+	 * reference-adjustments bottom-up, then we would fail to match this
+	 * plan's var nodes against the already-modified nodes of the children.
+	 */
+	plan->lefttree = set_plan_refs(root, plan->lefttree, rtoffset);
+	plan->righttree = set_plan_refs(root, plan->righttree, rtoffset);
+
+	return plan;
+}
+
+/*
+ * set_indexonlyscan_references
+ *		Do set_plan_references processing on an IndexOnlyScan
+ *
+ * This is unlike the handling of a plain IndexScan because we have to
+ * convert Vars referencing the heap into Vars referencing the index.
+ * We can use the fix_upper_expr machinery for that, by working from a
+ * targetlist describing the index columns.
+ */
+static Plan *
+set_indexonlyscan_references(PlannerInfo *root,
+							 IndexOnlyScan *plan,
+							 int rtoffset)
+{
+	indexed_tlist *index_itlist;
+
+	index_itlist = build_tlist_index(plan->indextlist);
+
+	plan->scan.scanrelid += rtoffset;
+	plan->scan.plan.targetlist = (List *)
+		fix_upper_expr(root,
+					   (Node *) plan->scan.plan.targetlist,
+					   index_itlist,
+					   INDEX_VAR,
+					   rtoffset);
+	plan->scan.plan.qual = (List *)
+		fix_upper_expr(root,
+					   (Node *) plan->scan.plan.qual,
+					   index_itlist,
+					   INDEX_VAR,
+					   rtoffset);
+	/* indexqual is already transformed to reference index columns */
+	plan->indexqual = fix_scan_list(root, plan->indexqual, rtoffset);
+	/* indexorderby is already transformed to reference index columns */
+	plan->indexorderby = fix_scan_list(root, plan->indexorderby, rtoffset);
+	/* indextlist must NOT be transformed to reference index columns */
+	plan->indextlist = fix_scan_list(root, plan->indextlist, rtoffset);
+
+	pfree(index_itlist);
+
+	return (Plan *) plan;
+}
+
+/*
+ * set_subqueryscan_references
+ *		Do set_plan_references processing on a SubqueryScan
+ *
+ * We try to strip out the SubqueryScan entirely; if we can't, we have
+ * to do the normal processing on it.
+ */
+static Plan *
+set_subqueryscan_references(PlannerInfo *root,
+							SubqueryScan *plan,
+							int rtoffset)
+{
+	RelOptInfo *rel;
+	Plan	   *result;
+
+	/* Need to look up the subquery's RelOptInfo, since we need its subroot */
+	rel = find_base_rel(root, plan->scan.scanrelid);
+
+	/* Recursively process the subplan */
+	plan->subplan = set_plan_references(rel->subroot, plan->subplan);
+
+	if (trivial_subqueryscan(plan))
+	{
+		/*
+		 * We can omit the SubqueryScan node and just pull up the subplan.
+		 */
+		ListCell   *lp,
+				   *lc;
+
+		result = plan->subplan;
+
+		/* We have to be sure we don't lose any initplans */
+		result->initPlan = list_concat(plan->scan.plan.initPlan,
+									   result->initPlan);
+
+		/*
+		 * We also have to transfer the SubqueryScan's result-column names
+		 * into the subplan, else columns sent to client will be improperly
+		 * labeled if this is the topmost plan level.  Copy the "source
+		 * column" information too.
+		 */
+		forboth(lp, plan->scan.plan.targetlist, lc, result->targetlist)
+		{
+			TargetEntry *ptle = (TargetEntry *) lfirst(lp);
+			TargetEntry *ctle = (TargetEntry *) lfirst(lc);
+
+			ctle->resname = ptle->resname;
+			ctle->resorigtbl = ptle->resorigtbl;
+			ctle->resorigcol = ptle->resorigcol;
+		}
+	}
+	else
+	{
+		/*
+		 * Keep the SubqueryScan node.  We have to do the processing that
+		 * set_plan_references would otherwise have done on it.  Notice we do
+		 * not do set_upper_references() here, because a SubqueryScan will
+		 * always have been created with correct references to its subplan's
+		 * outputs to begin with.
+		 */
+		plan->scan.scanrelid += rtoffset;
+		plan->scan.plan.targetlist =
+			fix_scan_list(root, plan->scan.plan.targetlist, rtoffset);
+		plan->scan.plan.qual =
+			fix_scan_list(root, plan->scan.plan.qual, rtoffset);
+
+		result = (Plan *) plan;
+	}
+
+	return result;
+}
+
+/*
+ * trivial_subqueryscan
+ *		Detect whether a SubqueryScan can be deleted from the plan tree.
+ *
+ * We can delete it if it has no qual to check and the targetlist just
+ * regurgitates the output of the child plan.
+ */
+static bool
+trivial_subqueryscan(SubqueryScan *plan)
+{
+	int			attrno;
+	ListCell   *lp,
+			   *lc;
+
+	if (plan->scan.plan.qual != NIL)
+		return false;
+
+	if (list_length(plan->scan.plan.targetlist) !=
+		list_length(plan->subplan->targetlist))
+		return false;			/* tlists not same length */
+
+	attrno = 1;
+	forboth(lp, plan->scan.plan.targetlist, lc, plan->subplan->targetlist)
+	{
+		TargetEntry *ptle = (TargetEntry *) lfirst(lp);
+		TargetEntry *ctle = (TargetEntry *) lfirst(lc);
+
+		if (ptle->resjunk != ctle->resjunk)
+			return false;		/* tlist doesn't match junk status */
+
+		/*
+		 * We accept either a Var referencing the corresponding element of the
+		 * subplan tlist, or a Const equaling the subplan element. See
+		 * generate_setop_tlist() for motivation.
+		 */
+		if (ptle->expr && IsA(ptle->expr, Var))
+		{
+			Var		   *var = (Var *) ptle->expr;
+
+			Assert(var->varno == plan->scan.scanrelid);
+			Assert(var->varlevelsup == 0);
+			if (var->varattno != attrno)
+				return false;	/* out of order */
+		}
+		else if (ptle->expr && IsA(ptle->expr, Const))
+		{
+			if (!equal(ptle->expr, ctle->expr))
+				return false;
+		}
+		else
+			return false;
+
+		attrno++;
+	}
+
+	return true;
+}
+
+/*
+ * set_foreignscan_references
+ *	   Do set_plan_references processing on a ForeignScan
+ */
+static void
+set_foreignscan_references(PlannerInfo *root,
+						   ForeignScan *fscan,
+						   int rtoffset)
+{
+	/* Adjust scanrelid if it's valid */
+	if (fscan->scan.scanrelid > 0)
+		fscan->scan.scanrelid += rtoffset;
+
+	if (fscan->fdw_scan_tlist != NIL || fscan->scan.scanrelid == 0)
+	{
+		/*
+		 * Adjust tlist, qual, fdw_exprs, fdw_recheck_quals to reference
+		 * foreign scan tuple
+		 */
+		indexed_tlist *itlist = build_tlist_index(fscan->fdw_scan_tlist);
+
+		fscan->scan.plan.targetlist = (List *)
+			fix_upper_expr(root,
+						   (Node *) fscan->scan.plan.targetlist,
+						   itlist,
+						   INDEX_VAR,
+						   rtoffset);
+		fscan->scan.plan.qual = (List *)
+			fix_upper_expr(root,
+						   (Node *) fscan->scan.plan.qual,
+						   itlist,
+						   INDEX_VAR,
+						   rtoffset);
+		fscan->fdw_exprs = (List *)
+			fix_upper_expr(root,
+						   (Node *) fscan->fdw_exprs,
+						   itlist,
+						   INDEX_VAR,
+						   rtoffset);
+		fscan->fdw_recheck_quals = (List *)
+			fix_upper_expr(root,
+						   (Node *) fscan->fdw_recheck_quals,
+						   itlist,
+						   INDEX_VAR,
+						   rtoffset);
+		pfree(itlist);
+		/* fdw_scan_tlist itself just needs fix_scan_list() adjustments */
+		fscan->fdw_scan_tlist =
+			fix_scan_list(root, fscan->fdw_scan_tlist, rtoffset);
+	}
+	else
+	{
+		/*
+		 * Adjust tlist, qual, fdw_exprs, fdw_recheck_quals in the standard
+		 * way
+		 */
+		fscan->scan.plan.targetlist =
+			fix_scan_list(root, fscan->scan.plan.targetlist, rtoffset);
+		fscan->scan.plan.qual =
+			fix_scan_list(root, fscan->scan.plan.qual, rtoffset);
+		fscan->fdw_exprs =
+			fix_scan_list(root, fscan->fdw_exprs, rtoffset);
+		fscan->fdw_recheck_quals =
+			fix_scan_list(root, fscan->fdw_recheck_quals, rtoffset);
+	}
+
+	/* Adjust fs_relids if needed */
+	if (rtoffset > 0)
+	{
+		Bitmapset  *tempset = NULL;
+		int			x = -1;
+
+		while ((x = bms_next_member(fscan->fs_relids, x)) >= 0)
+			tempset = bms_add_member(tempset, x + rtoffset);
+		fscan->fs_relids = tempset;
+	}
+}
+
+/*
+ * set_customscan_references
+ *	   Do set_plan_references processing on a CustomScan
+ */
+static void
+set_customscan_references(PlannerInfo *root,
+						  CustomScan *cscan,
+						  int rtoffset)
+{
+	ListCell   *lc;
+
+	/* Adjust scanrelid if it's valid */
+	if (cscan->scan.scanrelid > 0)
+		cscan->scan.scanrelid += rtoffset;
+
+	if (cscan->custom_scan_tlist != NIL || cscan->scan.scanrelid == 0)
+	{
+		/* Adjust tlist, qual, custom_exprs to reference custom scan tuple */
+		indexed_tlist *itlist = build_tlist_index(cscan->custom_scan_tlist);
+
+		cscan->scan.plan.targetlist = (List *)
+			fix_upper_expr(root,
+						   (Node *) cscan->scan.plan.targetlist,
+						   itlist,
+						   INDEX_VAR,
+						   rtoffset);
+		cscan->scan.plan.qual = (List *)
+			fix_upper_expr(root,
+						   (Node *) cscan->scan.plan.qual,
+						   itlist,
+						   INDEX_VAR,
+						   rtoffset);
+		cscan->custom_exprs = (List *)
+			fix_upper_expr(root,
+						   (Node *) cscan->custom_exprs,
+						   itlist,
+						   INDEX_VAR,
+						   rtoffset);
+		pfree(itlist);
+		/* custom_scan_tlist itself just needs fix_scan_list() adjustments */
+		cscan->custom_scan_tlist =
+			fix_scan_list(root, cscan->custom_scan_tlist, rtoffset);
+	}
+	else
+	{
+		/* Adjust tlist, qual, custom_exprs in the standard way */
+		cscan->scan.plan.targetlist =
+			fix_scan_list(root, cscan->scan.plan.targetlist, rtoffset);
+		cscan->scan.plan.qual =
+			fix_scan_list(root, cscan->scan.plan.qual, rtoffset);
+		cscan->custom_exprs =
+			fix_scan_list(root, cscan->custom_exprs, rtoffset);
+	}
+
+	/* Adjust child plan-nodes recursively, if needed */
+	foreach(lc, cscan->custom_plans)
+	{
+		lfirst(lc) = set_plan_refs(root, (Plan *) lfirst(lc), rtoffset);
+	}
+
+	/* Adjust custom_relids if needed */
+	if (rtoffset > 0)
+	{
+		Bitmapset  *tempset = NULL;
+		int			x = -1;
+
+		while ((x = bms_next_member(cscan->custom_relids, x)) >= 0)
+			tempset = bms_add_member(tempset, x + rtoffset);
+		cscan->custom_relids = tempset;
+	}
+}
+
+/*
+ * copyVar
+ *		Copy a Var node.
+ *
+ * fix_scan_expr and friends do this enough times that it's worth having
+ * a bespoke routine instead of using the generic copyObject() function.
+ */
+static inline Var *
+copyVar(Var *var)
+{
+	Var		   *newvar = (Var *) palloc(sizeof(Var));
+
+	*newvar = *var;
+	return newvar;
+}
+
+/*
+ * fix_expr_common
+ *		Do generic set_plan_references processing on an expression node
+ *
+ * This is code that is common to all variants of expression-fixing.
+ * We must look up operator opcode info for OpExpr and related nodes,
+ * add OIDs from regclass Const nodes into root->glob->relationOids, and
+ * add PlanInvalItems for user-defined functions into root->glob->invalItems.
+ * We also fill in column index lists for GROUPING() expressions.
+ *
+ * We assume it's okay to update opcode info in-place.  So this could possibly
+ * scribble on the planner's input data structures, but it's OK.
+ */
+static void
+fix_expr_common(PlannerInfo *root, Node *node)
+{
+	/* We assume callers won't call us on a NULL pointer */
+	if (IsA(node, Aggref))
+	{
+		record_plan_function_dependency(root,
+										((Aggref *) node)->aggfnoid);
+	}
+	else if (IsA(node, WindowFunc))
+	{
+		record_plan_function_dependency(root,
+										((WindowFunc *) node)->winfnoid);
+	}
+	else if (IsA(node, FuncExpr))
+	{
+		record_plan_function_dependency(root,
+										((FuncExpr *) node)->funcid);
+	}
+	else if (IsA(node, OpExpr))
+	{
+		set_opfuncid((OpExpr *) node);
+		record_plan_function_dependency(root,
+										((OpExpr *) node)->opfuncid);
+	}
+	else if (IsA(node, DistinctExpr))
+	{
+		set_opfuncid((OpExpr *) node);	/* rely on struct equivalence */
+		record_plan_function_dependency(root,
+										((DistinctExpr *) node)->opfuncid);
+	}
+	else if (IsA(node, NullIfExpr))
+	{
+		set_opfuncid((OpExpr *) node);	/* rely on struct equivalence */
+		record_plan_function_dependency(root,
+										((NullIfExpr *) node)->opfuncid);
+	}
+	else if (IsA(node, ScalarArrayOpExpr))
+	{
+		set_sa_opfuncid((ScalarArrayOpExpr *) node);
+		record_plan_function_dependency(root,
+										((ScalarArrayOpExpr *) node)->opfuncid);
+	}
+	else if (IsA(node, ArrayCoerceExpr))
+	{
+		if (OidIsValid(((ArrayCoerceExpr *) node)->elemfuncid))
+			record_plan_function_dependency(root,
+											((ArrayCoerceExpr *) node)->elemfuncid);
+	}
+	else if (IsA(node, Const))
+	{
+		Const	   *con = (Const *) node;
+
+		/* Check for regclass reference */
+		if (ISREGCLASSCONST(con))
+			root->glob->relationOids =
+				lappend_oid(root->glob->relationOids,
+							DatumGetObjectId(con->constvalue));
+	}
+	else if (IsA(node, GroupingFunc))
+	{
+		GroupingFunc *g = (GroupingFunc *) node;
+		AttrNumber *grouping_map = root->grouping_map;
+
+		/* If there are no grouping sets, we don't need this. */
+
+		Assert(grouping_map || g->cols == NIL);
+
+		if (grouping_map)
+		{
+			ListCell   *lc;
+			List	   *cols = NIL;
+
+			foreach(lc, g->refs)
+			{
+				cols = lappend_int(cols, grouping_map[lfirst_int(lc)]);
+			}
+
+			Assert(!g->cols || equal(cols, g->cols));
+
+			if (!g->cols)
+				g->cols = cols;
+		}
+	}
+}
+
+/*
+ * fix_param_node
+ *		Do set_plan_references processing on a Param
+ *
+ * If it's a PARAM_MULTIEXPR, replace it with the appropriate Param from
+ * root->multiexpr_params; otherwise no change is needed.
+ * Just for paranoia's sake, we make a copy of the node in either case.
+ */
+static Node *
+fix_param_node(PlannerInfo *root, Param *p)
+{
+	if (p->paramkind == PARAM_MULTIEXPR)
+	{
+		int			subqueryid = p->paramid >> 16;
+		int			colno = p->paramid & 0xFFFF;
+		List	   *params;
+
+		if (subqueryid <= 0 ||
+			subqueryid > list_length(root->multiexpr_params))
+			elog(ERROR, "unexpected PARAM_MULTIEXPR ID: %d", p->paramid);
+		params = (List *) list_nth(root->multiexpr_params, subqueryid - 1);
+		if (colno <= 0 || colno > list_length(params))
+			elog(ERROR, "unexpected PARAM_MULTIEXPR ID: %d", p->paramid);
+		return copyObject(list_nth(params, colno - 1));
+	}
+	return (Node *) copyObject(p);
+}
+
+/*
+ * fix_scan_expr
+ *		Do set_plan_references processing on a scan-level expression
+ *
+ * This consists of incrementing all Vars' varnos by rtoffset,
+ * replacing PARAM_MULTIEXPR Params, expanding PlaceHolderVars,
+ * replacing Aggref nodes that should be replaced by initplan output Params,
+ * looking up operator opcode info for OpExpr and related nodes,
+ * and adding OIDs from regclass Const nodes into root->glob->relationOids.
+ */
+static Node *
+fix_scan_expr(PlannerInfo *root, Node *node, int rtoffset)
+{
+	fix_scan_expr_context context;
+
+	context.root = root;
+	context.rtoffset = rtoffset;
+
+	if (rtoffset != 0 ||
+		root->multiexpr_params != NIL ||
+		root->glob->lastPHId != 0 ||
+		root->minmax_aggs != NIL)
+	{
+		return fix_scan_expr_mutator(node, &context);
+	}
+	else
+	{
+		/*
+		 * If rtoffset == 0, we don't need to change any Vars, and if there
+		 * are no MULTIEXPR subqueries then we don't need to replace
+		 * PARAM_MULTIEXPR Params, and if there are no placeholders anywhere
+		 * we won't need to remove them, and if there are no minmax Aggrefs we
+		 * won't need to replace them.  Then it's OK to just scribble on the
+		 * input node tree instead of copying (since the only change, filling
+		 * in any unset opfuncid fields, is harmless).  This saves just enough
+		 * cycles to be noticeable on trivial queries.
+		 */
+		(void) fix_scan_expr_walker(node, &context);
+		return node;
+	}
+}
+
+static Node *
+fix_scan_expr_mutator(Node *node, fix_scan_expr_context *context)
+{
+	if (node == NULL)
+		return NULL;
+	if (IsA(node, Var))
+	{
+		Var		   *var = copyVar((Var *) node);
+
+		Assert(var->varlevelsup == 0);
+
+		/*
+		 * We should not see any Vars marked INNER_VAR or OUTER_VAR.  But an
+		 * indexqual expression could contain INDEX_VAR Vars.
+		 */
+		Assert(var->varno != INNER_VAR);
+		Assert(var->varno != OUTER_VAR);
+		if (!IS_SPECIAL_VARNO(var->varno))
+			var->varno += context->rtoffset;
+		if (var->varnoold > 0)
+			var->varnoold += context->rtoffset;
+		return (Node *) var;
+	}
+	if (IsA(node, Param))
+		return fix_param_node(context->root, (Param *) node);
+	if (IsA(node, Aggref))
+	{
+		Aggref	   *aggref = (Aggref *) node;
+
+		/* See if the Aggref should be replaced by a Param */
+		if (context->root->minmax_aggs != NIL &&
+			list_length(aggref->args) == 1)
+		{
+			TargetEntry *curTarget = (TargetEntry *) linitial(aggref->args);
+			ListCell   *lc;
+
+			foreach(lc, context->root->minmax_aggs)
+			{
+				MinMaxAggInfo *mminfo = (MinMaxAggInfo *) lfirst(lc);
+
+				if (mminfo->aggfnoid == aggref->aggfnoid &&
+					equal(mminfo->target, curTarget->expr))
+					return (Node *) copyObject(mminfo->param);
+			}
+		}
+		/* If no match, just fall through to process it normally */
+	}
+	if (IsA(node, CurrentOfExpr))
+	{
+		CurrentOfExpr *cexpr = (CurrentOfExpr *) copyObject(node);
+
+		Assert(cexpr->cvarno != INNER_VAR);
+		Assert(cexpr->cvarno != OUTER_VAR);
+		if (!IS_SPECIAL_VARNO(cexpr->cvarno))
+			cexpr->cvarno += context->rtoffset;
+		return (Node *) cexpr;
+	}
+	if (IsA(node, PlaceHolderVar))
+	{
+		/* At scan level, we should always just evaluate the contained expr */
+		PlaceHolderVar *phv = (PlaceHolderVar *) node;
+
+		return fix_scan_expr_mutator((Node *) phv->phexpr, context);
+	}
+	fix_expr_common(context->root, node);
+	return expression_tree_mutator(node, fix_scan_expr_mutator,
+								   (void *) context);
+}
+
+static bool
+fix_scan_expr_walker(Node *node, fix_scan_expr_context *context)
+{
+	if (node == NULL)
+		return false;
+	Assert(!IsA(node, PlaceHolderVar));
+	fix_expr_common(context->root, node);
+	return expression_tree_walker(node, fix_scan_expr_walker,
+								  (void *) context);
+}
+
+/*
+ * set_join_references
+ *	  Modify the target list and quals of a join node to reference its
+ *	  subplans, by setting the varnos to OUTER_VAR or INNER_VAR and setting
+ *	  attno values to the result domain number of either the corresponding
+ *	  outer or inner join tuple item.  Also perform opcode lookup for these
+ *	  expressions, and add regclass OIDs to root->glob->relationOids.
+ */
+static void
+set_join_references(PlannerInfo *root, Join *join, int rtoffset)
+{
+	Plan	   *outer_plan = join->plan.lefttree;
+	Plan	   *inner_plan = join->plan.righttree;
+	indexed_tlist *outer_itlist;
+	indexed_tlist *inner_itlist;
+
+	outer_itlist = build_tlist_index(outer_plan->targetlist);
+	inner_itlist = build_tlist_index(inner_plan->targetlist);
+
+	/*
+	 * First process the joinquals (including merge or hash clauses).  These
+	 * are logically below the join so they can always use all values
+	 * available from the input tlists.  It's okay to also handle
+	 * NestLoopParams now, because those couldn't refer to nullable
+	 * subexpressions.
+	 */
+	join->joinqual = fix_join_expr(root,
+								   join->joinqual,
+								   outer_itlist,
+								   inner_itlist,
+								   (Index) 0,
+								   rtoffset);
+
+	/* Now do join-type-specific stuff */
+	if (IsA(join, NestLoop))
+	{
+		NestLoop   *nl = (NestLoop *) join;
+		ListCell   *lc;
+
+		foreach(lc, nl->nestParams)
+		{
+			NestLoopParam *nlp = (NestLoopParam *) lfirst(lc);
+
+			nlp->paramval = (Var *) fix_upper_expr(root,
+												   (Node *) nlp->paramval,
+												   outer_itlist,
+												   OUTER_VAR,
+												   rtoffset);
+			/* Check we replaced any PlaceHolderVar with simple Var */
+			if (!(IsA(nlp->paramval, Var) &&
+				  nlp->paramval->varno == OUTER_VAR))
+				elog(ERROR, "NestLoopParam was not reduced to a simple Var");
+		}
+	}
+	else if (IsA(join, MergeJoin))
+	{
+		MergeJoin  *mj = (MergeJoin *) join;
+
+		mj->mergeclauses = fix_join_expr(root,
+										 mj->mergeclauses,
+										 outer_itlist,
+										 inner_itlist,
+										 (Index) 0,
+										 rtoffset);
+	}
+	else if (IsA(join, HashJoin))
+	{
+		HashJoin   *hj = (HashJoin *) join;
+
+		hj->hashclauses = fix_join_expr(root,
+										hj->hashclauses,
+										outer_itlist,
+										inner_itlist,
+										(Index) 0,
+										rtoffset);
+	}
+
+	/*
+	 * Now we need to fix up the targetlist and qpqual, which are logically
+	 * above the join.  This means they should not re-use any input expression
+	 * that was computed in the nullable side of an outer join.  Vars and
+	 * PlaceHolderVars are fine, so we can implement this restriction just by
+	 * clearing has_non_vars in the indexed_tlist structs.
+	 *
+	 * XXX This is a grotty workaround for the fact that we don't clearly
+	 * distinguish between a Var appearing below an outer join and the "same"
+	 * Var appearing above it.  If we did, we'd not need to hack the matching
+	 * rules this way.
+	 */
+	switch (join->jointype)
+	{
+		case JOIN_LEFT:
+		case JOIN_SEMI:
+		case JOIN_ANTI:
+			inner_itlist->has_non_vars = false;
+			break;
+		case JOIN_RIGHT:
+			outer_itlist->has_non_vars = false;
+			break;
+		case JOIN_FULL:
+			outer_itlist->has_non_vars = false;
+			inner_itlist->has_non_vars = false;
+			break;
+		default:
+			break;
+	}
+
+	join->plan.targetlist = fix_join_expr(root,
+										  join->plan.targetlist,
+										  outer_itlist,
+										  inner_itlist,
+										  (Index) 0,
+										  rtoffset);
+	join->plan.qual = fix_join_expr(root,
+									join->plan.qual,
+									outer_itlist,
+									inner_itlist,
+									(Index) 0,
+									rtoffset);
+
+	pfree(outer_itlist);
+	pfree(inner_itlist);
+}
+
+/*
+ * set_upper_references
+ *	  Update the targetlist and quals of an upper-level plan node
+ *	  to refer to the tuples returned by its lefttree subplan.
+ *	  Also perform opcode lookup for these expressions, and
+ *	  add regclass OIDs to root->glob->relationOids.
+ *
+ * This is used for single-input plan types like Agg, Group, Result.
+ *
+ * In most cases, we have to match up individual Vars in the tlist and
+ * qual expressions with elements of the subplan's tlist (which was
+ * generated by flattening these selfsame expressions, so it should have all
+ * the required variables).  There is an important exception, however:
+ * depending on where we are in the plan tree, sort/group columns may have
+ * been pushed into the subplan tlist unflattened.  If these values are also
+ * needed in the output then we want to reference the subplan tlist element
+ * rather than recomputing the expression.
+ */
+static void
+set_upper_references(PlannerInfo *root, Plan *plan, int rtoffset)
+{
+	Plan	   *subplan = plan->lefttree;
+	indexed_tlist *subplan_itlist;
+	List	   *output_targetlist;
+	ListCell   *l;
+
+	subplan_itlist = build_tlist_index(subplan->targetlist);
+
+	output_targetlist = NIL;
+	foreach(l, plan->targetlist)
+	{
+		TargetEntry *tle = (TargetEntry *) lfirst(l);
+		Node	   *newexpr;
+
+		/* If it's a sort/group item, first try to match by sortref */
+		if (tle->ressortgroupref != 0)
+		{
+			newexpr = (Node *)
+				search_indexed_tlist_for_sortgroupref(tle->expr,
+													  tle->ressortgroupref,
+													  subplan_itlist,
+													  OUTER_VAR);
+			if (!newexpr)
+				newexpr = fix_upper_expr(root,
+										 (Node *) tle->expr,
+										 subplan_itlist,
+										 OUTER_VAR,
+										 rtoffset);
+		}
+		else
+			newexpr = fix_upper_expr(root,
+									 (Node *) tle->expr,
+									 subplan_itlist,
+									 OUTER_VAR,
+									 rtoffset);
+		tle = flatCopyTargetEntry(tle);
+		tle->expr = (Expr *) newexpr;
+		output_targetlist = lappend(output_targetlist, tle);
+	}
+	plan->targetlist = output_targetlist;
+
+	plan->qual = (List *)
+		fix_upper_expr(root,
+					   (Node *) plan->qual,
+					   subplan_itlist,
+					   OUTER_VAR,
+					   rtoffset);
+
+	pfree(subplan_itlist);
+}
+
+/*
+ * Recursively scan an expression tree and convert Aggrefs to the proper
+ * intermediate form for combining aggregates.  This means (1) replacing each
+ * one's argument list with a single argument that is the original Aggref
+ * modified to show partial aggregation and (2) changing the upper Aggref to
+ * show combining aggregation.
+ *
+ * After this step, set_upper_references will replace the partial Aggrefs
+ * with Vars referencing the lower Agg plan node's outputs, so that the final
+ * form seen by the executor is a combining Aggref with a Var as input.
+ *
+ * It's rather messy to postpone this step until setrefs.c; ideally it'd be
+ * done in createplan.c.  The difficulty is that once we modify the Aggref
+ * expressions, they will no longer be equal() to their original form and
+ * so cross-plan-node-level matches will fail.  So this has to happen after
+ * the plan node above the Agg has resolved its subplan references.
+ */
+static Node *
+convert_combining_aggrefs(Node *node, void *context)
+{
+	if (node == NULL)
+		return NULL;
+	if (IsA(node, Aggref))
+	{
+		Aggref	   *orig_agg = (Aggref *) node;
+		Aggref	   *child_agg;
+		Aggref	   *parent_agg;
+
+		/* Assert we've not chosen to partial-ize any unsupported cases */
+		Assert(orig_agg->aggorder == NIL);
+		Assert(orig_agg->aggdistinct == NIL);
+
+		/*
+		 * Since aggregate calls can't be nested, we needn't recurse into the
+		 * arguments.  But for safety, flat-copy the Aggref node itself rather
+		 * than modifying it in-place.
+		 */
+		child_agg = makeNode(Aggref);
+		memcpy(child_agg, orig_agg, sizeof(Aggref));
+
+		/*
+		 * For the parent Aggref, we want to copy all the fields of the
+		 * original aggregate *except* the args list, which we'll replace
+		 * below, and the aggfilter expression, which should be applied only
+		 * by the child not the parent.  Rather than explicitly knowing about
+		 * all the other fields here, we can momentarily modify child_agg to
+		 * provide a suitable source for copyObject.
+		 */
+		child_agg->args = NIL;
+		child_agg->aggfilter = NULL;
+		parent_agg = copyObject(child_agg);
+		child_agg->args = orig_agg->args;
+		child_agg->aggfilter = orig_agg->aggfilter;
+
+		/*
+		 * Now, set up child_agg to represent the first phase of partial
+		 * aggregation.  For now, assume serialization is required.
+		 */
+		mark_partial_aggref(child_agg, AGGSPLIT_INITIAL_SERIAL);
+
+		/*
+		 * And set up parent_agg to represent the second phase.
+		 */
+		parent_agg->args = list_make1(makeTargetEntry((Expr *) child_agg,
+													  1, NULL, false));
+		mark_partial_aggref(parent_agg, AGGSPLIT_FINAL_DESERIAL);
+
+		return (Node *) parent_agg;
+	}
+	return expression_tree_mutator(node, convert_combining_aggrefs,
+								   (void *) context);
+}
+
+/*
+ * set_dummy_tlist_references
+ *	  Replace the targetlist of an upper-level plan node with a simple
+ *	  list of OUTER_VAR references to its child.
+ *
+ * This is used for plan types like Sort and Append that don't evaluate
+ * their targetlists.  Although the executor doesn't care at all what's in
+ * the tlist, EXPLAIN needs it to be realistic.
+ *
+ * Note: we could almost use set_upper_references() here, but it fails for
+ * Append for lack of a lefttree subplan.  Single-purpose code is faster
+ * anyway.
+ */
+static void
+set_dummy_tlist_references(Plan *plan, int rtoffset)
+{
+	List	   *output_targetlist;
+	ListCell   *l;
+
+	output_targetlist = NIL;
+	foreach(l, plan->targetlist)
+	{
+		TargetEntry *tle = (TargetEntry *) lfirst(l);
+		Var		   *oldvar = (Var *) tle->expr;
+		Var		   *newvar;
+
+		/*
+		 * As in search_indexed_tlist_for_non_var(), we prefer to keep Consts
+		 * as Consts, not Vars referencing Consts.  Here, there's no speed
+		 * advantage to be had, but it makes EXPLAIN output look cleaner, and
+		 * again it avoids confusing the executor.
+		 */
+		if (IsA(oldvar, Const))
+		{
+			/* just reuse the existing TLE node */
+			output_targetlist = lappend(output_targetlist, tle);
+			continue;
+		}
+
+		newvar = makeVar(OUTER_VAR,
+						 tle->resno,
+						 exprType((Node *) oldvar),
+						 exprTypmod((Node *) oldvar),
+						 exprCollation((Node *) oldvar),
+						 0);
+		if (IsA(oldvar, Var))
+		{
+			newvar->varnoold = oldvar->varno + rtoffset;
+			newvar->varoattno = oldvar->varattno;
+		}
+		else
+		{
+			newvar->varnoold = 0;	/* wasn't ever a plain Var */
+			newvar->varoattno = 0;
+		}
+
+		tle = flatCopyTargetEntry(tle);
+		tle->expr = (Expr *) newvar;
+		output_targetlist = lappend(output_targetlist, tle);
+	}
+	plan->targetlist = output_targetlist;
+
+	/* We don't touch plan->qual here */
+}
+
+
+/*
+ * build_tlist_index --- build an index data structure for a child tlist
+ *
+ * In most cases, subplan tlists will be "flat" tlists with only Vars,
+ * so we try to optimize that case by extracting information about Vars
+ * in advance.  Matching a parent tlist to a child is still an O(N^2)
+ * operation, but at least with a much smaller constant factor than plain
+ * tlist_member() searches.
+ *
+ * The result of this function is an indexed_tlist struct to pass to
+ * search_indexed_tlist_for_var() or search_indexed_tlist_for_non_var().
+ * When done, the indexed_tlist may be freed with a single pfree().
+ */
+static indexed_tlist *
+build_tlist_index(List *tlist)
+{
+	indexed_tlist *itlist;
+	tlist_vinfo *vinfo;
+	ListCell   *l;
+
+	/* Create data structure with enough slots for all tlist entries */
+	itlist = (indexed_tlist *)
+		palloc(offsetof(indexed_tlist, vars) +
+			   list_length(tlist) * sizeof(tlist_vinfo));
+
+	itlist->tlist = tlist;
+	itlist->has_ph_vars = false;
+	itlist->has_non_vars = false;
+
+	/* Find the Vars and fill in the index array */
+	vinfo = itlist->vars;
+	foreach(l, tlist)
+	{
+		TargetEntry *tle = (TargetEntry *) lfirst(l);
+
+		if (tle->expr && IsA(tle->expr, Var))
+		{
+			Var		   *var = (Var *) tle->expr;
+
+			vinfo->varno = var->varno;
+			vinfo->varattno = var->varattno;
+			vinfo->resno = tle->resno;
+			vinfo++;
+		}
+		else if (tle->expr && IsA(tle->expr, PlaceHolderVar))
+			itlist->has_ph_vars = true;
+		else
+			itlist->has_non_vars = true;
+	}
+
+	itlist->num_vars = (vinfo - itlist->vars);
+
+	return itlist;
+}
+
+/*
+ * build_tlist_index_other_vars --- build a restricted tlist index
+ *
+ * This is like build_tlist_index, but we only index tlist entries that
+ * are Vars belonging to some rel other than the one specified.  We will set
+ * has_ph_vars (allowing PlaceHolderVars to be matched), but not has_non_vars
+ * (so nothing other than Vars and PlaceHolderVars can be matched).
+ */
+static indexed_tlist *
+build_tlist_index_other_vars(List *tlist, Index ignore_rel)
+{
+	indexed_tlist *itlist;
+	tlist_vinfo *vinfo;
+	ListCell   *l;
+
+	/* Create data structure with enough slots for all tlist entries */
+	itlist = (indexed_tlist *)
+		palloc(offsetof(indexed_tlist, vars) +
+			   list_length(tlist) * sizeof(tlist_vinfo));
+
+	itlist->tlist = tlist;
+	itlist->has_ph_vars = false;
+	itlist->has_non_vars = false;
+
+	/* Find the desired Vars and fill in the index array */
+	vinfo = itlist->vars;
+	foreach(l, tlist)
+	{
+		TargetEntry *tle = (TargetEntry *) lfirst(l);
+
+		if (tle->expr && IsA(tle->expr, Var))
+		{
+			Var		   *var = (Var *) tle->expr;
+
+			if (var->varno != ignore_rel)
+			{
+				vinfo->varno = var->varno;
+				vinfo->varattno = var->varattno;
+				vinfo->resno = tle->resno;
+				vinfo++;
+			}
+		}
+		else if (tle->expr && IsA(tle->expr, PlaceHolderVar))
+			itlist->has_ph_vars = true;
+	}
+
+	itlist->num_vars = (vinfo - itlist->vars);
+
+	return itlist;
+}
+
+/*
+ * search_indexed_tlist_for_var --- find a Var in an indexed tlist
+ *
+ * If a match is found, return a copy of the given Var with suitably
+ * modified varno/varattno (to wit, newvarno and the resno of the TLE entry).
+ * Also ensure that varnoold is incremented by rtoffset.
+ * If no match, return NULL.
+ */
+static Var *
+search_indexed_tlist_for_var(Var *var, indexed_tlist *itlist,
+							 Index newvarno, int rtoffset)
+{
+	Index		varno = var->varno;
+	AttrNumber	varattno = var->varattno;
+	tlist_vinfo *vinfo;
+	int			i;
+
+	vinfo = itlist->vars;
+	i = itlist->num_vars;
+	while (i-- > 0)
+	{
+		if (vinfo->varno == varno && vinfo->varattno == varattno)
+		{
+			/* Found a match */
+			Var		   *newvar = copyVar(var);
+
+			newvar->varno = newvarno;
+			newvar->varattno = vinfo->resno;
+			if (newvar->varnoold > 0)
+				newvar->varnoold += rtoffset;
+			return newvar;
+		}
+		vinfo++;
+	}
+	return NULL;				/* no match */
+}
+
+/*
+ * search_indexed_tlist_for_non_var --- find a non-Var in an indexed tlist
+ *
+ * If a match is found, return a Var constructed to reference the tlist item.
+ * If no match, return NULL.
+ *
+ * NOTE: it is a waste of time to call this unless itlist->has_ph_vars or
+ * itlist->has_non_vars.  Furthermore, set_join_references() relies on being
+ * able to prevent matching of non-Vars by clearing itlist->has_non_vars,
+ * so there's a correctness reason not to call it unless that's set.
+ */
+static Var *
+search_indexed_tlist_for_non_var(Expr *node,
+								 indexed_tlist *itlist, Index newvarno)
+{
+	TargetEntry *tle;
+
+	/*
+	 * If it's a simple Const, replacing it with a Var is silly, even if there
+	 * happens to be an identical Const below; a Var is more expensive to
+	 * execute than a Const.  What's more, replacing it could confuse some
+	 * places in the executor that expect to see simple Consts for, eg,
+	 * dropped columns.
+	 */
+	if (IsA(node, Const))
+		return NULL;
+
+	tle = tlist_member(node, itlist->tlist);
+	if (tle)
+	{
+		/* Found a matching subplan output expression */
+		Var		   *newvar;
+
+		newvar = makeVarFromTargetEntry(newvarno, tle);
+		newvar->varnoold = 0;	/* wasn't ever a plain Var */
+		newvar->varoattno = 0;
+		return newvar;
+	}
+	return NULL;				/* no match */
+}
+
+/*
+ * search_indexed_tlist_for_sortgroupref --- find a sort/group expression
+ *
+ * If a match is found, return a Var constructed to reference the tlist item.
+ * If no match, return NULL.
+ *
+ * This is needed to ensure that we select the right subplan TLE in cases
+ * where there are multiple textually-equal()-but-volatile sort expressions.
+ * And it's also faster than search_indexed_tlist_for_non_var.
+ */
+static Var *
+search_indexed_tlist_for_sortgroupref(Expr *node,
+									  Index sortgroupref,
+									  indexed_tlist *itlist,
+									  Index newvarno)
+{
+	ListCell   *lc;
+
+	foreach(lc, itlist->tlist)
+	{
+		TargetEntry *tle = (TargetEntry *) lfirst(lc);
+
+		/* The equal() check should be redundant, but let's be paranoid */
+		if (tle->ressortgroupref == sortgroupref &&
+			equal(node, tle->expr))
+		{
+			/* Found a matching subplan output expression */
+			Var		   *newvar;
+
+			newvar = makeVarFromTargetEntry(newvarno, tle);
+			newvar->varnoold = 0;	/* wasn't ever a plain Var */
+			newvar->varoattno = 0;
+			return newvar;
+		}
+	}
+	return NULL;				/* no match */
+}
+
+/*
+ * fix_join_expr
+ *	   Create a new set of targetlist entries or join qual clauses by
+ *	   changing the varno/varattno values of variables in the clauses
+ *	   to reference target list values from the outer and inner join
+ *	   relation target lists.  Also perform opcode lookup and add
+ *	   regclass OIDs to root->glob->relationOids.
+ *
+ * This is used in three different scenarios:
+ * 1) a normal join clause, where all the Vars in the clause *must* be
+ *	  replaced by OUTER_VAR or INNER_VAR references.  In this case
+ *	  acceptable_rel should be zero so that any failure to match a Var will be
+ *	  reported as an error.
+ * 2) RETURNING clauses, which may contain both Vars of the target relation
+ *	  and Vars of other relations. In this case we want to replace the
+ *	  other-relation Vars by OUTER_VAR references, while leaving target Vars
+ *	  alone. Thus inner_itlist = NULL and acceptable_rel = the ID of the
+ *	  target relation should be passed.
+ * 3) ON CONFLICT UPDATE SET/WHERE clauses.  Here references to EXCLUDED are
+ *	  to be replaced with INNER_VAR references, while leaving target Vars (the
+ *	  to-be-updated relation) alone. Correspondingly inner_itlist is to be
+ *	  EXCLUDED elements, outer_itlist = NULL and acceptable_rel the target
+ *	  relation.
+ *
+ * 'clauses' is the targetlist or list of join clauses
+ * 'outer_itlist' is the indexed target list of the outer join relation,
+ *		or NULL
+ * 'inner_itlist' is the indexed target list of the inner join relation,
+ *		or NULL
+ * 'acceptable_rel' is either zero or the rangetable index of a relation
+ *		whose Vars may appear in the clause without provoking an error
+ * 'rtoffset': how much to increment varnoold by
+ *
+ * Returns the new expression tree.  The original clause structure is
+ * not modified.
+ */
+static List *
+fix_join_expr(PlannerInfo *root,
+			  List *clauses,
+			  indexed_tlist *outer_itlist,
+			  indexed_tlist *inner_itlist,
+			  Index acceptable_rel,
+			  int rtoffset)
+{
+	fix_join_expr_context context;
+
+	context.root = root;
+	context.outer_itlist = outer_itlist;
+	context.inner_itlist = inner_itlist;
+	context.acceptable_rel = acceptable_rel;
+	context.rtoffset = rtoffset;
+	return (List *) fix_join_expr_mutator((Node *) clauses, &context);
+}
+
+static Node *
+fix_join_expr_mutator(Node *node, fix_join_expr_context *context)
+{
+	Var		   *newvar;
+
+	if (node == NULL)
+		return NULL;
+	if (IsA(node, Var))
+	{
+		Var		   *var = (Var *) node;
+
+		/* Look for the var in the input tlists, first in the outer */
+		if (context->outer_itlist)
+		{
+			newvar = search_indexed_tlist_for_var(var,
+												  context->outer_itlist,
+												  OUTER_VAR,
+												  context->rtoffset);
+			if (newvar)
+				return (Node *) newvar;
+		}
+
+		/* then in the inner. */
+		if (context->inner_itlist)
+		{
+			newvar = search_indexed_tlist_for_var(var,
+												  context->inner_itlist,
+												  INNER_VAR,
+												  context->rtoffset);
+			if (newvar)
+				return (Node *) newvar;
+		}
+
+		/* If it's for acceptable_rel, adjust and return it */
+		if (var->varno == context->acceptable_rel)
+		{
+			var = copyVar(var);
+			var->varno += context->rtoffset;
+			if (var->varnoold > 0)
+				var->varnoold += context->rtoffset;
+			return (Node *) var;
+		}
+
+		/* No referent found for Var */
+		elog(ERROR, "variable not found in subplan target lists");
+	}
+	if (IsA(node, PlaceHolderVar))
+	{
+		PlaceHolderVar *phv = (PlaceHolderVar *) node;
+
+		/* See if the PlaceHolderVar has bubbled up from a lower plan node */
+		if (context->outer_itlist && context->outer_itlist->has_ph_vars)
+		{
+			newvar = search_indexed_tlist_for_non_var((Expr *) phv,
+													  context->outer_itlist,
+													  OUTER_VAR);
+			if (newvar)
+				return (Node *) newvar;
+		}
+		if (context->inner_itlist && context->inner_itlist->has_ph_vars)
+		{
+			newvar = search_indexed_tlist_for_non_var((Expr *) phv,
+													  context->inner_itlist,
+													  INNER_VAR);
+			if (newvar)
+				return (Node *) newvar;
+		}
+
+		/* If not supplied by input plans, evaluate the contained expr */
+		return fix_join_expr_mutator((Node *) phv->phexpr, context);
+	}
+	if (IsA(node, Param))
+		return fix_param_node(context->root, (Param *) node);
+	/* Try matching more complex expressions too, if tlists have any */
+	if (context->outer_itlist && context->outer_itlist->has_non_vars)
+	{
+		newvar = search_indexed_tlist_for_non_var((Expr *) node,
+												  context->outer_itlist,
+												  OUTER_VAR);
+		if (newvar)
+			return (Node *) newvar;
+	}
+	if (context->inner_itlist && context->inner_itlist->has_non_vars)
+	{
+		newvar = search_indexed_tlist_for_non_var((Expr *) node,
+												  context->inner_itlist,
+												  INNER_VAR);
+		if (newvar)
+			return (Node *) newvar;
+	}
+	fix_expr_common(context->root, node);
+	return expression_tree_mutator(node,
+								   fix_join_expr_mutator,
+								   (void *) context);
+}
+
+/*
+ * fix_upper_expr
+ *		Modifies an expression tree so that all Var nodes reference outputs
+ *		of a subplan.  Also looks for Aggref nodes that should be replaced
+ *		by initplan output Params.  Also performs opcode lookup, and adds
+ *		regclass OIDs to root->glob->relationOids.
+ *
+ * This is used to fix up target and qual expressions of non-join upper-level
+ * plan nodes, as well as index-only scan nodes.
+ *
+ * An error is raised if no matching var can be found in the subplan tlist
+ * --- so this routine should only be applied to nodes whose subplans'
+ * targetlists were generated by flattening the expressions used in the
+ * parent node.
+ *
+ * If itlist->has_non_vars is true, then we try to match whole subexpressions
+ * against elements of the subplan tlist, so that we can avoid recomputing
+ * expressions that were already computed by the subplan.  (This is relatively
+ * expensive, so we don't want to try it in the common case where the
+ * subplan tlist is just a flattened list of Vars.)
+ *
+ * 'node': the tree to be fixed (a target item or qual)
+ * 'subplan_itlist': indexed target list for subplan (or index)
+ * 'newvarno': varno to use for Vars referencing tlist elements
+ * 'rtoffset': how much to increment varnoold by
+ *
+ * The resulting tree is a copy of the original in which all Var nodes have
+ * varno = newvarno, varattno = resno of corresponding targetlist element.
+ * The original tree is not modified.
+ */
+static Node *
+fix_upper_expr(PlannerInfo *root,
+			   Node *node,
+			   indexed_tlist *subplan_itlist,
+			   Index newvarno,
+			   int rtoffset)
+{
+	fix_upper_expr_context context;
+
+	context.root = root;
+	context.subplan_itlist = subplan_itlist;
+	context.newvarno = newvarno;
+	context.rtoffset = rtoffset;
+	return fix_upper_expr_mutator(node, &context);
+}
+
+static Node *
+fix_upper_expr_mutator(Node *node, fix_upper_expr_context *context)
+{
+	Var		   *newvar;
+
+	if (node == NULL)
+		return NULL;
+	if (IsA(node, Var))
+	{
+		Var		   *var = (Var *) node;
+
+		newvar = search_indexed_tlist_for_var(var,
+											  context->subplan_itlist,
+											  context->newvarno,
+											  context->rtoffset);
+		if (!newvar)
+			elog(ERROR, "variable not found in subplan target list");
+		return (Node *) newvar;
+	}
+	if (IsA(node, PlaceHolderVar))
+	{
+		PlaceHolderVar *phv = (PlaceHolderVar *) node;
+
+		/* See if the PlaceHolderVar has bubbled up from a lower plan node */
+		if (context->subplan_itlist->has_ph_vars)
+		{
+			newvar = search_indexed_tlist_for_non_var((Expr *) phv,
+													  context->subplan_itlist,
+													  context->newvarno);
+			if (newvar)
+				return (Node *) newvar;
+		}
+		/* If not supplied by input plan, evaluate the contained expr */
+		return fix_upper_expr_mutator((Node *) phv->phexpr, context);
+	}
+	if (IsA(node, Param))
+		return fix_param_node(context->root, (Param *) node);
+	if (IsA(node, Aggref))
+	{
+		Aggref	   *aggref = (Aggref *) node;
+
+		/* See if the Aggref should be replaced by a Param */
+		if (context->root->minmax_aggs != NIL &&
+			list_length(aggref->args) == 1)
+		{
+			TargetEntry *curTarget = (TargetEntry *) linitial(aggref->args);
+			ListCell   *lc;
+
+			foreach(lc, context->root->minmax_aggs)
+			{
+				MinMaxAggInfo *mminfo = (MinMaxAggInfo *) lfirst(lc);
+
+				if (mminfo->aggfnoid == aggref->aggfnoid &&
+					equal(mminfo->target, curTarget->expr))
+					return (Node *) copyObject(mminfo->param);
+			}
+		}
+		/* If no match, just fall through to process it normally */
+	}
+	/* Try matching more complex expressions too, if tlist has any */
+	if (context->subplan_itlist->has_non_vars)
+	{
+		newvar = search_indexed_tlist_for_non_var((Expr *) node,
+												  context->subplan_itlist,
+												  context->newvarno);
+		if (newvar)
+			return (Node *) newvar;
+	}
+	fix_expr_common(context->root, node);
+	return expression_tree_mutator(node,
+								   fix_upper_expr_mutator,
+								   (void *) context);
+}
+
+/*
+ * set_returning_clause_references
+ *		Perform setrefs.c's work on a RETURNING targetlist
+ *
+ * If the query involves more than just the result table, we have to
+ * adjust any Vars that refer to other tables to reference junk tlist
+ * entries in the top subplan's targetlist.  Vars referencing the result
+ * table should be left alone, however (the executor will evaluate them
+ * using the actual heap tuple, after firing triggers if any).  In the
+ * adjusted RETURNING list, result-table Vars will have their original
+ * varno (plus rtoffset), but Vars for other rels will have varno OUTER_VAR.
+ *
+ * We also must perform opcode lookup and add regclass OIDs to
+ * root->glob->relationOids.
+ *
+ * 'rlist': the RETURNING targetlist to be fixed
+ * 'topplan': the top subplan node that will be just below the ModifyTable
+ *		node (note it's not yet passed through set_plan_refs)
+ * 'resultRelation': RT index of the associated result relation
+ * 'rtoffset': how much to increment varnos by
+ *
+ * Note: the given 'root' is for the parent query level, not the 'topplan'.
+ * This does not matter currently since we only access the dependency-item
+ * lists in root->glob, but it would need some hacking if we wanted a root
+ * that actually matches the subplan.
+ *
+ * Note: resultRelation is not yet adjusted by rtoffset.
+ */
+static List *
+set_returning_clause_references(PlannerInfo *root,
+								List *rlist,
+								Plan *topplan,
+								Index resultRelation,
+								int rtoffset)
+{
+	indexed_tlist *itlist;
+
+	/*
+	 * We can perform the desired Var fixup by abusing the fix_join_expr
+	 * machinery that formerly handled inner indexscan fixup.  We search the
+	 * top plan's targetlist for Vars of non-result relations, and use
+	 * fix_join_expr to convert RETURNING Vars into references to those tlist
+	 * entries, while leaving result-rel Vars as-is.
+	 *
+	 * PlaceHolderVars will also be sought in the targetlist, but no
+	 * more-complex expressions will be.  Note that it is not possible for a
+	 * PlaceHolderVar to refer to the result relation, since the result is
+	 * never below an outer join.  If that case could happen, we'd have to be
+	 * prepared to pick apart the PlaceHolderVar and evaluate its contained
+	 * expression instead.
+	 */
+	itlist = build_tlist_index_other_vars(topplan->targetlist, resultRelation);
+
+	rlist = fix_join_expr(root,
+						  rlist,
+						  itlist,
+						  NULL,
+						  resultRelation,
+						  rtoffset);
+
+	pfree(itlist);
+
+	return rlist;
+}
+
+
+/*****************************************************************************
+ *					QUERY DEPENDENCY MANAGEMENT
+ *****************************************************************************/
+
+/*
+ * record_plan_function_dependency
+ *		Mark the current plan as depending on a particular function.
+ *
+ * This is exported so that the function-inlining code can record a
+ * dependency on a function that it's removed from the plan tree.
+ */
+void
+record_plan_function_dependency(PlannerInfo *root, Oid funcid)
+{
+	/*
+	 * For performance reasons, we don't bother to track built-in functions;
+	 * we just assume they'll never change (or at least not in ways that'd
+	 * invalidate plans using them).  For this purpose we can consider a
+	 * built-in function to be one with OID less than FirstBootstrapObjectId.
+	 * Note that the OID generator guarantees never to generate such an OID
+	 * after startup, even at OID wraparound.
+	 */
+	if (funcid >= (Oid) FirstBootstrapObjectId)
+	{
+		PlanInvalItem *inval_item = makeNode(PlanInvalItem);
+
+		/*
+		 * It would work to use any syscache on pg_proc, but the easiest is
+		 * PROCOID since we already have the function's OID at hand.  Note
+		 * that plancache.c knows we use PROCOID.
+		 */
+		inval_item->cacheId = PROCOID;
+		inval_item->hashValue = GetSysCacheHashValue1(PROCOID,
+													  ObjectIdGetDatum(funcid));
+
+		root->glob->invalItems = lappend(root->glob->invalItems, inval_item);
+	}
+}
+
+/*
+ * extract_query_dependencies
+ *		Given a rewritten, but not yet planned, query or queries
+ *		(i.e. a Query node or list of Query nodes), extract dependencies
+ *		just as set_plan_references would do.  Also detect whether any
+ *		rewrite steps were affected by RLS.
+ *
+ * This is needed by plancache.c to handle invalidation of cached unplanned
+ * queries.
+ */
+void
+extract_query_dependencies(Node *query,
+						   List **relationOids,
+						   List **invalItems,
+						   bool *hasRowSecurity)
+{
+	PlannerGlobal glob;
+	PlannerInfo root;
+
+	/* Make up dummy planner state so we can use this module's machinery */
+	MemSet(&glob, 0, sizeof(glob));
+	glob.type = T_PlannerGlobal;
+	glob.relationOids = NIL;
+	glob.invalItems = NIL;
+	/* Hack: we use glob.dependsOnRole to collect hasRowSecurity flags */
+	glob.dependsOnRole = false;
+
+	MemSet(&root, 0, sizeof(root));
+	root.type = T_PlannerInfo;
+	root.glob = &glob;
+
+	(void) extract_query_dependencies_walker(query, &root);
+
+	*relationOids = glob.relationOids;
+	*invalItems = glob.invalItems;
+	*hasRowSecurity = glob.dependsOnRole;
+}
+
+static bool
+extract_query_dependencies_walker(Node *node, PlannerInfo *context)
+{
+	if (node == NULL)
+		return false;
+	Assert(!IsA(node, PlaceHolderVar));
+	/* Extract function dependencies and check for regclass Consts */
+	fix_expr_common(context, node);
+	if (IsA(node, Query))
+	{
+		Query	   *query = (Query *) node;
+		ListCell   *lc;
+
+		if (query->commandType == CMD_UTILITY)
+		{
+			/*
+			 * Ignore utility statements, except those (such as EXPLAIN) that
+			 * contain a parsed-but-not-planned query.
+			 */
+			query = UtilityContainsQuery(query->utilityStmt);
+			if (query == NULL)
+				return false;
+		}
+
+		/* Remember if any Query has RLS quals applied by rewriter */
+		if (query->hasRowSecurity)
+			context->glob->dependsOnRole = true;
+
+		/* Collect relation OIDs in this Query's rtable */
+		foreach(lc, query->rtable)
+		{
+			RangeTblEntry *rte = (RangeTblEntry *) lfirst(lc);
+
+			if (rte->rtekind == RTE_RELATION)
+				context->glob->relationOids =
+					lappend_oid(context->glob->relationOids, rte->relid);
+			else if (rte->rtekind == RTE_NAMEDTUPLESTORE &&
+					 OidIsValid(rte->relid))
+				context->glob->relationOids =
+					lappend_oid(context->glob->relationOids,
+								rte->relid);
+		}
+
+		/* And recurse into the query's subexpressions */
+		return query_tree_walker(query, extract_query_dependencies_walker,
+								 (void *) context, 0);
+	}
+	return expression_tree_walker(node, extract_query_dependencies_walker,
+								  (void *) context);
+}
diff -ruN a/src/backend/optimizer/prep/prepunion.c b/src/backend/optimizer/prep/prepunion.c
--- a/src/backend/optimizer/prep/prepunion.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/prep/prepunion.c	2017-12-28 14:58:03.499304815 +0300
@@ -576,7 +576,8 @@
 	/*
 	 * Append the child results together.
 	 */
-	path = (Path *) create_append_path(result_rel, pathlist, NULL, 0, NIL);
+	path = (Path *) create_append_path(result_rel, pathlist, NULL, 0, NIL,
+									   false, NIL);
 
 	/* We have to manually jam the right tlist into the path; ick */
 	path->pathtarget = create_pathtarget(root, tlist);
@@ -688,7 +689,8 @@
 	/*
 	 * Append the child results together.
 	 */
-	path = (Path *) create_append_path(result_rel, pathlist, NULL, 0, NIL);
+	path = (Path *) create_append_path(result_rel, pathlist, NULL, 0, NIL,
+									   false, NIL);
 
 	/* We have to manually jam the right tlist into the path; ick */
 	path->pathtarget = create_pathtarget(root, tlist);
diff -ruN a/src/backend/optimizer/util/pathnode.c b/src/backend/optimizer/util/pathnode.c
--- a/src/backend/optimizer/util/pathnode.c	2017-12-28 14:57:41.895568476 +0300
+++ b/src/backend/optimizer/util/pathnode.c	2017-12-28 14:58:03.499304815 +0300
@@ -1201,7 +1201,8 @@
  */
 AppendPath *
 create_append_path(RelOptInfo *rel, List *subpaths, Relids required_outer,
-				   int parallel_workers, List *partitioned_rels)
+				   int parallel_workers, List *partitioned_rels,
+				   bool pull_tlist, List *pathkeys)
 {
 	AppendPath *pathnode = makeNode(AppendPath);
 	ListCell   *l;
@@ -1214,9 +1215,10 @@
 	pathnode->path.parallel_aware = false;
 	pathnode->path.parallel_safe = rel->consider_parallel;
 	pathnode->path.parallel_workers = parallel_workers;
-	pathnode->path.pathkeys = NIL;	/* result is always considered unsorted */
-	pathnode->partitioned_rels = list_copy(partitioned_rels);
+	pathnode->path.pathkeys = pathkeys;	/* !=NIL in case of append OR index scans */
+	pathnode->partitioned_rels = partitioned_rels;
 	pathnode->subpaths = subpaths;
+	pathnode->pull_tlist = pull_tlist;
 
 	/*
 	 * We don't bother with inventing a cost_append(), but just do it here.
diff -ruN a/src/backend/parser/gram.y b/src/backend/parser/gram.y
--- a/src/backend/parser/gram.y	2017-12-28 14:57:41.879568672 +0300
+++ b/src/backend/parser/gram.y	2017-12-28 14:58:03.499304815 +0300
@@ -602,7 +602,7 @@
 
 /* ordinary key words in alphabetical order */
 %token <keyword> ABORT_P ABSOLUTE_P ACCESS ACTION ADD_P ADMIN AFTER
-	AGGREGATE ALL ALSO ALTER ALWAYS ANALYSE ANALYZE AND ANY ARRAY AS ASC
+	AGGREGATE ALL ALSO ALTER ALWAYS ANALYSE ANALYZE AND ANY APPLICATION ARRAY AS ASC
 	ASSERTION ASSIGNMENT ASYMMETRIC AT ATTACH ATTRIBUTE AUTHORIZATION
 
 	BACKWARD BEFORE BEGIN_P BETWEEN BIGINT BINARY BIT
@@ -10629,6 +10629,8 @@
 lock_type:	ACCESS SHARE					{ $$ = AccessShareLock; }
 			| ROW SHARE						{ $$ = RowShareLock; }
 			| ROW EXCLUSIVE					{ $$ = RowExclusiveLock; }
+			| APPLICATION SHARE             { $$ = ApplicationShareLock; }
+			| APPLICATION EXCLUSIVE         { $$ = ApplicationExclusiveLock; }
 			| SHARE UPDATE EXCLUSIVE		{ $$ = ShareUpdateExclusiveLock; }
 			| SHARE							{ $$ = ShareLock; }
 			| SHARE ROW EXCLUSIVE			{ $$ = ShareRowExclusiveLock; }
@@ -12601,7 +12603,7 @@
 				}
 			| a_expr LIKE a_expr ESCAPE a_expr					%prec LIKE
 				{
-					FuncCall *n = makeFuncCall(SystemFuncName("like_escape"),
+					FuncCall *n = makeFuncCall(list_make1(makeString("like_escape")),
 											   list_make2($3, $5),
 											   @2);
 					$$ = (Node *) makeSimpleA_Expr(AEXPR_LIKE, "~~",
@@ -12614,7 +12616,7 @@
 				}
 			| a_expr NOT_LA LIKE a_expr ESCAPE a_expr			%prec NOT_LA
 				{
-					FuncCall *n = makeFuncCall(SystemFuncName("like_escape"),
+					FuncCall *n = makeFuncCall(list_make1(makeString("like_escape")),
 											   list_make2($4, $6),
 											   @2);
 					$$ = (Node *) makeSimpleA_Expr(AEXPR_LIKE, "!~~",
@@ -12627,7 +12629,7 @@
 				}
 			| a_expr ILIKE a_expr ESCAPE a_expr					%prec ILIKE
 				{
-					FuncCall *n = makeFuncCall(SystemFuncName("like_escape"),
+					FuncCall *n = makeFuncCall(list_make1(makeString("like_escape")),
 											   list_make2($3, $5),
 											   @2);
 					$$ = (Node *) makeSimpleA_Expr(AEXPR_ILIKE, "~~*",
@@ -12640,7 +12642,7 @@
 				}
 			| a_expr NOT_LA ILIKE a_expr ESCAPE a_expr			%prec NOT_LA
 				{
-					FuncCall *n = makeFuncCall(SystemFuncName("like_escape"),
+					FuncCall *n = makeFuncCall(list_make1(makeString("like_escape")),
 											   list_make2($4, $6),
 											   @2);
 					$$ = (Node *) makeSimpleA_Expr(AEXPR_ILIKE, "!~~*",
@@ -12649,7 +12651,7 @@
 
 			| a_expr SIMILAR TO a_expr							%prec SIMILAR
 				{
-					FuncCall *n = makeFuncCall(SystemFuncName("similar_escape"),
+					FuncCall *n = makeFuncCall(list_make1(makeString("similar_escape")),
 											   list_make2($4, makeNullAConst(-1)),
 											   @2);
 					$$ = (Node *) makeSimpleA_Expr(AEXPR_SIMILAR, "~",
@@ -12657,7 +12659,7 @@
 				}
 			| a_expr SIMILAR TO a_expr ESCAPE a_expr			%prec SIMILAR
 				{
-					FuncCall *n = makeFuncCall(SystemFuncName("similar_escape"),
+					FuncCall *n = makeFuncCall(list_make1(makeString("similar_escape")),
 											   list_make2($4, $6),
 											   @2);
 					$$ = (Node *) makeSimpleA_Expr(AEXPR_SIMILAR, "~",
@@ -12665,7 +12667,7 @@
 				}
 			| a_expr NOT_LA SIMILAR TO a_expr					%prec NOT_LA
 				{
-					FuncCall *n = makeFuncCall(SystemFuncName("similar_escape"),
+					FuncCall *n = makeFuncCall(list_make1(makeString("similar_escape")),
 											   list_make2($5, makeNullAConst(-1)),
 											   @2);
 					$$ = (Node *) makeSimpleA_Expr(AEXPR_SIMILAR, "!~",
@@ -12673,7 +12675,7 @@
 				}
 			| a_expr NOT_LA SIMILAR TO a_expr ESCAPE a_expr		%prec NOT_LA
 				{
-					FuncCall *n = makeFuncCall(SystemFuncName("similar_escape"),
+					FuncCall *n = makeFuncCall(list_make1(makeString("similar_escape")),
 											   list_make2($5, $7),
 											   @2);
 					$$ = (Node *) makeSimpleA_Expr(AEXPR_SIMILAR, "!~",
@@ -14595,6 +14597,7 @@
 			| ALSO
 			| ALTER
 			| ALWAYS
+			| APPLICATION
 			| ASSERTION
 			| ASSIGNMENT
 			| AT
diff -ruN a/src/backend/storage/lmgr/lock.c b/src/backend/storage/lmgr/lock.c
--- a/src/backend/storage/lmgr/lock.c	2017-12-28 14:57:41.875568721 +0300
+++ b/src/backend/storage/lmgr/lock.c	2017-12-28 14:58:03.499304815 +0300
@@ -100,7 +100,13 @@
 	LOCKBIT_ON(AccessShareLock) | LOCKBIT_ON(RowShareLock) |
 	LOCKBIT_ON(RowExclusiveLock) | LOCKBIT_ON(ShareUpdateExclusiveLock) |
 	LOCKBIT_ON(ShareLock) | LOCKBIT_ON(ShareRowExclusiveLock) |
-	LOCKBIT_ON(ExclusiveLock) | LOCKBIT_ON(AccessExclusiveLock)
+	LOCKBIT_ON(ExclusiveLock) | LOCKBIT_ON(AccessExclusiveLock),
+
+	/* ApplicationShareLock*/
+	LOCKBIT_ON(ApplicationExclusiveLock),
+
+	/* ApplicationExclusiveLock*/
+	LOCKBIT_ON(ApplicationExclusiveLock) | LOCKBIT_ON(ApplicationShareLock)
 
 };
 
@@ -115,7 +121,9 @@
 	"ShareLock",
 	"ShareRowExclusiveLock",
 	"ExclusiveLock",
-	"AccessExclusiveLock"
+	"AccessExclusiveLock",
+	"ApplicationShareLock",
+	"ApplicationExclusiveLock"
 };
 
 #ifndef LOCK_DEBUG
@@ -123,7 +131,7 @@
 #endif
 
 static const LockMethodData default_lockmethod = {
-	AccessExclusiveLock,		/* highest valid lock mode number */
+	ApplicationExclusiveLock,		/* highest valid lock mode number */
 	LockConflicts,
 	lock_mode_names,
 #ifdef LOCK_DEBUG
@@ -134,7 +142,7 @@
 };
 
 static const LockMethodData user_lockmethod = {
-	AccessExclusiveLock,		/* highest valid lock mode number */
+	ApplicationExclusiveLock,		/* highest valid lock mode number */
 	LockConflicts,
 	lock_mode_names,
 #ifdef LOCK_DEBUG
diff -ruN a/src/include/nodes/relation.h b/src/include/nodes/relation.h
--- a/src/include/nodes/relation.h	2017-12-28 14:57:41.819569404 +0300
+++ b/src/include/nodes/relation.h	2017-12-28 14:58:03.499304815 +0300
@@ -1178,6 +1178,11 @@
 	/* RT indexes of non-leaf tables in a partition tree */
 	List	   *partitioned_rels;
 	List	   *subpaths;		/* list of component Paths */
+	bool		pull_tlist;		/* if = true, create_append_plan()
+									should get targetlist from any
+									subpath - they are the same,
+									because the only place - append
+									index scan for range OR */
 } AppendPath;
 
 #define IS_DUMMY_PATH(p) \
diff -ruN a/src/include/optimizer/pathnode.h b/src/include/optimizer/pathnode.h
--- a/src/include/optimizer/pathnode.h	2017-12-28 14:57:41.819569404 +0300
+++ b/src/include/optimizer/pathnode.h	2017-12-28 14:58:03.499304815 +0300
@@ -65,7 +65,8 @@
 					List *tidquals, Relids required_outer);
 extern AppendPath *create_append_path(RelOptInfo *rel, List *subpaths,
 				   Relids required_outer, int parallel_workers,
-				   List *partitioned_rels);
+				   List *partitioned_rels,
+				   bool pull_tlist, List *pathkeys);
 extern MergeAppendPath *create_merge_append_path(PlannerInfo *root,
 						 RelOptInfo *rel,
 						 List *subpaths,
diff -ruN a/src/include/optimizer/paths.h b/src/include/optimizer/paths.h
--- a/src/include/optimizer/paths.h	2017-12-28 14:57:41.819569404 +0300
+++ b/src/include/optimizer/paths.h	2017-12-28 14:58:03.499304815 +0300
@@ -68,6 +68,8 @@
  *	  routines to generate index paths
  */
 extern void create_index_paths(PlannerInfo *root, RelOptInfo *rel);
+extern List *generate_bitmap_or_paths(PlannerInfo *root, RelOptInfo *rel,
+									  List *clauses, List *other_clauses);
 extern bool relation_has_unique_index_for(PlannerInfo *root, RelOptInfo *rel,
 							  List *restrictlist,
 							  List *exprlist, List *oprlist);
@@ -220,10 +222,12 @@
 extern List *make_inner_pathkeys_for_merge(PlannerInfo *root,
 							  List *mergeclauses,
 							  List *outer_pathkeys);
+extern int pathkeys_useful_for_ordering(PlannerInfo *root, List *pathkeys);
 extern List *truncate_useless_pathkeys(PlannerInfo *root,
 						  RelOptInfo *rel,
 						  List *pathkeys);
 extern bool has_useful_pathkeys(PlannerInfo *root, RelOptInfo *rel);
+extern void keybased_rewrite_index_paths(PlannerInfo *root, RelOptInfo *rel);
 extern PathKey *make_canonical_pathkey(PlannerInfo *root,
 					   EquivalenceClass *eclass, Oid opfamily,
 					   int strategy, bool nulls_first);
diff -ruN a/src/include/optimizer/planmain.h b/src/include/optimizer/planmain.h
--- a/src/include/optimizer/planmain.h	2017-12-28 14:57:41.819569404 +0300
+++ b/src/include/optimizer/planmain.h	2017-12-28 14:58:03.499304815 +0300
@@ -56,6 +56,9 @@
 extern bool is_projection_capable_path(Path *path);
 extern bool is_projection_capable_plan(Plan *plan);
 
+extern Node * fix_indexqual_operand(Node *node, IndexOptInfo *index, int
+									indexcol);
+
 /* External use of these functions is deprecated: */
 extern Sort *make_sort_from_sortclauses(List *sortcls, Plan *lefttree);
 extern Agg *make_agg(List *tlist, List *qual,
diff -ruN a/src/include/parser/kwlist.h b/src/include/parser/kwlist.h
--- a/src/include/parser/kwlist.h	2017-12-28 14:57:41.815569453 +0300
+++ b/src/include/parser/kwlist.h	2017-12-28 14:58:03.499304815 +0300
@@ -42,6 +42,7 @@
 PG_KEYWORD("analyze", ANALYZE, RESERVED_KEYWORD)
 PG_KEYWORD("and", AND, RESERVED_KEYWORD)
 PG_KEYWORD("any", ANY, RESERVED_KEYWORD)
+PG_KEYWORD("application", APPLICATION, UNRESERVED_KEYWORD)
 PG_KEYWORD("array", ARRAY, RESERVED_KEYWORD)
 PG_KEYWORD("as", AS, RESERVED_KEYWORD)
 PG_KEYWORD("asc", ASC, RESERVED_KEYWORD)
diff -ruN a/src/include/storage/lock.h b/src/include/storage/lock.h
--- a/src/include/storage/lock.h	2017-12-28 14:57:41.815569453 +0300
+++ b/src/include/storage/lock.h	2017-12-28 14:58:03.499304815 +0300
@@ -82,11 +82,14 @@
 	 (vxid).localTransactionId = (proc).lxid)
 
 /* MAX_LOCKMODES cannot be larger than the # of bits in LOCKMASK */
-#define MAX_LOCKMODES		10
+#define MAX_LOCKMODES		12
 
 #define LOCKBIT_ON(lockmode) (1 << (lockmode))
 #define LOCKBIT_OFF(lockmode) (~(1 << (lockmode)))
 
+#define ApplicationShareLock       9   /* requested explicitly */
+#define ApplicationExclusiveLock   10  /* requested explicitly */
+
 
 /*
  * This data structure defines the locking semantics associated with a
diff -ruN a/src/test/regress/expected/create_index.out b/src/test/regress/expected/create_index.out
--- a/src/test/regress/expected/create_index.out	2017-12-28 14:57:41.855568965 +0300
+++ b/src/test/regress/expected/create_index.out	2017-12-28 14:58:03.499304815 +0300
@@ -2798,18 +2798,12 @@
 EXPLAIN (COSTS OFF)
 SELECT * FROM tenk1
   WHERE thousand = 42 AND (tenthous = 1 OR tenthous = 3 OR tenthous = 42);
-                                                               QUERY PLAN                                                                
------------------------------------------------------------------------------------------------------------------------------------------
- Bitmap Heap Scan on tenk1
-   Recheck Cond: (((thousand = 42) AND (tenthous = 1)) OR ((thousand = 42) AND (tenthous = 3)) OR ((thousand = 42) AND (tenthous = 42)))
-   ->  BitmapOr
-         ->  Bitmap Index Scan on tenk1_thous_tenthous
-               Index Cond: ((thousand = 42) AND (tenthous = 1))
-         ->  Bitmap Index Scan on tenk1_thous_tenthous
-               Index Cond: ((thousand = 42) AND (tenthous = 3))
-         ->  Bitmap Index Scan on tenk1_thous_tenthous
-               Index Cond: ((thousand = 42) AND (tenthous = 42))
-(9 rows)
+                           QUERY PLAN                            
+-----------------------------------------------------------------
+ Index Scan using tenk1_thous_tenthous on tenk1
+   Index Cond: ((thousand = 42) AND (thousand = 42))
+   Filter: ((tenthous = 1) OR (tenthous = 3) OR (tenthous = 42))
+(3 rows)
 
 SELECT * FROM tenk1
   WHERE thousand = 42 AND (tenthous = 1 OR tenthous = 3 OR tenthous = 42);
diff -ruN a/src/test/regress/expected/select.out b/src/test/regress/expected/select.out
--- a/src/test/regress/expected/select.out	2017-12-28 14:57:41.855568965 +0300
+++ b/src/test/regress/expected/select.out	2017-12-28 14:58:03.499304815 +0300
@@ -518,6 +518,124 @@
 (9 rows)
 
 --
+-- test order by NULLS (FIRST|LAST)
+--
+select unique1, unique2 into onek_with_null from onek;
+insert into onek_with_null (unique1,unique2) values (NULL, -1), (NULL, NULL);
+select * from onek_with_null order by unique1 nulls first	, unique2				limit 3;
+ unique1 | unique2 
+---------+---------
+         |      -1
+         |        
+       0 |     998
+(3 rows)
+
+select * from onek_with_null order by unique1 nulls last	, unique2				limit 3;
+ unique1 | unique2 
+---------+---------
+       0 |     998
+       1 |     214
+       2 |     326
+(3 rows)
+
+select * from onek_with_null order by unique1 nulls first	, unique2	nulls first	limit 3;
+ unique1 | unique2 
+---------+---------
+         |        
+         |      -1
+       0 |     998
+(3 rows)
+
+select * from onek_with_null order by unique1 nulls last	, unique2	nulls first	limit 3;
+ unique1 | unique2 
+---------+---------
+       0 |     998
+       1 |     214
+       2 |     326
+(3 rows)
+
+select * from onek_with_null order by unique1 nulls first	, unique2	nulls last	limit 3;
+ unique1 | unique2 
+---------+---------
+         |      -1
+         |        
+       0 |     998
+(3 rows)
+
+select * from onek_with_null order by unique1 nulls last	, unique2	nulls last	limit 3;
+ unique1 | unique2 
+---------+---------
+       0 |     998
+       1 |     214
+       2 |     326
+(3 rows)
+
+select * from onek_with_null order by unique1 desc nulls first	, unique2	desc 			limit 3;
+ unique1 | unique2 
+---------+---------
+         |        
+         |      -1
+     999 |     152
+(3 rows)
+
+select * from onek_with_null order by unique1 desc nulls last	, unique2	desc 			limit 3;
+ unique1 | unique2 
+---------+---------
+     999 |     152
+     998 |     549
+     997 |      21
+(3 rows)
+
+select * from onek_with_null order by unique1 desc nulls first	, unique2	desc nulls first	limit 3;
+ unique1 | unique2 
+---------+---------
+         |        
+         |      -1
+     999 |     152
+(3 rows)
+
+select * from onek_with_null order by unique1 desc nulls last	, unique2	desc nulls first	limit 3;
+ unique1 | unique2 
+---------+---------
+     999 |     152
+     998 |     549
+     997 |      21
+(3 rows)
+
+select * from onek_with_null order by unique1 desc nulls first	, unique2	desc nulls last	limit 3;
+ unique1 | unique2 
+---------+---------
+         |      -1
+         |        
+     999 |     152
+(3 rows)
+
+select * from onek_with_null order by unique1 desc nulls last	, unique2	desc nulls last	limit 3;
+ unique1 | unique2 
+---------+---------
+     999 |     152
+     998 |     549
+     997 |      21
+(3 rows)
+
+select unique1 as u1, unique2 as u2 from onek_with_null order by u1 nulls first	, u2	nulls first	limit 3;
+ u1 | u2  
+----+-----
+    |    
+    |  -1
+  0 | 998
+(3 rows)
+
+select unique1 as u1, unique2 as u2 from onek_with_null order by u1 asc nulls first	, u2 desc	nulls first	limit 3;
+ u1 | u2  
+----+-----
+    |    
+    |  -1
+  0 | 998
+(3 rows)
+
+drop table onek_with_null;
+--
 -- Test ORDER BY options
 --
 CREATE TEMP TABLE foo (f1 int);
diff -ruN a/src/test/regress/sql/select.sql b/src/test/regress/sql/select.sql
--- a/src/test/regress/sql/select.sql	2017-12-28 14:57:41.851569013 +0300
+++ b/src/test/regress/sql/select.sql	2017-12-28 14:58:03.499304815 +0300
@@ -149,6 +149,33 @@
 TABLE int8_tbl;
 
 --
+-- test order by NULLS (FIRST|LAST)
+--
+
+select unique1, unique2 into onek_with_null from onek;
+insert into onek_with_null (unique1,unique2) values (NULL, -1), (NULL, NULL);
+
+
+select * from onek_with_null order by unique1 nulls first	, unique2				limit 3;
+select * from onek_with_null order by unique1 nulls last	, unique2				limit 3;
+select * from onek_with_null order by unique1 nulls first	, unique2	nulls first	limit 3;
+select * from onek_with_null order by unique1 nulls last	, unique2	nulls first	limit 3;
+select * from onek_with_null order by unique1 nulls first	, unique2	nulls last	limit 3;
+select * from onek_with_null order by unique1 nulls last	, unique2	nulls last	limit 3;
+
+select * from onek_with_null order by unique1 desc nulls first	, unique2	desc 			limit 3;
+select * from onek_with_null order by unique1 desc nulls last	, unique2	desc 			limit 3;
+select * from onek_with_null order by unique1 desc nulls first	, unique2	desc nulls first	limit 3;
+select * from onek_with_null order by unique1 desc nulls last	, unique2	desc nulls first	limit 3;
+select * from onek_with_null order by unique1 desc nulls first	, unique2	desc nulls last	limit 3;
+select * from onek_with_null order by unique1 desc nulls last	, unique2	desc nulls last	limit 3;
+
+select unique1 as u1, unique2 as u2 from onek_with_null order by u1 nulls first	, u2	nulls first	limit 3;
+select unique1 as u1, unique2 as u2 from onek_with_null order by u1 asc nulls first	, u2 desc	nulls first	limit 3;
+
+drop table onek_with_null;
+
+--
 -- Test ORDER BY options
 --
 
diff -ruN a/src/tools/msvc/Mkvcbuild.pm b/src/tools/msvc/Mkvcbuild.pm
--- a/src/tools/msvc/Mkvcbuild.pm	2017-12-28 14:57:41.923568135 +0300
+++ b/src/tools/msvc/Mkvcbuild.pm	2017-12-28 15:03:07.995586794 +0300
@@ -62,6 +62,7 @@
 	'initdb'     => ['ws2_32.lib'],
 	'pg_restore' => ['ws2_32.lib'],
 	'pgbench'    => ['ws2_32.lib'],
+        'mchar'      => ['icuin.lib', 'icuuc.lib'],
 	'psql'       => ['ws2_32.lib'] };
 my $frontend_extraincludes = {
 	'initdb' => ['src/timezone'],
diff -ruN a/src/tools/msvc/Mkvcbuild.pm.orig b/src/tools/msvc/Mkvcbuild.pm.orig
--- a/src/tools/msvc/Mkvcbuild.pm.orig	1970-01-01 03:00:00.000000000 +0300
+++ b/src/tools/msvc/Mkvcbuild.pm.orig	2017-12-28 14:58:15.591157234 +0300
@@ -0,0 +1,973 @@
+package Mkvcbuild;
+
+#
+# Package that generates build files for msvc build
+#
+# src/tools/msvc/Mkvcbuild.pm
+#
+use Carp;
+use Win32;
+use strict;
+use warnings;
+use Project;
+use Solution;
+use Cwd;
+use File::Copy;
+use Config;
+use VSObjectFactory;
+use List::Util qw(first);
+
+use Exporter;
+our (@ISA, @EXPORT_OK);
+@ISA       = qw(Exporter);
+@EXPORT_OK = qw(Mkvcbuild);
+
+my $solution;
+my $libpgport;
+my $libpgcommon;
+my $libpgfeutils;
+my $postgres;
+my $libpq;
+
+# Set of variables for modules in contrib/ and src/test/modules/
+my $contrib_defines = { 'refint' => 'REFINT_VERBOSE' };
+my @contrib_uselibpq = ('dblink', 'oid2name', 'postgres_fdw', 'vacuumlo');
+my @contrib_uselibpgport   = ('oid2name', 'pg_standby', 'vacuumlo');
+my @contrib_uselibpgcommon = ('oid2name', 'pg_standby', 'vacuumlo');
+my $contrib_extralibs      = undef;
+my $contrib_extraincludes = { 'dblink' => ['src/backend'] };
+my $contrib_extrasource = {
+	'cube' => [ 'contrib/cube/cubescan.l', 'contrib/cube/cubeparse.y' ],
+	'seg'  => [ 'contrib/seg/segscan.l',   'contrib/seg/segparse.y' ], };
+my @contrib_excludes = (
+	'commit_ts',       'hstore_plperl',
+	'hstore_plpython', 'intagg',
+	'ltree_plpython',  'pgcrypto',
+	'sepgsql',         'brin',
+	'test_extensions', 'test_pg_dump',
+	'snapshot_too_old');
+
+# Set of variables for frontend modules
+my $frontend_defines = { 'initdb' => 'FRONTEND' };
+my @frontend_uselibpq = ('pg_ctl', 'pg_upgrade', 'pgbench', 'psql', 'initdb');
+my @frontend_uselibpgport = (
+	'pg_archivecleanup', 'pg_test_fsync',
+	'pg_test_timing',    'pg_upgrade',
+	'pg_waldump',        'pgbench');
+my @frontend_uselibpgcommon = (
+	'pg_archivecleanup', 'pg_test_fsync',
+	'pg_test_timing',    'pg_upgrade',
+	'pg_waldump',        'pgbench');
+my $frontend_extralibs = {
+	'initdb'     => ['ws2_32.lib'],
+	'pg_restore' => ['ws2_32.lib'],
+	'pgbench'    => ['ws2_32.lib'],
+        'mchar'      => ['icuin.lib', 'icuuc.lib'],
+	'psql'       => ['ws2_32.lib'] };
+my $frontend_extraincludes = {
+	'initdb' => ['src/timezone'],
+	'psql'   => ['src/backend'] };
+my $frontend_extrasource = {
+	'psql' => ['src/bin/psql/psqlscanslash.l'],
+	'pgbench' =>
+	  [ 'src/bin/pgbench/exprscan.l', 'src/bin/pgbench/exprparse.y' ] };
+my @frontend_excludes = (
+	'pgevent',    'pg_basebackup', 'pg_rewind', 'pg_dump',
+	'pg_waldump', 'scripts');
+
+sub mkvcbuild
+{
+	our $config = shift;
+
+	chdir('../../..') if (-d '../msvc' && -d '../../../src');
+	die 'Must run from root or msvc directory'
+	  unless (-d 'src/tools/msvc' && -d 'src');
+
+	my $vsVersion = DetermineVisualStudioVersion();
+
+	$solution = CreateSolution($vsVersion, $config);
+
+	our @pgportfiles = qw(
+	  chklocale.c crypt.c fls.c fseeko.c getrusage.c inet_aton.c random.c
+	  srandom.c getaddrinfo.c gettimeofday.c inet_net_ntop.c kill.c open.c
+	  erand48.c snprintf.c strlcat.c strlcpy.c dirmod.c noblock.c path.c
+	  pg_strong_random.c pgcheckdir.c pgmkdirp.c pgsleep.c pgstrcasecmp.c
+	  pqsignal.c mkdtemp.c qsort.c qsort_arg.c quotes.c system.c
+	  sprompt.c tar.c thread.c getopt.c getopt_long.c dirent.c
+	  win32env.c win32error.c win32security.c win32setlocale.c);
+
+	push(@pgportfiles, 'rint.c') if ($vsVersion < '12.00');
+
+	if ($vsVersion >= '9.00')
+	{
+		push(@pgportfiles, 'pg_crc32c_choose.c');
+		push(@pgportfiles, 'pg_crc32c_sse42.c');
+		push(@pgportfiles, 'pg_crc32c_sb8.c');
+	}
+	else
+	{
+		push(@pgportfiles, 'pg_crc32c_sb8.c');
+	}
+
+	our @pgcommonallfiles = qw(
+	  base64.c config_info.c controldata_utils.c exec.c ip.c keywords.c
+	  md5.c pg_lzcompress.c pgfnames.c psprintf.c relpath.c rmtree.c
+	  saslprep.c scram-common.c string.c unicode_norm.c username.c
+	  wait_error.c);
+
+	if ($solution->{options}->{openssl})
+	{
+		push(@pgcommonallfiles, 'sha2_openssl.c');
+	}
+	else
+	{
+		push(@pgcommonallfiles, 'sha2.c');
+	}
+
+	our @pgcommonfrontendfiles = (
+		@pgcommonallfiles, qw(fe_memutils.c file_utils.c
+		  restricted_token.c));
+
+	our @pgcommonbkndfiles = @pgcommonallfiles;
+
+	our @pgfeutilsfiles = qw(
+	  mbprint.c print.c psqlscan.l psqlscan.c simple_list.c string_utils.c);
+
+	$libpgport = $solution->AddProject('libpgport', 'lib', 'misc');
+	$libpgport->AddDefine('FRONTEND');
+	$libpgport->AddFiles('src/port', @pgportfiles);
+
+	$libpgcommon = $solution->AddProject('libpgcommon', 'lib', 'misc');
+	$libpgcommon->AddDefine('FRONTEND');
+	$libpgcommon->AddFiles('src/common', @pgcommonfrontendfiles);
+
+	$libpgfeutils = $solution->AddProject('libpgfeutils', 'lib', 'misc');
+	$libpgfeutils->AddDefine('FRONTEND');
+	$libpgfeutils->AddIncludeDir('src/interfaces/libpq');
+	$libpgfeutils->AddFiles('src/fe_utils', @pgfeutilsfiles);
+
+	$postgres = $solution->AddProject('postgres', 'exe', '', 'src/backend');
+	$postgres->AddIncludeDir('src/backend');
+	$postgres->AddDir('src/backend/port/win32');
+	$postgres->AddFile('src/backend/utils/fmgrtab.c');
+	$postgres->ReplaceFile(
+		'src/backend/port/dynloader.c',
+		'src/backend/port/dynloader/win32.c');
+	$postgres->ReplaceFile('src/backend/port/pg_sema.c',
+		'src/backend/port/win32_sema.c');
+	$postgres->ReplaceFile('src/backend/port/pg_shmem.c',
+		'src/backend/port/win32_shmem.c');
+	$postgres->AddFiles('src/port',   @pgportfiles);
+	$postgres->AddFiles('src/common', @pgcommonbkndfiles);
+	$postgres->AddDir('src/timezone');
+
+	# We need source files from src/timezone, but that directory's resource
+	# file pertains to "zic", not to the backend.
+	$postgres->RemoveFile('src/timezone/win32ver.rc');
+	$postgres->AddFiles('src/backend/parser', 'scan.l', 'gram.y');
+	$postgres->AddFiles('src/backend/bootstrap', 'bootscanner.l',
+		'bootparse.y');
+	$postgres->AddFiles('src/backend/utils/misc', 'guc-file.l');
+	$postgres->AddFiles(
+		'src/backend/replication', 'repl_scanner.l',
+		'repl_gram.y',             'syncrep_scanner.l',
+		'syncrep_gram.y');
+	$postgres->AddDefine('BUILDING_DLL');
+	$postgres->AddLibrary('secur32.lib');
+	$postgres->AddLibrary('ws2_32.lib');
+	$postgres->AddLibrary('wldap32.lib') if ($solution->{options}->{ldap});
+	$postgres->FullExportDLL('postgres.lib');
+
+   # The OBJS scraper doesn't know about ifdefs, so remove be-secure-openssl.c
+   # if building without OpenSSL
+	if (!$solution->{options}->{openssl})
+	{
+		$postgres->RemoveFile('src/backend/libpq/be-secure-openssl.c');
+	}
+
+	my $snowball = $solution->AddProject('dict_snowball', 'dll', '',
+		'src/backend/snowball');
+
+	# This Makefile uses VPATH to find most source files in a subdirectory.
+	$snowball->RelocateFiles(
+		'src/backend/snowball/libstemmer',
+		sub {
+			return shift !~ /(dict_snowball.c|win32ver.rc)$/;
+		});
+	$snowball->AddIncludeDir('src/include/snowball');
+	$snowball->AddReference($postgres);
+
+	my $plpgsql =
+	  $solution->AddProject('plpgsql', 'dll', 'PLs', 'src/pl/plpgsql/src');
+	$plpgsql->AddFiles('src/pl/plpgsql/src', 'pl_gram.y');
+	$plpgsql->AddReference($postgres);
+
+	if ($solution->{options}->{tcl})
+	{
+		my $found = 0;
+		my $pltcl =
+		  $solution->AddProject('pltcl', 'dll', 'PLs', 'src/pl/tcl');
+		$pltcl->AddIncludeDir($solution->{options}->{tcl} . '/include');
+		$pltcl->AddReference($postgres);
+
+		for my $tclver (qw(86t 86 85 84))
+		{
+			my $tcllib = $solution->{options}->{tcl} . "/lib/tcl$tclver.lib";
+			if (-e $tcllib)
+			{
+				$pltcl->AddLibrary($tcllib);
+				$found = 1;
+				last;
+			}
+		}
+		die "Unable to find $solution->{options}->{tcl}/lib/tcl<version>.lib"
+		  unless $found;
+	}
+
+	$libpq = $solution->AddProject('libpq', 'dll', 'interfaces',
+		'src/interfaces/libpq');
+	$libpq->AddDefine('FRONTEND');
+	$libpq->AddDefine('UNSAFE_STAT_OK');
+	$libpq->AddIncludeDir('src/port');
+	$libpq->AddLibrary('secur32.lib');
+	$libpq->AddLibrary('ws2_32.lib');
+	$libpq->AddLibrary('wldap32.lib') if ($solution->{options}->{ldap});
+	$libpq->UseDef('src/interfaces/libpq/libpqdll.def');
+	$libpq->ReplaceFile('src/interfaces/libpq/libpqrc.c',
+		'src/interfaces/libpq/libpq.rc');
+	$libpq->AddReference($libpgport);
+
+   # The OBJS scraper doesn't know about ifdefs, so remove fe-secure-openssl.c
+   # and sha2_openssl.c if building without OpenSSL, and remove sha2.c if
+   # building with OpenSSL.
+	if (!$solution->{options}->{openssl})
+	{
+		$libpq->RemoveFile('src/interfaces/libpq/fe-secure-openssl.c');
+		$libpq->RemoveFile('src/common/sha2_openssl.c');
+	}
+	else
+	{
+		$libpq->RemoveFile('src/common/sha2.c');
+	}
+
+	my $libpqwalreceiver =
+	  $solution->AddProject('libpqwalreceiver', 'dll', '',
+		'src/backend/replication/libpqwalreceiver');
+	$libpqwalreceiver->AddIncludeDir('src/interfaces/libpq');
+	$libpqwalreceiver->AddReference($postgres, $libpq);
+
+	my $pgoutput = $solution->AddProject('pgoutput', 'dll', '',
+		'src/backend/replication/pgoutput');
+	$pgoutput->AddReference($postgres);
+
+	my $pgtypes = $solution->AddProject(
+		'libpgtypes', 'dll',
+		'interfaces', 'src/interfaces/ecpg/pgtypeslib');
+	$pgtypes->AddDefine('FRONTEND');
+	$pgtypes->AddReference($libpgport);
+	$pgtypes->UseDef('src/interfaces/ecpg/pgtypeslib/pgtypeslib.def');
+	$pgtypes->AddIncludeDir('src/interfaces/ecpg/include');
+
+	my $libecpg = $solution->AddProject('libecpg', 'dll', 'interfaces',
+		'src/interfaces/ecpg/ecpglib');
+	$libecpg->AddDefine('FRONTEND');
+	$libecpg->AddIncludeDir('src/interfaces/ecpg/include');
+	$libecpg->AddIncludeDir('src/interfaces/libpq');
+	$libecpg->AddIncludeDir('src/port');
+	$libecpg->UseDef('src/interfaces/ecpg/ecpglib/ecpglib.def');
+	$libecpg->AddLibrary('ws2_32.lib');
+	$libecpg->AddReference($libpq, $pgtypes, $libpgport);
+
+	my $libecpgcompat = $solution->AddProject(
+		'libecpg_compat', 'dll',
+		'interfaces',     'src/interfaces/ecpg/compatlib');
+	$libecpgcompat->AddDefine('FRONTEND');
+	$libecpgcompat->AddIncludeDir('src/interfaces/ecpg/include');
+	$libecpgcompat->AddIncludeDir('src/interfaces/libpq');
+	$libecpgcompat->UseDef('src/interfaces/ecpg/compatlib/compatlib.def');
+	$libecpgcompat->AddReference($pgtypes, $libecpg, $libpgport);
+
+	my $ecpg = $solution->AddProject('ecpg', 'exe', 'interfaces',
+		'src/interfaces/ecpg/preproc');
+	$ecpg->AddIncludeDir('src/interfaces/ecpg/include');
+	$ecpg->AddIncludeDir('src/interfaces/libpq');
+	$ecpg->AddPrefixInclude('src/interfaces/ecpg/preproc');
+	$ecpg->AddFiles('src/interfaces/ecpg/preproc', 'pgc.l', 'preproc.y');
+	$ecpg->AddDefine('ECPG_COMPILE');
+	$ecpg->AddReference($libpgcommon, $libpgport);
+
+	my $pgregress_ecpg =
+	  $solution->AddProject('pg_regress_ecpg', 'exe', 'misc');
+	$pgregress_ecpg->AddFile('src/interfaces/ecpg/test/pg_regress_ecpg.c');
+	$pgregress_ecpg->AddFile('src/test/regress/pg_regress.c');
+	$pgregress_ecpg->AddIncludeDir('src/port');
+	$pgregress_ecpg->AddIncludeDir('src/test/regress');
+	$pgregress_ecpg->AddDefine('HOST_TUPLE="i686-pc-win32vc"');
+	$pgregress_ecpg->AddLibrary('ws2_32.lib');
+	$pgregress_ecpg->AddDirResourceFile('src/interfaces/ecpg/test');
+	$pgregress_ecpg->AddReference($libpgcommon, $libpgport);
+
+	my $isolation_tester =
+	  $solution->AddProject('isolationtester', 'exe', 'misc');
+	$isolation_tester->AddFile('src/test/isolation/isolationtester.c');
+	$isolation_tester->AddFile('src/test/isolation/specparse.y');
+	$isolation_tester->AddFile('src/test/isolation/specscanner.l');
+	$isolation_tester->AddFile('src/test/isolation/specparse.c');
+	$isolation_tester->AddIncludeDir('src/test/isolation');
+	$isolation_tester->AddIncludeDir('src/port');
+	$isolation_tester->AddIncludeDir('src/test/regress');
+	$isolation_tester->AddIncludeDir('src/interfaces/libpq');
+	$isolation_tester->AddDefine('HOST_TUPLE="i686-pc-win32vc"');
+	$isolation_tester->AddLibrary('ws2_32.lib');
+	$isolation_tester->AddDirResourceFile('src/test/isolation');
+	$isolation_tester->AddReference($libpq, $libpgcommon, $libpgport);
+
+	my $pgregress_isolation =
+	  $solution->AddProject('pg_isolation_regress', 'exe', 'misc');
+	$pgregress_isolation->AddFile('src/test/isolation/isolation_main.c');
+	$pgregress_isolation->AddFile('src/test/regress/pg_regress.c');
+	$pgregress_isolation->AddIncludeDir('src/port');
+	$pgregress_isolation->AddIncludeDir('src/test/regress');
+	$pgregress_isolation->AddDefine('HOST_TUPLE="i686-pc-win32vc"');
+	$pgregress_isolation->AddLibrary('ws2_32.lib');
+	$pgregress_isolation->AddDirResourceFile('src/test/isolation');
+	$pgregress_isolation->AddReference($libpgcommon, $libpgport);
+
+	# src/bin
+	my $D;
+	opendir($D, 'src/bin') || croak "Could not opendir on src/bin!\n";
+	while (my $d = readdir($D))
+	{
+		next if ($d =~ /^\./);
+		next unless (-f "src/bin/$d/Makefile");
+		next if (grep { /^$d$/ } @frontend_excludes);
+		AddSimpleFrontend($d);
+	}
+
+	my $pgbasebackup = AddSimpleFrontend('pg_basebackup', 1);
+	$pgbasebackup->AddFile('src/bin/pg_basebackup/pg_basebackup.c');
+	$pgbasebackup->AddLibrary('ws2_32.lib');
+
+	my $pgreceivewal = AddSimpleFrontend('pg_basebackup', 1);
+	$pgreceivewal->{name} = 'pg_receivewal';
+	$pgreceivewal->AddFile('src/bin/pg_basebackup/pg_receivewal.c');
+	$pgreceivewal->AddLibrary('ws2_32.lib');
+
+	my $pgrecvlogical = AddSimpleFrontend('pg_basebackup', 1);
+	$pgrecvlogical->{name} = 'pg_recvlogical';
+	$pgrecvlogical->AddFile('src/bin/pg_basebackup/pg_recvlogical.c');
+	$pgrecvlogical->AddLibrary('ws2_32.lib');
+
+	my $pgrewind = AddSimpleFrontend('pg_rewind', 1);
+	$pgrewind->{name} = 'pg_rewind';
+	$pgrewind->AddFile('src/backend/access/transam/xlogreader.c');
+	$pgrewind->AddLibrary('ws2_32.lib');
+	$pgrewind->AddDefine('FRONTEND');
+
+	my $pgevent = $solution->AddProject('pgevent', 'dll', 'bin');
+	$pgevent->AddFiles('src/bin/pgevent', 'pgevent.c', 'pgmsgevent.rc');
+	$pgevent->AddResourceFile('src/bin/pgevent', 'Eventlog message formatter',
+		'win32');
+	$pgevent->RemoveFile('src/bin/pgevent/win32ver.rc');
+	$pgevent->UseDef('src/bin/pgevent/pgevent.def');
+	$pgevent->DisableLinkerWarnings('4104');
+
+	my $pgdump = AddSimpleFrontend('pg_dump', 1);
+	$pgdump->AddIncludeDir('src/backend');
+	$pgdump->AddFile('src/bin/pg_dump/pg_dump.c');
+	$pgdump->AddFile('src/bin/pg_dump/common.c');
+	$pgdump->AddFile('src/bin/pg_dump/pg_dump_sort.c');
+	$pgdump->AddLibrary('ws2_32.lib');
+
+	my $pgdumpall = AddSimpleFrontend('pg_dump', 1);
+
+	# pg_dumpall doesn't use the files in the Makefile's $(OBJS), unlike
+	# pg_dump and pg_restore.
+	# So remove their sources from the object, keeping the other setup that
+	# AddSimpleFrontend() has done.
+	my @nodumpall = grep { m!src/bin/pg_dump/.*\.c$! }
+	  keys %{ $pgdumpall->{files} };
+	delete @{ $pgdumpall->{files} }{@nodumpall};
+	$pgdumpall->{name} = 'pg_dumpall';
+	$pgdumpall->AddIncludeDir('src/backend');
+	$pgdumpall->AddFile('src/bin/pg_dump/pg_dumpall.c');
+	$pgdumpall->AddFile('src/bin/pg_dump/dumputils.c');
+	$pgdumpall->AddLibrary('ws2_32.lib');
+
+	my $pgrestore = AddSimpleFrontend('pg_dump', 1);
+	$pgrestore->{name} = 'pg_restore';
+	$pgrestore->AddIncludeDir('src/backend');
+	$pgrestore->AddFile('src/bin/pg_dump/pg_restore.c');
+	$pgrestore->AddLibrary('ws2_32.lib');
+
+	my $zic = $solution->AddProject('zic', 'exe', 'utils');
+	$zic->AddFiles('src/timezone', 'zic.c');
+	$zic->AddDirResourceFile('src/timezone');
+	$zic->AddReference($libpgcommon, $libpgport);
+
+	if (!$solution->{options}->{xml})
+	{
+		push @contrib_excludes, 'xml2';
+	}
+
+	if (!$solution->{options}->{openssl})
+	{
+		push @contrib_excludes, 'sslinfo';
+	}
+
+	if (!$solution->{options}->{uuid})
+	{
+		push @contrib_excludes, 'uuid-ossp';
+	}
+
+	# AddProject() does not recognize the constructs used to populate OBJS in
+	# the pgcrypto Makefile, so it will discover no files.
+	my $pgcrypto =
+	  $solution->AddProject('pgcrypto', 'dll', 'crypto', 'contrib/pgcrypto');
+	$pgcrypto->AddFiles(
+		'contrib/pgcrypto', 'pgcrypto.c',
+		'px.c',             'px-hmac.c',
+		'px-crypt.c',       'crypt-gensalt.c',
+		'crypt-blowfish.c', 'crypt-des.c',
+		'crypt-md5.c',      'mbuf.c',
+		'pgp.c',            'pgp-armor.c',
+		'pgp-cfb.c',        'pgp-compress.c',
+		'pgp-decrypt.c',    'pgp-encrypt.c',
+		'pgp-info.c',       'pgp-mpi.c',
+		'pgp-pubdec.c',     'pgp-pubenc.c',
+		'pgp-pubkey.c',     'pgp-s2k.c',
+		'pgp-pgsql.c');
+	if ($solution->{options}->{openssl})
+	{
+		$pgcrypto->AddFiles('contrib/pgcrypto', 'openssl.c',
+			'pgp-mpi-openssl.c');
+	}
+	else
+	{
+		$pgcrypto->AddFiles(
+			'contrib/pgcrypto', 'md5.c',
+			'sha1.c',           'internal.c',
+			'internal-sha2.c',  'blf.c',
+			'rijndael.c',       'pgp-mpi-internal.c',
+			'imath.c');
+	}
+	$pgcrypto->AddReference($postgres);
+	$pgcrypto->AddLibrary('ws2_32.lib');
+	my $mf = Project::read_file('contrib/pgcrypto/Makefile');
+	GenerateContribSqlFiles('pgcrypto', $mf);
+
+	foreach my $subdir ('contrib', 'src/test/modules')
+	{
+		opendir($D, $subdir) || croak "Could not opendir on $subdir!\n";
+		while (my $d = readdir($D))
+		{
+			next if ($d =~ /^\./);
+			next unless (-f "$subdir/$d/Makefile");
+			next if (grep { /^$d$/ } @contrib_excludes);
+			AddContrib($subdir, $d);
+		}
+		closedir($D);
+	}
+
+	# Build Perl and Python modules after contrib/ modules to satisfy some
+	# dependencies with transform contrib modules, like hstore_plpython
+	# ltree_plpython and hstore_plperl.
+	if ($solution->{options}->{python})
+	{
+
+		# Attempt to get python version and location.
+		# Assume python.exe in specified dir.
+		my $pythonprog = "import sys;print(sys.prefix);"
+		  . "print(str(sys.version_info[0])+str(sys.version_info[1]))";
+		my $prefixcmd =
+		  $solution->{options}->{python} . "\\python -c \"$pythonprog\"";
+		my $pyout = `$prefixcmd`;
+		die "Could not query for python version!\n" if $?;
+		my ($pyprefix, $pyver) = split(/\r?\n/, $pyout);
+
+		# Sometimes (always?) if python is not present, the execution
+		# appears to work, but gives no data...
+		die "Failed to query python for version information\n"
+		  if (!(defined($pyprefix) && defined($pyver)));
+
+		my $pymajorver = substr($pyver, 0, 1);
+		my $plpython = $solution->AddProject('plpython' . $pymajorver,
+			'dll', 'PLs', 'src/pl/plpython');
+		$plpython->AddIncludeDir($pyprefix . '/include');
+		$plpython->AddLibrary($pyprefix . "/Libs/python$pyver.lib");
+		$plpython->AddReference($postgres);
+
+		# Add transform modules dependent on plpython
+		my $hstore_plpython = AddTransformModule(
+			'hstore_plpython' . $pymajorver, 'contrib/hstore_plpython',
+			'plpython' . $pymajorver,        'src/pl/plpython',
+			'hstore',                        'contrib/hstore');
+		$hstore_plpython->AddDefine(
+			'PLPYTHON_LIBNAME="plpython' . $pymajorver . '"');
+		my $ltree_plpython = AddTransformModule(
+			'ltree_plpython' . $pymajorver, 'contrib/ltree_plpython',
+			'plpython' . $pymajorver,       'src/pl/plpython',
+			'ltree',                        'contrib/ltree');
+		$ltree_plpython->AddDefine(
+			'PLPYTHON_LIBNAME="plpython' . $pymajorver . '"');
+	}
+
+	if ($solution->{options}->{perl})
+	{
+		my $plperlsrc = "src/pl/plperl/";
+		my $plperl =
+		  $solution->AddProject('plperl', 'dll', 'PLs', 'src/pl/plperl');
+		$plperl->AddIncludeDir($solution->{options}->{perl} . '/lib/CORE');
+
+		# Add defines from Perl's ccflags; see PGAC_CHECK_PERL_EMBED_CCFLAGS
+		my @perl_embed_ccflags;
+		foreach my $f (split(" ", $Config{ccflags}))
+		{
+			if (   $f =~ /^-D[^_]/
+				|| $f =~ /^-D_USE_32BIT_TIME_T/)
+			{
+				$f =~ s/\-D//;
+				push(@perl_embed_ccflags, $f);
+			}
+		}
+
+		# Perl versions before 5.13.4 don't provide -D_USE_32BIT_TIME_T
+		# regardless of how they were built.  On 32-bit Windows, assume
+		# such a version was built with a pre-MSVC-2005 compiler, and
+		# define the symbol anyway, so that we are compatible if we're
+		# being built with a later MSVC version.
+		push(@perl_embed_ccflags, '_USE_32BIT_TIME_T')
+		  if $solution->{platform} eq 'Win32'
+			  && $Config{PERL_REVISION} == 5
+			  && ($Config{PERL_VERSION} < 13
+				  || (   $Config{PERL_VERSION} == 13
+					  && $Config{PERL_SUBVERSION} < 4));
+
+		# Also, a hack to prevent duplicate definitions of uid_t/gid_t
+		push(@perl_embed_ccflags, 'PLPERL_HAVE_UID_GID');
+
+		foreach my $f (@perl_embed_ccflags)
+		{
+			$plperl->AddDefine($f);
+		}
+
+		foreach my $xs ('SPI.xs', 'Util.xs')
+		{
+			(my $xsc = $xs) =~ s/\.xs/.c/;
+			if (Solution::IsNewer("$plperlsrc$xsc", "$plperlsrc$xs"))
+			{
+				my $xsubppdir = first { -e "$_/ExtUtils/xsubpp" } @INC;
+				print "Building $plperlsrc$xsc...\n";
+				system( $solution->{options}->{perl}
+					  . '/bin/perl '
+					  . "$xsubppdir/ExtUtils/xsubpp -typemap "
+					  . $solution->{options}->{perl}
+					  . '/lib/ExtUtils/typemap '
+					  . "$plperlsrc$xs "
+					  . ">$plperlsrc$xsc");
+				if ((!(-f "$plperlsrc$xsc")) || -z "$plperlsrc$xsc")
+				{
+					unlink("$plperlsrc$xsc");    # if zero size
+					die "Failed to create $xsc.\n";
+				}
+			}
+		}
+		if (Solution::IsNewer(
+				'src/pl/plperl/perlchunks.h',
+				'src/pl/plperl/plc_perlboot.pl')
+			|| Solution::IsNewer(
+				'src/pl/plperl/perlchunks.h',
+				'src/pl/plperl/plc_trusted.pl'))
+		{
+			print 'Building src/pl/plperl/perlchunks.h ...' . "\n";
+			my $basedir = getcwd;
+			chdir 'src/pl/plperl';
+			system( $solution->{options}->{perl}
+				  . '/bin/perl '
+				  . 'text2macro.pl '
+				  . '--strip="^(\#.*|\s*)$$" '
+				  . 'plc_perlboot.pl plc_trusted.pl '
+				  . '>perlchunks.h');
+			chdir $basedir;
+			if ((!(-f 'src/pl/plperl/perlchunks.h'))
+				|| -z 'src/pl/plperl/perlchunks.h')
+			{
+				unlink('src/pl/plperl/perlchunks.h');    # if zero size
+				die 'Failed to create perlchunks.h' . "\n";
+			}
+		}
+		if (Solution::IsNewer(
+				'src/pl/plperl/plperl_opmask.h',
+				'src/pl/plperl/plperl_opmask.pl'))
+		{
+			print 'Building src/pl/plperl/plperl_opmask.h ...' . "\n";
+			my $basedir = getcwd;
+			chdir 'src/pl/plperl';
+			system( $solution->{options}->{perl}
+				  . '/bin/perl '
+				  . 'plperl_opmask.pl '
+				  . 'plperl_opmask.h');
+			chdir $basedir;
+			if ((!(-f 'src/pl/plperl/plperl_opmask.h'))
+				|| -z 'src/pl/plperl/plperl_opmask.h')
+			{
+				unlink('src/pl/plperl/plperl_opmask.h');    # if zero size
+				die 'Failed to create plperl_opmask.h' . "\n";
+			}
+		}
+		$plperl->AddReference($postgres);
+		my $perl_path = $solution->{options}->{perl} . '\lib\CORE\*.*';
+		my @perl_libs =
+		  grep { /perl\d+.(lib|a)$/ } glob($perl_path);
+		if (@perl_libs == 1)
+		{
+			$plperl->AddLibrary($perl_libs[0]);
+		}
+		else
+		{
+			die
+"could not identify perl library version matching pattern $perl_path\n";
+		}
+
+		# Add transform module dependent on plperl
+		my $hstore_plperl = AddTransformModule(
+			'hstore_plperl', 'contrib/hstore_plperl',
+			'plperl',        'src/pl/plperl',
+			'hstore',        'contrib/hstore');
+
+		foreach my $f (@perl_embed_ccflags)
+		{
+			$hstore_plperl->AddDefine($f);
+		}
+	}
+
+	$mf =
+	  Project::read_file('src/backend/utils/mb/conversion_procs/Makefile');
+	$mf =~ s{\\\r?\n}{}g;
+	$mf =~ m{SUBDIRS\s*=\s*(.*)$}m
+	  || die 'Could not match in conversion makefile' . "\n";
+	foreach my $sub (split /\s+/, $1)
+	{
+		my $dir = 'src/backend/utils/mb/conversion_procs/' . $sub;
+		my $p = $solution->AddProject($sub, 'dll', 'conversion procs', $dir);
+		$p->AddFile("$dir/$sub.c");    # implicit source file
+		$p->AddReference($postgres);
+	}
+
+	$mf = Project::read_file('src/bin/scripts/Makefile');
+	$mf =~ s{\\\r?\n}{}g;
+	$mf =~ m{PROGRAMS\s*=\s*(.*)$}m
+	  || die 'Could not match in bin/scripts/Makefile' . "\n";
+	foreach my $prg (split /\s+/, $1)
+	{
+		my $proj = $solution->AddProject($prg, 'exe', 'bin');
+		$mf =~ m{$prg\s*:\s*(.*)$}m
+		  || die 'Could not find script define for $prg' . "\n";
+		my @files = split /\s+/, $1;
+		foreach my $f (@files)
+		{
+			$f =~ s/\.o$/\.c/;
+			if ($f =~ /\.c$/)
+			{
+				$proj->AddFile('src/bin/scripts/' . $f);
+			}
+		}
+		$proj->AddIncludeDir('src/interfaces/libpq');
+		$proj->AddReference($libpq, $libpgfeutils, $libpgcommon, $libpgport);
+		$proj->AddDirResourceFile('src/bin/scripts');
+		$proj->AddLibrary('ws2_32.lib');
+	}
+
+	# Regression DLL and EXE
+	my $regress = $solution->AddProject('regress', 'dll', 'misc');
+	$regress->AddFile('src/test/regress/regress.c');
+	$regress->AddDirResourceFile('src/test/regress');
+	$regress->AddReference($postgres);
+
+	my $pgregress = $solution->AddProject('pg_regress', 'exe', 'misc');
+	$pgregress->AddFile('src/test/regress/pg_regress.c');
+	$pgregress->AddFile('src/test/regress/pg_regress_main.c');
+	$pgregress->AddIncludeDir('src/port');
+	$pgregress->AddDefine('HOST_TUPLE="i686-pc-win32vc"');
+	$pgregress->AddLibrary('ws2_32.lib');
+	$pgregress->AddDirResourceFile('src/test/regress');
+	$pgregress->AddReference($libpgcommon, $libpgport);
+
+	# fix up pg_waldump once it's been set up
+	# files symlinked on Unix are copied on windows
+	my $pg_waldump = AddSimpleFrontend('pg_waldump');
+	$pg_waldump->AddDefine('FRONTEND');
+	foreach my $xf (glob('src/backend/access/rmgrdesc/*desc.c'))
+	{
+		$pg_waldump->AddFile($xf);
+	}
+	$pg_waldump->AddFile('src/backend/access/transam/xlogreader.c');
+
+	$solution->Save();
+	return $solution->{vcver};
+}
+
+#####################
+# Utility functions #
+#####################
+
+# Add a simple frontend project (exe)
+sub AddSimpleFrontend
+{
+	my $n        = shift;
+	my $uselibpq = shift;
+
+	my $p = $solution->AddProject($n, 'exe', 'bin');
+	$p->AddDir('src/bin/' . $n);
+	$p->AddReference($libpgfeutils, $libpgcommon, $libpgport);
+	if ($uselibpq)
+	{
+		$p->AddIncludeDir('src/interfaces/libpq');
+		$p->AddReference($libpq);
+	}
+
+	# Adjust module definition using frontend variables
+	AdjustFrontendProj($p);
+
+	return $p;
+}
+
+# Add a simple transform module
+sub AddTransformModule
+{
+	my $n              = shift;
+	my $n_src          = shift;
+	my $pl_proj_name   = shift;
+	my $pl_src         = shift;
+	my $transform_name = shift;
+	my $transform_src  = shift;
+
+	my $transform_proj = undef;
+	foreach my $proj (@{ $solution->{projects}->{'contrib'} })
+	{
+		if ($proj->{name} eq $transform_name)
+		{
+			$transform_proj = $proj;
+			last;
+		}
+	}
+	die "could not find base module $transform_name for transform module $n"
+	  if (!defined($transform_proj));
+
+	my $pl_proj = undef;
+	foreach my $proj (@{ $solution->{projects}->{'PLs'} })
+	{
+		if ($proj->{name} eq $pl_proj_name)
+		{
+			$pl_proj = $proj;
+			last;
+		}
+	}
+	die "could not find PL $pl_proj_name for transform module $n"
+	  if (!defined($pl_proj));
+
+	my $p = $solution->AddProject($n, 'dll', 'contrib', $n_src);
+	for my $file (glob("$n_src/*.c"))
+	{
+		$p->AddFile($file);
+	}
+	$p->AddReference($postgres);
+
+	# Add PL dependencies
+	$p->AddIncludeDir($pl_src);
+	$p->AddReference($pl_proj);
+	$p->AddIncludeDir($pl_proj->{includes});
+	foreach my $pl_lib (@{ $pl_proj->{libraries} })
+	{
+		$p->AddLibrary($pl_lib);
+	}
+
+	# Add base module dependencies
+	$p->AddIncludeDir($transform_src);
+	$p->AddIncludeDir($transform_proj->{includes});
+	foreach my $trans_lib (@{ $transform_proj->{libraries} })
+	{
+		$p->AddLibrary($trans_lib);
+	}
+	$p->AddReference($transform_proj);
+
+	return $p;
+}
+
+# Add a simple contrib project
+sub AddContrib
+{
+	my $subdir = shift;
+	my $n      = shift;
+	my $mf     = Project::read_file("$subdir/$n/Makefile");
+
+	if ($mf =~ /^MODULE_big\s*=\s*(.*)$/mg)
+	{
+		my $dn = $1;
+		my $proj = $solution->AddProject($dn, 'dll', 'contrib', "$subdir/$n");
+		$proj->AddReference($postgres);
+		AdjustContribProj($proj);
+	}
+	elsif ($mf =~ /^MODULES\s*=\s*(.*)$/mg)
+	{
+		foreach my $mod (split /\s+/, $1)
+		{
+			my $proj =
+			  $solution->AddProject($mod, 'dll', 'contrib', "$subdir/$n");
+			my $filename = $mod . '.c';
+			$proj->AddFile("$subdir/$n/$filename");
+			$proj->AddReference($postgres);
+			AdjustContribProj($proj);
+		}
+	}
+	elsif ($mf =~ /^PROGRAM\s*=\s*(.*)$/mg)
+	{
+		my $proj = $solution->AddProject($1, 'exe', 'contrib', "$subdir/$n");
+		AdjustContribProj($proj);
+	}
+	else
+	{
+		croak "Could not determine contrib module type for $n\n";
+	}
+
+	# Are there any output data files to build?
+	GenerateContribSqlFiles($n, $mf);
+}
+
+sub SubstituteMakefileVariables {
+	local $_ = shift; # Line to substitue
+	my $mf   = shift; # Makefile text
+	while (/\$\((\w+)\)/) {
+		my $varname = $1;
+		if ($mf =~ /^$varname\s*=\s*(.*)$/mg) {
+			my $varvalue=$1;
+			s/\$\($varname\)/$varvalue/g;
+				}
+			}
+	return $_;
+}
+
+
+sub GenerateContribSqlFiles
+{
+	my $n  = shift;
+	my $mf = shift;
+	$mf =~ s{\\\r?\n}{}g;
+	if ($mf =~ /^DATA_built\s*=\s*(.*)$/mg)
+	{
+		my $l = $1;
+
+		# Strip out $(addsuffix) rules
+		if (index($l, '$(addsuffix ') >= 0)
+		{
+			my $pcount = 0;
+			my $i;
+			for ($i = index($l, '$(addsuffix ') + 12; $i < length($l); $i++)
+			{
+				$pcount++ if (substr($l, $i, 1) eq '(');
+				$pcount-- if (substr($l, $i, 1) eq ')');
+				last      if ($pcount < 0);
+			}
+			$l =
+			  substr($l, 0, index($l, '$(addsuffix ')) . substr($l, $i + 1);
+		}
+
+		foreach my $d (split /\s+/, $l)
+		{
+			my $in  = "$d.in";
+			my $out = "$d";
+
+			if (Solution::IsNewer("contrib/$n/$out", "contrib/$n/$in"))
+			{
+				print "Building $out from $in (contrib/$n)...\n";
+				my $cont = Project::read_file("contrib/$n/$in");
+				my $dn   = $out;
+				$dn   =~ s/\.sql$//;
+				$cont =~ s/MODULE_PATHNAME/\$libdir\/$dn/g;
+				my $o;
+				open($o, '>', "contrib/$n/$out")
+				  || croak "Could not write to contrib/$n/$d";
+				print $o $cont;
+				close($o);
+			}
+		}
+	}
+}
+
+sub AdjustContribProj
+{
+	my $proj = shift;
+	AdjustModule(
+		$proj,                    $contrib_defines,
+		\@contrib_uselibpq,       \@contrib_uselibpgport,
+		\@contrib_uselibpgcommon, $contrib_extralibs,
+		$contrib_extrasource,     $contrib_extraincludes);
+}
+
+sub AdjustFrontendProj
+{
+	my $proj = shift;
+	AdjustModule(
+		$proj,                     $frontend_defines,
+		\@frontend_uselibpq,       \@frontend_uselibpgport,
+		\@frontend_uselibpgcommon, $frontend_extralibs,
+		$frontend_extrasource,     $frontend_extraincludes);
+}
+
+sub AdjustModule
+{
+	my $proj                  = shift;
+	my $module_defines        = shift;
+	my $module_uselibpq       = shift;
+	my $module_uselibpgport   = shift;
+	my $module_uselibpgcommon = shift;
+	my $module_extralibs      = shift;
+	my $module_extrasource    = shift;
+	my $module_extraincludes  = shift;
+	my $n                     = $proj->{name};
+
+	if ($module_defines->{$n})
+	{
+		foreach my $d ($module_defines->{$n})
+		{
+			$proj->AddDefine($d);
+		}
+	}
+	if (grep { /^$n$/ } @{$module_uselibpq})
+	{
+		$proj->AddIncludeDir('src\interfaces\libpq');
+		$proj->AddReference($libpq);
+	}
+	if (grep { /^$n$/ } @{$module_uselibpgport})
+	{
+		$proj->AddReference($libpgport);
+	}
+	if (grep { /^$n$/ } @{$module_uselibpgcommon})
+	{
+		$proj->AddReference($libpgcommon);
+	}
+	if ($module_extralibs->{$n})
+	{
+		foreach my $l (@{ $module_extralibs->{$n} })
+		{
+			$proj->AddLibrary($l);
+		}
+	}
+	if ($module_extraincludes->{$n})
+	{
+		foreach my $i (@{ $module_extraincludes->{$n} })
+		{
+			$proj->AddIncludeDir($i);
+		}
+	}
+	if ($module_extrasource->{$n})
+	{
+		foreach my $i (@{ $module_extrasource->{$n} })
+		{
+			print "Files $i\n";
+			$proj->AddFile($i);
+		}
+	}
+}
+
+1;
